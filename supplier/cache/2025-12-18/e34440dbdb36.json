{
  "title": "[12월2일] &quot;언어와 지능은 별개...LLM으로는 초지능 달성할 수 없어&quot;",
  "summary": "최근 더 버지에는 벤저민 라일리 코그니티브 레저넌스(Cognitive Resonance) 창립자의 칼럼이 소개됐습니다. 그는 '대형 언어 실수(Large language mistake)'라는 글을 통해 현재 오픈AI나 앤트로픽, 메타 등이 추진하는 초지능에 대해 비판했습니다.그는 먼저 이들 기업이 주장하는 초지능의 기반은 대형언어모델(LLM)이라고 지적했습니다. 근본적으로 이 모델들은 엄청난 양의 언어 데이터를 수집하고, 단어(정확하게는 '토큰') 간의 상관관계를 찾은 다음, 특정 입력 프롬프트가 주어졌을 때 어떤 결과가 나올지 예",
  "published_at": "2025-12-03T07:00:00+09:00",
  "modified_at": "2025-12-03T07:00:00+09:00",
  "author": [
    "AI타임스"
  ],
  "image": "https://cdn.aitimes.com/news/photo/202512/204431_205649_4322.png",
  "text": "(사진=셔터스톡) 최근 더 버지에는 벤저민 라일리 코그니티브 레저넌스(Cognitive Resonance) 창립자의 칼럼이 소개됐습니다. 그는 ' 대형 언어 실수(Large language mistake) '라는 글을 통해 현재 오픈AI나 앤트로픽, 메타 등이 추진하는 초지능에 대해 비판했습니다. 그는 먼저 이들 기업이 주장하는 초지능의 기반은 대형언어모델(LLM)이라고 지적했습니다. 근본적으로 이 모델들은 엄청난 양의 언어 데이터를 수집하고, 단어(정확하게는 '토큰') 간의 상관관계를 찾은 다음, 특정 입력 프롬프트가 주어졌을 때 어떤 결과가 나올지 예측하는 방식입니다. 생성 AI가 아무리 복잡하다고 해도, 본질적으로는 언어 모델이라는 것입니다. 라일리 창립자는 \"여기에서 문제는 현대 신경과학에 따르면 인간의 사고가 대체로 언어와 무관하다는 점\"이라고 지적했습니다. 이에 따라 모델을 더 정교하게 만든다고 인간과 비슷하거나 능가하는 지능을 만들어낼 것이라고 믿을 근거는 거의 없다고 합니다. 인간은 추론 능력, 추상화, 일반화 능력, 즉 지능이라고 부를 수 있는 능력의 결과를 전달하기 위해 언어를 사용합니다. 우리는 언어를 사용해 사고하지만, 그렇다고 해서 언어가 사고와 같아지는 것이 아니라고 합니다. 그리고 \"이런 구분을 이해하는 것이 과학적 사실과 AI에 열광하는 기업들의 추측성 SF 소설을 구분하는 열쇠\"라고 강조했습니다. 현재의 AI 모델 개발은 엄청난 양의 데이터를 수집하고 이를 강력한 컴퓨팅 파워와 결합해 통계적 상관관계를 개선하는 스케일링 법칙에 의존하고 있다고 설명했습니다. 최근 구글의 '제미나이 3' 발전이 스케일링이 아직 유효하다는 근거로 통하고 있지만, 근본적으로 모델이 언어를 기반으로 하는 한 한계가 있다는 지적입니다. 즉, 인간은 생각하기 위해 언어를 사용하지만, 그렇다고 해서 언어가 생각과 같은 것은 아니라는 말입니다. 그 예로 지난해 MIT와 UC 버클리의 과학자 3명이 네이처에 발표한 논문을 근거로 들었습니다. ' 언어는 사고보다는 의사소통을 위한 도구 '라는 이 연구는 언어가 사고와 추론 능력을 낳는다는 관념을 무너뜨리고, 언어가 우리가 서로 생각을 공유하는 데 사용하는 '문화적 도구'로 진화했다는 점을 강조합니다. 그리고 몇가지 증거를 제시했습니다. 그중 하나는 기능적 자기공명영상(fMRI)을 사용해 우리가 다양한 정신 활동을 할 때 뇌의 여러 부분이 활성화되는 것을 확인한 결과입니다. 수학 문제를 푸는 등 다양한 인지 활동을 할 때, 우리 뇌에서 활성화되는 부분은 언어 능력을 활성화하는 부분과 다르다는 것입니다. 또 뇌 손상이나 기타 질환으로 언어 능력을 상실한 사람이라도 전반적인 사고 능력은 근본적으로 손상되지 않았다는 점을 들었습니다. 말을 제대로 하지 못하는 아기라도 생각을 통해 세상을 빠르게 배웁니다. 이처럼 언어는 인간 사고의 한 측면일 뿐이며, 우리 지능의 상당 부분은 비언어적 능력과 관련이 있다는 것입니다. 그럼에도 많은 사람이 언어와 지능을 연관하는 것은 '생각을 공유하는 도구'로 사용되기 때문으로 봤습니다. 인간은 하나의 종으로서 언어를 사용해 현재와 세대를 거쳐 지식을 공유함으로써 이점을 얻는데, 인지 과학자 세실리아 헤이즈는 이런 관점에서 언어를 '인지 도구(Cognitive Tool)'라고 부릅니다. 즉, 우리의 인지는 언어 덕분에 향상되지만, 언어에 의해 만들어지거나 정의되는 것은 아니라는 말입니다. 인간은 말하는 능력을 빼앗긴다 해도 여전히 생각하고, 추론하고, 믿음을 형성하고, 사랑에 빠지고, 세상을 돌아다닐 수 있습니다. 우리가 경험하고 생각할 수 있는 범위는 여전히 엄청나다는 것입니다. 그는 \"하지만 LLM에서 언어를 제거하면, 아무것도 남지 않는다\"라고 말했습니다. 저명한 AI 연구자들도 같은 주장을 한다고 전했습니다. '월드 모델'이 이런 문제를 보완할 것이라고 주장하는 얀 르쿤 메타 수석과학자를 비롯해, 요슈아 벤지오 몬트리올대학교 교수, 에릭 슈미트 전 구글 CEO, 그리고 AI 회의론자로 유명한 게리 마커스 뉴욕대학교 교수 등의 말을 인용했습니다. 또 최근 AI 안전센터(Center for AI Safety) 등의 연구진이 발표한 논문을 인용헸습니다. 이들은 'GPT-4'와 'GPT-5'를 속도와 지식, 읽기 및 쓰기, 수학, 추론, 작업 기억, 기억 저장, 기억 검색, 시각 및 청각 등의 항목으로 비교했습니다. 그 결과로 작성한 그래프에는 지식과 읽기 및 쓰기, 수학, 추론 등 일부 항목에서만 진전을 이뤘거나 능력을 보일 분, 나머지에서는 거의 능력이 없는 것으로 나타났습니다. 이런 형태로는 초지능에 도달한다는 것이 무슨 의미냐는 것입니다. (사진=Center for AI Safety) 그리고 그래프 전체에서 뛰어난 성능을 보이는 모델을 어찌어찌 개발한다고 해도, 마지막 장애물'이 있다고 봤습니다. 인간의 사고방식을 복제한다고 해서, AI 시스템이 인류가 달성한 인지적 도약을 이룰 수 있다는 보장은 없다는 말입니다. 즉, 과학적인 발전은 기존 상식의 답습을 넘어, 패러다임의 변화가 일어날 때 가능하다는 말입니다. 이는 경험을 넘는, 새로운 질문과 아이디어를 통한 것인데, 아인슈타인의 상대성 원리를 그 예로 들었습니다. 결국 \"AI는 결국 '상식 저장소'에 불과하게 될 것\"이라고 결론 내렸습니다. \"AI는 우리가 데이터에 인코딩하고 학습한 어휘에 영원히 갇혀, 마치 '죽은 은유 기계(Dead Metaphor Machine)'처럼 될 것\"이라며 \"그리고 생각하고 추론하며 언어를 사용하여 서로의 생각을 전달하는 실제 인간은 세상에 대한 우리의 이해를 변화시키는 최전선에 서게 될 것\"이라고 강조했습니다. 이 칼럼이 눈길을 끄는 것은 최근 다시 스케일링이나 트랜스포머 아키텍처의 대안, 그리고 메타 러닝(meta learning) 등이 활발하게 거론되기 때문입니다. 사티아 나델라 마이크로소프트 CEO 는 지난달 29일 악셀 슈프링거와의 인터뷰에서 \"현재 AI는 '모방 게임(imitation game)'에 가깝다\"라고 지적했습니다. 이는 '죽은 은유 기계'와 비슷한 설명입니다. 또 \"지식(Knowledge)과 인지 핵심(Cognitive Core)을 분리해 학습 알고리즘 자체를 익히는 것이 다음 과학적 돌파구가 될 것\"이라고 예상했습니다. 이는 최근 강조되는 메타 러닝을 말합니다. 메타 러닝이란 단순히 지식을 익히는 것이 아니라, 학습하는 방법을 배우는 것(Learning to Learn)을 말합니다. 싱킹 머신 랩 도 인공일반지능(AGI)에 도달하려면, 메타 러닝이 필요하다고 최근 밝혔습니다. 여기에 1일 월스트리트 저널 은 패스웨이(Pathway)라는 스타트업이 '포스트-트랜스포머' 시대를 준비 중이라고 보도했습니다. 저명한 연구자들로 구성된 이 회사는 '대규모 병렬 포스트-트랜스포머 추론 아키텍처(Massively Parallel Post-Transformer Reasoning Architecture)'를 개발 중입니다. 이 아키텍처는 단순히 데이터를 암기하거나 패턴을 모방하는 것을 넘어, 지속적이고 맥락적인 추론 능력을 구축하는 것이 목표입니다. 이를 통해 AI가 인간처럼 '시간에 걸친 일반화' 능력을 갖출 수 있다는 것입니다. 특히 ' 트랜스포머와 뇌 모델 사이의 잃어버린 연결고리 '라는 논문을 발표했습니다. 이는 나델라 CEO가 언급했던 '인지 핵심'을 찾는 법처럼, AI를 인간의 인지 방식에 더 가깝게 설계하려는 의도를 담고 있습니다. 결국, 트랜스포머 기반의 현재 AI가 가진 모방 게임의 한계를 인정하고, 새로운 학습 알고리즘을 개발해 인간 수준의 일반화와 추론 능력을 갖추려는 메타 학습의 비전과 일치하는 것입니다. 현재 AI 모델은 3년 전 챗GPT의 등장 이후 언어 모델과 트랜스포머라는 기본 축으로 거의 정점에 달했다고 보는 전문가가 많습니다. 초지능을 이루기 위해서는 이상이 필요하다는 지적은 이제부터 본격적으로 등장할 것으로 보입니다. 이어 1일 주요 뉴스입니다. ■ 소라·나노 바나나 프로, 수요 급증으로 일일 한도 줄여 오픈AI와 구글이 각각 인기 서비스인 '소라'와 '나노 바나나'의 무료 사용량을 줄이고 있습니다. 오픈A에 이어 구글도 최근 인기 급증에 따라 컴퓨팅 인프라가 버티지 못할 수준에 달한 것으로 볼 수 있습니다. 이 서비스들은 결국 유료 모델로 굳어질 가능성이 높아지고 있습니다. (사진=알리바바) ■ 알리바바, 60억 매개변수의 강력한 'Z-이미지' 출시 PC에서 게임용 GPU로도 구동할 수 있는 이미지 모델이 등장했습니다. 그러면서도 이미지 퀄리티는 나노 바나나 등과 맞먹는다는 설명입니다. 알리바바도 \"미쳤다\"라는 평을 받고 있습니다. ■ 오픈AI 연구원 \"고교 중퇴 후 챗GPT로 머신 러닝 배워...박사급들과 연구 중\" 챗GPT로 독학, 코딩을 넘어 AI 전문가로 오픈AI에서 연구원 활동을 하는 사례가 공개됐습니다. 그는 대학과 같은 단계적 학습법이 아니라, 일단 실제 문제에 부딪힌 뒤 이를 해결하는 과정에서 AI를 통해 원리를 파악하는 방식을 사용했다고 밝혔습니다. AI타임스 news@aitimes.com",
  "url": "https://www.aitimes.com/news/articleView.html?idxno=204431",
  "article_id": "e34440",
  "cached_at": "2025-12-17T15:05:22.335608+00:00",
  "version": "V1.0"
}