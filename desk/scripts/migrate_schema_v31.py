# -*- coding: utf-8 -*-
"""
Schema v3.1 Migration Script
ê¸°ì¡´ ìºì‹œ íŒŒì¼ì˜ url, source_idë¥¼ _headerë¡œ ì´ë™

Usage:
    python scripts/migrate_schema_v31.py
    python scripts/migrate_schema_v31.py --dry-run  # í…ŒìŠ¤íŠ¸ ëª¨ë“œ
"""
import os
import sys
import json
import glob
from datetime import datetime

# Add project root to path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

CACHE_DIR = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), 'cache')


def migrate_article(data: dict) -> tuple[dict, bool]:
    """
    ë‹¨ì¼ ê¸°ì‚¬ ë°ì´í„°ë¥¼ v3.1ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜
    
    Returns:
        (migrated_data, was_modified)
    """
    header = data.get('_header', {})
    original = data.get('_original', {})
    
    modified = False
    
    # ì´ë¯¸ v3.1ì´ë©´ ìŠ¤í‚µ
    if header.get('version') == '3.1':
        return data, False
    
    # urlì„ _headerë¡œ ì´ë™
    if 'url' not in header and 'url' in original:
        header['url'] = original['url']
        modified = True
    
    # source_idë¥¼ _headerë¡œ ì´ë™
    if 'source_id' not in header and 'source_id' in original:
        header['source_id'] = original['source_id']
        modified = True
    
    # article_idê°€ ì—†ìœ¼ë©´ URLì—ì„œ ìƒì„±
    if 'article_id' not in header:
        url = header.get('url') or original.get('url')
        if url:
            import hashlib
            article_id = hashlib.md5(url.encode()).hexdigest()[:12]
            header['article_id'] = article_id
            modified = True
    
    # ë²„ì „ ì—…ë°ì´íŠ¸
    if modified:
        header['version'] = '3.1'
        data['_header'] = header
    
    return data, modified


def migrate_cache_files(dry_run: bool = False):
    """
    ìºì‹œ ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  JSON íŒŒì¼ì„ ë§ˆì´ê·¸ë ˆì´ì…˜
    """
    if not os.path.exists(CACHE_DIR):
        print(f"âŒ Cache directory not found: {CACHE_DIR}")
        return
    
    # ëª¨ë“  .json íŒŒì¼ ì°¾ê¸°
    pattern = os.path.join(CACHE_DIR, '**', '*.json')
    files = glob.glob(pattern, recursive=True)
    
    print(f"ğŸ“‚ Found {len(files)} cache files")
    print(f"{'ğŸ” DRY RUN MODE' if dry_run else 'ğŸ”§ MIGRATION MODE'}")
    print("-" * 50)
    
    migrated_count = 0
    skipped_count = 0
    error_count = 0
    
    for filepath in files:
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # ë§ˆì´ê·¸ë ˆì´ì…˜ ìˆ˜í–‰
            migrated_data, was_modified = migrate_article(data)
            
            if was_modified:
                if not dry_run:
                    with open(filepath, 'w', encoding='utf-8') as f:
                        json.dump(migrated_data, f, ensure_ascii=False, indent=2)
                
                article_id = migrated_data.get('_header', {}).get('article_id', 'unknown')
                print(f"âœ… {'Would migrate' if dry_run else 'Migrated'}: {article_id}")
                migrated_count += 1
            else:
                skipped_count += 1
                
        except json.JSONDecodeError as e:
            print(f"âš ï¸ JSON Error in {filepath}: {e}")
            error_count += 1
        except Exception as e:
            print(f"âŒ Error in {filepath}: {e}")
            error_count += 1
    
    print("-" * 50)
    print(f"ğŸ“Š Results:")
    print(f"   âœ… Migrated: {migrated_count}")
    print(f"   â­ï¸ Skipped (already v3.1): {skipped_count}")
    print(f"   âŒ Errors: {error_count}")
    
    if dry_run:
        print(f"\nğŸ’¡ Run without --dry-run to apply changes")


def main():
    dry_run = '--dry-run' in sys.argv
    
    print("=" * 50)
    print("  Schema v3.1 Migration")
    print(f"  Cache Dir: {CACHE_DIR}")
    print("=" * 50)
    
    migrate_cache_files(dry_run=dry_run)


if __name__ == '__main__':
    main()
