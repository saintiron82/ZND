# -*- coding: utf-8 -*-
"""
ì¡°íŒ(Desk) API - ê¸°ì‚¬ ê´€ë¦¬, ê±°ë¶€/ë³µêµ¬, ì¹´í…Œê³ ë¦¬ ì—…ë°ì´íŠ¸ ë“±
"""
import os
import json
import shutil
from datetime import datetime, timezone
from flask import Blueprint, request, jsonify, render_template
from dotenv import load_dotenv

# ê³µí†µ ì¸ì¦ ëª¨ë“ˆ
from src.routes.auth import requires_auth

# Load environment variables (ëª…ì‹œì  ê²½ë¡œ ì§€ì •)
env_path = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), '.env')
load_dotenv(env_path)

desk_bp = Blueprint('desk', __name__)

CACHE_DIR = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), 'cache')


@desk_bp.route('/desk')
@desk_bp.route('/')
@requires_auth
def desk_view():
    """Staging ë¯¸ë¦¬ë³´ê¸° í˜ì´ì§€ (ê´€ë¦¬ì ì „ìš©)"""
    return render_template('desk.html', active='desk')


from src.trash_manager import TrashManager

# Initialize TrashManager
trash_manager = None  # Will be initialized with CACHE_DIR

@desk_bp.route('/api/desk/list')
@requires_auth
def desk_list():
    """Cache í´ë”ì˜ ê¸°ì‚¬ ëª©ë¡ ë°˜í™˜ (ì¡°íŒ UIìš©) - ë¯¸ë¶„ì„ ê¸°ì‚¬ë„ í¬í•¨"""
    global trash_manager
    if trash_manager is None:
        trash_manager = TrashManager(CACHE_DIR)

    try:
        date_str = request.args.get('date', datetime.now().strftime('%Y-%m-%d'))
        include_published = request.args.get('include_published', 'false').lower() == 'true'
        include_trash = request.args.get('include_trash', 'false').lower() == 'true'
        include_unanalyzed = request.args.get('include_unanalyzed', 'false').lower() == 'true'
        
        # [NEW] ì‹œê°„ ë²”ìœ„ íŒŒë¼ë¯¸í„° (Inspectorì™€ ë™ê¸°í™”)
        hours_param = request.args.get('hours', '0')
        try:
            filter_hours = int(hours_param)
        except:
            filter_hours = 0
        
        cutoff_time = None
        if filter_hours > 0:
            from datetime import timedelta
            cutoff_time = datetime.now(timezone.utc) - timedelta(hours=filter_hours)
        
        # [MODIFIED] Support 'all' date for Global Staging View
        is_all_dates = (date_str == 'all')
        
        files_to_process = []
        if is_all_dates:
            import glob
            # Inspectorì™€ ë™ì¼í•˜ê²Œ ëª¨ë“  í•˜ìœ„ í´ë” ê²€ìƒ‰
            # êµ¬ì¡°: desk/cache/YYYY-MM-DD/*.json OR desk/cache/*.json
            search_pattern = os.path.join(CACHE_DIR, '**', '*.json')
            files_to_process = glob.glob(search_pattern, recursive=True)
        else:
            cache_date_dir = os.path.join(CACHE_DIR, date_str)
            if os.path.exists(cache_date_dir):
                files_to_process = [os.path.join(cache_date_dir, f) for f in os.listdir(cache_date_dir) if f.endswith('.json')]
        
        articles = []
        unanalyzed_count = 0  # [NEW] ë¯¸ë¶„ì„ ê¸°ì‚¬ ì¹´ìš´í„°
        
        # [NEW] Firebaseì—ì„œ ë°œí–‰ëœ article_ids ì¡°íšŒ (ë™ê¸°í™”)
        published_article_ids = set()
        skip_firebase_sync = os.getenv('DESK_SKIP_FIREBASE_SYNC', 'false').lower() == 'true'
        if not include_published and not skip_firebase_sync:
            try:
                from src.published_articles import get_published_article_ids
                published_article_ids = get_published_article_ids()
                print(f"ğŸ”— [Desk] Firebase sync: {len(published_article_ids)} published IDs loaded")
            except Exception as e:
                pass
        
        for filepath in files_to_process:
            try:
                filename = os.path.basename(filepath)
                # Skip batch files if any
                if 'batch_' in filename: continue

                with open(filepath, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                
                # [CRITICAL FILTER] ë¨¼ì € ìƒíƒœ ì²´í¬
                is_published = data.get('published', False)
                is_rejected = data.get('rejected', False)
                is_saved = data.get('saved', False)  # [NEW] Staged ìƒíƒœ (Inspector ê¸°ì¤€ ACCEPTED)
                dedup_status = data.get('dedup_status')
                
                # Firebase Sync
                article_id = data.get('article_id', '')
                if article_id and article_id in published_article_ids:
                    is_published = True
                
                # ì™„ë£Œëœ ê¸°ì‚¬(ë°œí–‰/ê±°ë¶€/ì¤‘ë³µ/ì €ì¥ë¨)ëŠ” ë¯¸ë¶„ì„ ì¹´ìš´íŠ¸ì—ì„œ ì œì™¸í•´ì•¼ í•¨
                is_completed = is_published or is_rejected or is_saved or (dedup_status == 'duplicate')
                
                # ë¶„ì„ ìƒíƒœ ì²´í¬
                is_analyzed = (
                    data.get('mll_status') == 'analyzed' or
                    data.get('raw_analysis') is not None or
                    data.get('zero_echo_score') is not None
                )
                
                # [FIX Logic] ì™„ë£Œë˜ì§€ ì•Šì€ ê¸°ì‚¬ ì¤‘ ë¶„ì„ì´ ì•ˆ ëœ ê²ƒë§Œ ì¹´ìš´íŠ¸
                if not is_completed and not is_analyzed:
                    unanalyzed_count += 1
                    if not include_unanalyzed:
                        continue # ì¹´ìš´íŠ¸ë§Œ í•˜ê³  ëª©ë¡ì—” ì•ˆ ë„£ìŒ
                
                # 1. Trash Filter (ê±°ë¶€ëœ ê¸°ì‚¬)
                if not include_trash and is_rejected:
                    continue
                    
                # 2. Published Filter
                if not include_published and is_published:
                    continue

                # [NEW] 3. ì‹œê°„ ë²”ìœ„ í•„í„°ë§ (Inspectorì™€ ë™ê¸°í™”)
                if cutoff_time:
                    crawled_at_str = data.get('crawled_at') or data.get('cached_at') or data.get('saved_at')
                    if crawled_at_str:
                        try:
                            crawled_at = datetime.fromisoformat(crawled_at_str.replace('Z', '+00:00'))
                            if crawled_at.tzinfo is None:
                                crawled_at = crawled_at.replace(tzinfo=timezone.utc)
                            if crawled_at < cutoff_time:
                                continue  # ì‹œê°„ ë²”ìœ„ ë°–
                        except:
                            pass  # íŒŒì‹± ì‹¤íŒ¨ ì‹œ í¬í•¨

                articles.append({
                    'filename': filename,
                    'filepath': filepath,
                    'article_id': data.get('article_id', ''),
                    'url': data.get('url', ''),
                    'title': data.get('title', ''),
                    'title_ko': data.get('title_ko', ''),
                    'summary': data.get('summary', ''),
                    'zero_echo_score': data.get('zero_echo_score'),
                    'impact_score': data.get('impact_score'),
                    'source_id': data.get('source_id', ''),
                    'rejected': is_rejected,
                    'reject_reason': data.get('reject_reason', ''),
                    'published': is_published,
                    'publish_id': data.get('publish_id', ''),
                    'edition_name': data.get('edition_name', ''),
                    'staged_at': data.get('staged_at', ''),
                    'dedup_status': data.get('dedup_status'),
                    'category': data.get('category'),
                    'status': data.get('status', ''),
                    'mll_status': data.get('mll_status', ''),
                    'date_folder': os.path.basename(os.path.dirname(filepath)),
                    'crawled_at': data.get('crawled_at') or data.get('cached_at') or data.get('saved_at') or data.get('staged_at') or datetime.now().isoformat()
                })
            except Exception as e:
                pass
        
        # ì •ë ¬: ëŒ€ê¸°ì¤‘ â†’ ë°œí–‰ë¨ â†’ ê±°ë¶€ë¨, ë‚ ì§œ ë‚´ë¦¼ì°¨ìˆœ
        articles.sort(key=lambda x: (
            2 if not x['published'] and not x['rejected'] else (1 if x['published'] else 0),
            x.get('crawled_at', '')
        ), reverse=True)
        
        return jsonify({
            'date': date_str,
            'articles': articles,
            'total': len(articles),
            'unanalyzed_count': unanalyzed_count
        })
    except Exception as e:
        print(f"âŒ [Staging List] Error: {e}")
        return jsonify({'error': str(e)}), 500


@desk_bp.route('/api/desk/reject_selected', methods=['POST'])
@requires_auth
def desk_reject_selected():
    """ğŸ—‘ï¸ ì„ íƒëœ ê¸°ì‚¬ ì¼ê´„ ê±°ë¶€ (Reject)"""
    try:
        data = request.json or {}
        date_str = data.get('date') or datetime.now().strftime('%Y-%m-%d')
        filenames = data.get('filenames', [])
        
        if not filenames:
            return jsonify({'success': False, 'error': 'No filenames provided'}), 400
            
        cache_date_dir = os.path.join(CACHE_DIR, date_str)
        count = 0
        
        for filename in filenames:
            filepath = os.path.join(cache_date_dir, filename)
            
            # [MODIFIED] If not found in target dir (or date='all'), search all folders
            if not os.path.exists(filepath):
                found_path = None
                if os.path.exists(CACHE_DIR):
                    for d in os.listdir(CACHE_DIR):
                        possible_path = os.path.join(CACHE_DIR, d, filename)
                        if os.path.exists(possible_path):
                            found_path = possible_path
                            break
                
                if found_path:
                    filepath = found_path
                else:
                    print(f"âš ï¸ Reject skip: {filename} not found")
                    continue
                
            try:
                with open(filepath, 'r', encoding='utf-8') as f:
                    article_data = json.load(f)
                
                article_data['rejected'] = True
                article_data['reject_reason'] = 'manual_batch_reject'
                
                with open(filepath, 'w', encoding='utf-8') as f:
                    json.dump(article_data, f, ensure_ascii=False, indent=2)
                count += 1
            except Exception as e:
                print(f"âš ï¸ Reject error {filename}: {e}")
                
        return jsonify({
            'success': True,
            'message': f"{count}ê°œ ê¸°ì‚¬ ê±°ë¶€ ì²˜ë¦¬ ì™„ë£Œ"
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


@desk_bp.route('/api/desk/restore_selected', methods=['POST'])
@requires_auth
def desk_restore_selected():
    """â™»ï¸ ì„ íƒëœ ê¸°ì‚¬ ë³µêµ¬ (Restore rejected articles)"""
    try:
        data = request.json or {}
        date_str = data.get('date') or datetime.now().strftime('%Y-%m-%d')
        filenames = data.get('filenames', [])
        
        if not filenames:
            return jsonify({'success': False, 'error': 'No filenames provided'}), 400
            
        cache_date_dir = os.path.join(CACHE_DIR, date_str)
        count = 0
        
        for filename in filenames:
            filepath = os.path.join(cache_date_dir, filename)
            if not os.path.exists(filepath):
                # ë‹¤ë¥¸ ë‚ ì§œì—ë„ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ê²€ìƒ‰
                for date_folder in os.listdir(CACHE_DIR):
                    check_path = os.path.join(CACHE_DIR, date_folder, filename)
                    if os.path.exists(check_path):
                        filepath = check_path
                        break
                        
            if not os.path.exists(filepath):
                continue
                
            try:
                with open(filepath, 'r', encoding='utf-8') as f:
                    article_data = json.load(f)
                
                # ê±°ë¶€ ìƒíƒœ í•´ì œ
                article_data['rejected'] = False
                if 'reject_reason' in article_data:
                    del article_data['reject_reason']
                
                with open(filepath, 'w', encoding='utf-8') as f:
                    json.dump(article_data, f, ensure_ascii=False, indent=2)
                count += 1
                print(f"â™»ï¸ [Restore] ë³µêµ¬ë¨: {filename}")
            except Exception as e:
                print(f"âš ï¸ Restore error {filename}: {e}")
                
        return jsonify({
            'success': True,
            'message': f"{count}ê°œ ê¸°ì‚¬ ë³µêµ¬ ì™„ë£Œ"
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


@desk_bp.route('/api/desk/file')
@requires_auth
def desk_file():
    """íŠ¹ì • Staging íŒŒì¼ ìƒì„¸ ë‚´ìš© ë°˜í™˜"""
    try:
        date_str = request.args.get('date', datetime.now().strftime('%Y-%m-%d'))
        filename = request.args.get('filename')
        
        if not filename:
            return jsonify({'error': 'filename is required'}), 400
        
        # 1. Try specified date first
        filepath = os.path.join(CACHE_DIR, date_str, filename)
        
        # 2. If 'all' or not found, search in all date folders
        if date_str == 'all' or not os.path.exists(filepath):
            found_path = None
            if os.path.exists(CACHE_DIR):
                for d in os.listdir(CACHE_DIR):
                    possible_path = os.path.join(CACHE_DIR, d, filename)
                    if os.path.exists(possible_path):
                        found_path = possible_path
                        break
            
            if found_path:
                filepath = found_path
            else:
                return jsonify({'error': 'File not found'}), 404
        
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
            
            # [Add] Inject current folder date if needed for UI context
            # data['_folder_date'] = os.path.basename(os.path.dirname(filepath))
        
        return jsonify(data)
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@desk_bp.route('/api/desk/update_categories', methods=['POST'])
@requires_auth
def desk_update_categories():
    """ì¹´í…Œê³ ë¦¬ ì •ë³´ë¥¼ ëª¨ë“  ë‚ ì§œ í´ë”ì˜ ìºì‹œì— ì €ì¥"""
    try:
        data = request.json or {}
        category_results = data.get('results', [])
        sent_ids = set(data.get('sent_ids', []))
        
        # article_id -> category ë§µ êµ¬ì¶•
        category_map = {}
        for group in category_results:
            category = group.get('category', 'ë¯¸ë¶„ë¥˜')
            for article_id in group.get('article_ids', []):
                category_map[article_id] = category
        
        updated_count = 0
        uncategorized_count = 0
        
        if not os.path.exists(CACHE_DIR):
            return jsonify({'success': False, 'error': 'Cache directory not found'}), 404
        
        for date_folder in os.listdir(CACHE_DIR):
            cache_date_dir = os.path.join(CACHE_DIR, date_folder)
            if not os.path.isdir(cache_date_dir):
                continue
            
            for filename in os.listdir(cache_date_dir):
                if not filename.endswith('.json'):
                    continue
                
                filepath = os.path.join(cache_date_dir, filename)
                try:
                    with open(filepath, 'r', encoding='utf-8') as f:
                        article_data = json.load(f)
                    
                    # filenameì—ì„œ article_id ì¶”ì¶œ
                    parts = filename.replace('.json', '').split('_')
                    article_id = parts[-1] if len(parts) > 1 else parts[0]
                    stored_article_id = article_data.get('article_id') or article_id
                    
                    is_in_result = stored_article_id in category_map or article_id in category_map
                    is_in_scope = not sent_ids or (stored_article_id in sent_ids or article_id in sent_ids)
                    
                    if not is_in_result and not is_in_scope:
                        continue
                    
                    if is_in_result:
                        cat = category_map.get(stored_article_id) or category_map.get(article_id, 'ë¯¸ë¶„ë¥˜')
                        article_data['category'] = cat
                        article_data['dedup_status'] = 'selected'
                    else:
                        article_data['dedup_status'] = 'duplicate'
                        uncategorized_count += 1
                    
                    with open(filepath, 'w', encoding='utf-8') as f:
                        json.dump(article_data, f, ensure_ascii=False, indent=2)
                    
                    updated_count += 1
                    
                except Exception as e:
                    print(f"âš ï¸ [Update Category] Error on {filename}: {e}")
        
        return jsonify({
            'success': True,
            'updated': updated_count,
            'uncategorized': uncategorized_count,
            'message': f'{updated_count}ê°œ ê¸°ì‚¬ ì¹´í…Œê³ ë¦¬ ì—…ë°ì´íŠ¸ ì™„ë£Œ'
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


@desk_bp.route('/api/desk/reset_dedup', methods=['POST'])
@requires_auth
def desk_reset_dedup():
    """ëª¨ë“  staging íŒŒì¼ì˜ dedup_statusì™€ category ì´ˆê¸°í™”"""
    try:
        data = request.json or {}
        date_str = data.get('date') or datetime.now().strftime('%Y-%m-%d')
        
        cache_date_dir = os.path.join(CACHE_DIR, date_str)
        
        if not os.path.exists(cache_date_dir):
            return jsonify({'success': False, 'error': 'Staging folder not found'}), 404
        
        reset_count = 0
        
        for filename in os.listdir(cache_date_dir):
            if not filename.endswith('.json'):
                continue
            
            filepath = os.path.join(cache_date_dir, filename)
            try:
                with open(filepath, 'r', encoding='utf-8') as f:
                    article_data = json.load(f)
                
                if 'dedup_status' in article_data:
                    del article_data['dedup_status']
                if 'category' in article_data:
                    del article_data['category']
                
                with open(filepath, 'w', encoding='utf-8') as f:
                    json.dump(article_data, f, ensure_ascii=False, indent=2)
                
                reset_count += 1
                
            except Exception as e:
                print(f"âš ï¸ [Reset Dedup] Error on {filename}: {e}")
        
        return jsonify({
            'success': True,
            'reset': reset_count,
            'message': f'{reset_count}ê°œ ê¸°ì‚¬ ì¤‘ë³µ ìƒíƒœ ì´ˆê¸°í™” ì™„ë£Œ'
        })
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


@desk_bp.route('/api/desk/delete_permanent', methods=['POST'])
@requires_auth
def desk_delete_permanent():
    """ğŸ—‘ï¸ ì„ íƒëœ ê¸°ì‚¬ ì˜êµ¬ ì‚­ì œ (DB Reject + File Delete)"""
    global trash_manager
    if trash_manager is None:
        trash_manager = TrashManager(CACHE_DIR)
        
    try:
        data = request.json or {}
        filename = data.get('filename')
        date_str = data.get('date') or datetime.now().strftime('%Y-%m-%d')
        
        if not filename:
            return jsonify({'success': False, 'error': 'filename required'})
            
        # 1. Get URL from file to reject it in DB
        filepath = os.path.join(CACHE_DIR, date_str, filename)
        url = None
        
        if os.path.exists(filepath):
            try:
                with open(filepath, 'r', encoding='utf-8') as f:
                    file_data = json.load(f)
                    url = file_data.get('url')
            except Exception as e:
                print(f"âš ï¸ Failed to read file for URL extraction: {e}")
        
        if not url:
             return jsonify({'success': False, 'error': 'Cannot find file or URL to reject'})

        # 2. Use TrashManager to dispose
        result = trash_manager.dispose_items([url])
        
        return jsonify(result)

    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


@desk_bp.route('/api/desk/delete_file', methods=['POST'])
@requires_auth
def desk_delete_file():
    """staging íŒŒì¼ ì™„ì „ ì‚­ì œ"""
    try:
        data = request.json or {}
        filename = data.get('filename')
        date_str = data.get('date') or datetime.now().strftime('%Y-%m-%d')
        
        if not filename:
            return jsonify({'success': False, 'error': 'filename required'})
        
        deleted = False
        
        staging_file = os.path.join(CACHE_DIR, date_str, filename)
        if os.path.exists(staging_file):
            os.remove(staging_file)
            deleted = True
        
        if not deleted:
            for date_folder in os.listdir(CACHE_DIR):
                check_path = os.path.join(CACHE_DIR, date_folder, filename)
                if os.path.exists(check_path):
                    os.remove(check_path)
                    deleted = True
                    break
        
        if deleted:
            return jsonify({'success': True, 'message': f'{filename} ì‚­ì œ ì™„ë£Œ'})
        else:
            return jsonify({'success': False, 'error': f'{filename} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'})
    
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


@desk_bp.route('/api/desk/clear_cache', methods=['POST'])
@requires_auth
def desk_clear_cache():
    """ë‚ ì§œë³„ ìºì‹œ ì‚­ì œ"""
    try:
        data = request.json or {}
        date_str = data.get('date')
        
        if not date_str:
            return jsonify({'success': False, 'error': 'date required'})
        
        deleted_count = 0
        
        cache_date_path = os.path.join(CACHE_DIR, date_str)
        if os.path.exists(cache_date_path) and os.path.isdir(cache_date_path):
            file_count = len([f for f in os.listdir(cache_date_path) if f.endswith('.json')])
            shutil.rmtree(cache_date_path)
            deleted_count = file_count
        
        if deleted_count > 0:
            return jsonify({'success': True, 'message': f'{date_str} ìºì‹œ {deleted_count}ê°œ íŒŒì¼ ì‚­ì œ ì™„ë£Œ'})
        else:
            return jsonify({'success': True, 'message': f'{date_str} ìºì‹œê°€ ì—†ê±°ë‚˜ ì´ë¯¸ ì‚­ì œë¨'})
    
    except Exception as e:
        return jsonify({'success': False, 'error': str(e)}), 500


@desk_bp.route('/api/desk/settings', methods=['GET'])
@requires_auth
def desk_settings():
    """ğŸ“‹ Desk í™˜ê²½ ì„¤ì • ì¡°íšŒ (ì»¤íŠ¸ë¼ì¸ ê¸°ë³¸ê°’ ë“±)"""
    return jsonify({
        'success': True,
        'cutline_is_default': float(os.getenv('CUTLINE_IS_DEFAULT', 6.5)),
        'cutline_zs_default': float(os.getenv('CUTLINE_ZS_DEFAULT', 3.0))
    })
