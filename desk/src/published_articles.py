# -*- coding: utf-8 -*-
"""
ë°œí–‰ëœ ê¸°ì‚¬ ì¡°íšŒ ìœ í‹¸ë¦¬í‹°
- Firebase publications ì»¬ë ‰ì…˜ì—ì„œ ë°œí–‰ëœ article_ids ì¡°íšŒ
- ìºì‹±ì„ í†µí•´ ë°˜ë³µ ì¡°íšŒ ìµœì†Œí™”
"""
from datetime import datetime, timezone, timedelta

# ìºì‹œ (ë©”ëª¨ë¦¬)
_published_ids_cache = None
_published_urls_cache = None
_cache_updated_at = None
_CACHE_TTL_SECONDS = 300  # 5ë¶„ ìºì‹œ


def get_db():
    """DB í´ë¼ì´ì–¸íŠ¸ ê°€ì ¸ì˜¤ê¸° (ì§€ì—° ì„í¬íŠ¸)"""
    from src.pipeline import get_db as pipeline_get_db
    return pipeline_get_db()


def get_published_article_ids(force_refresh: bool = False) -> set:
    """
    Firebase publications ì»¬ë ‰ì…˜ì—ì„œ ë°œí–‰ëœ ëª¨ë“  article_id ì¡°íšŒ
    
    Args:
        force_refresh: Trueë©´ ìºì‹œ ë¬´ì‹œí•˜ê³  ìƒˆë¡œ ì¡°íšŒ
        
    Returns:
        set[str]: ë°œí–‰ëœ article_id ì§‘í•©
    """
    global _published_ids_cache, _cache_updated_at
    
    # ìºì‹œ ìœ íš¨ì„± ì²´í¬
    now = datetime.now(timezone.utc)
    if not force_refresh and _published_ids_cache is not None and _cache_updated_at:
        if (now - _cache_updated_at).total_seconds() < _CACHE_TTL_SECONDS:
            return _published_ids_cache
    
    db = get_db()
    if not db or not db.db:
        print("âš ï¸ [PublishedArticles] DB not connected")
        return _published_ids_cache or set()
    
    try:
        published_ids = set()
        
        # publications ì»¬ë ‰ì…˜ì—ì„œ ëª¨ë“  ë¬¸ì„œ ì¡°íšŒ
        docs = db.db.collection('publications').stream()
        
        for doc in docs:
            data = doc.to_dict()
            # released ìƒíƒœì¸ ê²ƒë§Œ ëŒ€ìƒ
            if data.get('status') != 'released':
                continue
                
            # article_ids ë°°ì—´ì—ì„œ ID ì¶”ì¶œ
            article_ids = data.get('article_ids', [])
            if article_ids:
                published_ids.update(article_ids)
            
            # í•˜ìœ„ í˜¸í™˜: articles ë°°ì—´ì—ì„œë„ ID ì¶”ì¶œ
            articles = data.get('articles', [])
            for art in articles:
                if art.get('id'):
                    published_ids.add(art['id'])
        
        _published_ids_cache = published_ids
        _cache_updated_at = now
        
        print(f"âœ… [PublishedArticles] Loaded {len(published_ids)} published article IDs")
        return published_ids
        
    except Exception as e:
        print(f"âŒ [PublishedArticles] Error: {e}")
        return _published_ids_cache or set()


def is_article_published(article_id: str) -> bool:
    """
    íŠ¹ì • ê¸°ì‚¬ê°€ ì´ë¯¸ ë°œí–‰ë˜ì—ˆëŠ”ì§€ í™•ì¸
    
    Args:
        article_id: í™•ì¸í•  ê¸°ì‚¬ ID
        
    Returns:
        bool: ë°œí–‰ ì—¬ë¶€
    """
    published_ids = get_published_article_ids()
    return article_id in published_ids


def invalidate_cache():
    """ìºì‹œ ê°•ì œ ë¬´íš¨í™” (ë°œí–‰ í›„ í˜¸ì¶œ)"""
    global _published_ids_cache, _published_urls_cache, _cache_updated_at
    _published_ids_cache = None
    _published_urls_cache = None
    _cache_updated_at = None
    print("ğŸ”„ [PublishedArticles] Cache invalidated")
