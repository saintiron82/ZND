{
  "title": "AI 스케일링 논쟁 재점화: 제미나이 3와 새로운 연구 시대",
  "summary": "일리아 수츠케버 창립자가 스케일링 법칙의 종말을 선언한 지 1년 만에 구글의 제미나이 3가 성능 향상 비결로 사전 훈련과 사후 훈련 개선을 제시하며 스케일링 논쟁에 다시 불을 붙였습니다. 수츠케버 창립자는 데이터 고갈을 이유로 스케일링의 한계를 지적하며 '연구 시대'로의 회귀를 주장했고, 순다르 피차이 구글 CEO는 인프라 개선을 통한 사전 훈련의 지속적인 성능 향상 가능성을 강조했습니다. 두 사람 모두 모델 성능 향상을 위해 사전 훈련 이상의 방법, 특히 강화 학습(RL)의 중요성을 언급하며, 스케일링과 기술 혁신 연구의 병행이 AI 발전의 핵심임을 시사했습니다.",
  "published_at": "2025-11-28T07:00:00+09:00",
  "modified_at": "2025-11-28T07:00:00+09:00",
  "author": [
    "AI타임스"
  ],
  "image": "https://cdn.aitimes.com/news/photo/202511/204302_205480_1655.jpg",
  "text": "1년 전인 2024년 12월13일 일리야 수츠케버 SSI 창립자는 캐나다 밴쿠버에서 열린 '뉴립스(NeurIPS)' 컨퍼런스에서 \" 우리가 아는 사전 훈련은 의심할 여지 없이 끝날 것 \"이라고 말했습니다. 이는 당시의 화두였던 스케일링 법칙 시대의 종말을 선언한 것입니다. 그는 \"컴퓨팅은 성장하고 있지만, 데이터는 성장하지 않는다. 왜냐하면 인터넷은 하나 뿐이기 때문\"이라며 \"우리는 최고 데이터를 달성했고, 더는 없을 것\"이라고 이유를 밝혔습니다. 사티아 나델라 마이크로소프트 CEO 나 젠슨 황 엔비디아 CEO 도 비슷한 발언을 했습니다. 이처럼 지난해 말부터는 스케일링의 시대가 끝나고, 추론이 새로운 AI 발전의 법칙으로 자리 잡는 분위기였습니다. 그리고 1년여가 지난 현재, 구글의 '제미나이 3'가 다시 스케일링 논쟁 에 불을 붙였습니다. 제미나이 개발 공동 책임자인 오리올 비냘스 딥마인드 부사장이 제미나이 3의 성능 향상 비결로 \"사전 훈련과 사후 훈련이 개선됐기 때문\"이라며 \"스케일링 법칙은 끝났다는 일반적인 믿음과는 반대\"라고 말한 것입니다. 이번 주에는 논쟁의 핵심인 수츠케버 창립자와 순다르 피차이 구글 CEO가 나란히 팟캐스터에 출연, 이에 대한 입장을 밝혀 눈길을 끌었습니다. 우선 수츠케버 창립자는 25일(현지시간) 공개된 '드와르케시 팟캐스트'에 출연, 이에 대한 의견을 내놓았습니다. 그는 제미나이라는 단어를 딱 한번 언급했습니다. \"사전 훈련을 통해 무언가를 얻을 수 있고, 실제로 트위터에서 사람들이 말하는 다양한 내용을 바탕으로 볼 때, 제미나이가 사전 훈련에서 더 많은 것을 얻어내는 방법을 발견한 것처럼 보인다\"라며 \"다만 어느 시점에서는 사전 훈련이 데이터 고갈에 직면할 것\"이라고 말했습니다. 즉 제미나이 3로 조금 스케일링의 여지를 보였을지는 모르지만, 근본적으로 새로운 데이터가 대거 추가되지 않는 한 더 큰 발전은 어렵다고 반복한 것입니다. 그리고 그는 AI 연구가 다시 '연구 시대(Age of Research)'로 회귀하고 있다고 주장했습니다. 그는 2012~2020년까지를 연구 시대로, 이후 2025년까지를 스케일링 시대로 규정했습니다. 현재는 엄청난 규모의 컴퓨팅 자원을 보유하기 때문에, 단순히 규모를 키우는 대신 \"컴퓨팅을 가장 생산적으로 사용하는 방법을 찾는\" 새로운 연구가 필요하다는 것입니다. 또 AI의 근본적인 문제로 '일반화(Generalization)' 능력을 꼽았습니다. 인간이 운전 같은 새로운 기술을 배우는 데 매우 적은 데이터만 있어도 뛰어난 학습 효율을 낼 수 있다는 것이 AI와의 차이라는 것입니다. 이는 진화를 통해 시각이나 운동 능력에 강력한 선험적 지식(Prior)을 부여했기 때문일 수도 있지만, 수학이나 코딩 같은 새로운 영역에서의 뛰어난 학습 능력은 인간이 더 나은 근본적인 머신러닝 원리를 가지고 있다는 것을 시사한다는 설명입니다. 여기에 인간이 가진 감정은 일종의 '가치 함수(Value Function)' 역할을 해 의사 결정에 중요한 역할을 하며, 이는 AI의 강화 학습(RL) 효율성에도 영향을 미칠 수 있다고 언급했습니다. 따라서 이런 점에 집중하는 새로운 AI 연구가 필요하다는 내용입니다. 수츠케버 창립자는 실제로 이런 연구를 기반으로 인공일반지능(AGI) 개발에 도전 중입니다. 피차이 CEO도 26일 스케일링에 대해 언급했습니다. 이는 구글의 '풀 스택(Full Stack)' 역량을 설명하는 중에 등장했습니다. 먼저 방송에 참여한 로건 킬패트릭 AI 스튜디오 제품 책임자가 사전 훈련이 제미나이에서 매우 잘 작동하고 있다며, 이것이 모델의 근본적인 역량의 '가속제(accelerant)'와 같은 역할을 한다고 설명했습니다. 그리고 이를 인프라 덕분이라고 덧붙였습니다. 피차이 CEO는 이에 동의하며 하드웨어 인프라의 발전이 사전 훈련을 직접적으로 향상한다고 밝혔습니다. \"물론이다. 인프라를 개선하면 사전 훈련, 사후 훈련, 테스트 시간 컴퓨팅 등에서 모델을 더 좋게 만든다\"라는 내용입니다. 즉, 구글이 TPU와 데이터센터 등 인프라를 개선하면, 그 혜택이 사전 훈련된 모델의 성능 향상으로 이어지고, 이는 다시 전체 제품에 반영되는 선순환 구조를 이루고 있음을 설명한 것입니다. 여기에서 왜 구글이나 오픈AI, 앤트로픽, 메타와 같은 기업들이 천문학적인 투자로 인프라 구축에 나섰는지를 파악할 수 있습니다. 이들은 아직 스케일링 시대가 끝나지 않았다고 보는 것입니다. 데이터가 한계에 달했더라도 기존과는 비교가 안 될 정도의 엄청난 인프라를 투입하면, 모델 성능이 향상될 수 있다고 보는 것입니다. 특히, 현재 프론티어 모델은 이미 상당 부분에서 인간을 능가하고 있습니다. 여기에서 조금 더 성능을 끌어올리면 인공일반지능(AGI)이 손에 잡힐 듯 보일 수 있습니다. 모든 역량을 인프라 구축에 집중하는 것이 이해되는 상황입니다. 그리고 수츠케버 창립자와 피차이 CEO의 주장은 다른 것 같지만, 근본적인 부분에서는 일치한다고 볼 수 있습니다. 모델 성능을 더 올리려면 사전 훈련 이상이 필요하다는 것입니다. 둘 다 사후 훈련, 특히 RL을 지목했습니다. 이 역시 지난해 말부터 새로운 스케일링 법칙으로 떠오른 핵심입니다. 이와 관련, 야오 슌위 구글 딥마인드 수석과학자도 이날 사우스차이나모닝포스트 와의 인터뷰에서 \"데이터의 한계에 도달할 때까지 적어도 1년 동안은 사전 훈련이 결과를 낼 것으로 예상한다\"라고 밝혔습니다. 특히 \"AI의 미래는 규모 확장과 기술 혁신 연구를 동시에 추진하는 데 달려 있다\"라고 말했습니다. 즉, 수츠케버 창립자가 지적한 새로운 연구와 스케일링이 병행돼야 한다는 말입니다. 이처럼 AI 연구는 다시 확장된 분위기입니다. 아니, 주요 기업들은 이미 두가지를 병행하고 있으며, 제미나이 3 출시로 무엇을 하는지가 드러났다고 보는 것이 맞을 것 같습니다. 그리고 이들의 주장이 맞다면 내년 초에 출시될 새로운 모델들을 제미나이 3처럼 진전을 이룰 것으로 예측할 수 있습니다. 또 이런 노력이 모여 2026년에는 마침내 AGI에 근접했다는 평가가 나올지 기대됩니다. 이어 26일 주요 뉴스입니다. (사진=센서타워) ■ 국내 챗GPT 매출 3000억...미국 이어 전 세계 2위 국내 사용자들이 미국에 이어 챗GPT 유료 결제를 가장 많이 한 것으로 알려졌습니다. 특히 다운로드 수에 비교하면, 미국과 결제 규모가 거의 차이 없을 정도입니다. AI 사용 면에서는 세계 최고 수준으로 볼 수 있습니다. ■ 미국, '과학용' 국가 AI 모델 프로젝트 추진...\"AI 맨해튼 프로젝트\" 미국 정부가 과학 연구를 지원하는 파운데이션 모델 개발에 국가 역량을 집중하기로 했습니다. 오픈AI 등 최고 수준의 민간 기업과 수십년간 축적된 방대한 정부 데이터 등을 통합한다는 것입니다. 이는 프론티어 모델을 개발하는 기업들의 수요와도 맞물립니다. ■ 싱가포르, '라마'에서 '큐원'으로 자체 모델 기반 교체...\"중국 기술 큰 승리\" 싱가포르가 소버린 AI 모델의 기반을 라마에서 큐원으로 교체했습니다. 이를 두고 중국에서는 미국을 앞질렀다고 자평했습니다. 이보다는 국가용 AI 모델을 '프롬 스크레치'가 아닌, 오픈 소스를 미세조정해 개발하는 싱가포르의 방식이 눈길을 끕니다. AI타임스 news@aitimes.com",
  "url": "https://www.aitimes.com/news/articleView.html?idxno=204302",
  "article_id": "LEGACY_CALL",
  "cached_at": "2025-12-17T15:05:28.609110+00:00",
  "profile_version": "AI_INDUSTRY_NEWS_V6.6.3",
  "tags": [
    "LLM",
    "GEN_AI",
    "RESEARCH_PAPER"
  ],
  "raw_analysis": {
    "impact_entity": {
      "id": "TIER_Z_GENERAL",
      "value": "1.0",
      "reasoning": "본문의 주요 주체인 일리아 수츠케버와 순다르 피차이는 특정 기업의 CEO 또는 창립자이지만, 이들의 발언은 특정 기업의 모델 출시보다는 AI 연구 및 발전 방향에 대한 일반적인 논의에 초점을 맞추고 있습니다. 따라서 'TIER_Z_GENERAL'로 분류합니다."
    },
    "impact_events": [
      {
        "id": "MODEL_RELEASE",
        "value": "1.5",
        "reasoning": "구글의 '제미나이 3' 모델 출시가 언급되었으며, 이는 스케일링 논쟁을 촉발하는 계기가 되었습니다. 제미나이 3는 TIER_1 또는 TIER_2 기업의 모델이지만, 텍스트에서 'GPT-4를 능가한다'는 명확한 검증이나 'Verified Venue'에서의 성과가 입증되지 않았으므로 'MODEL_RELEASE'로 분류합니다."
      }
    ],
    "penalties": [
      {
        "id": "VAGUE_FUTURE_PROMISE",
        "value": "1.0",
        "reasoning": "수츠케버 창립자는 AI 연구가 '연구 시대'로 회귀하고 있으며, 컴퓨팅을 생산적으로 사용하는 방법을 찾는 새로운 연구가 필요하다고 주장하지만, 구체적인 연구 방법론이나 결과에 대한 명확한 제시보다는 일반적인 방향성을 제시하고 있습니다."
      },
      {
        "id": "IRRELEVANT_ENTITY_NOISE",
        "value": "2.0",
        "reasoning": "본문은 AI 스케일링 논쟁이라는 특정 주제에 집중하고 있으며, 언급된 인물들의 발언은 해당 논쟁과 직접적으로 관련되어 있습니다. 따라서 'IRRELEVANT_ENTITY_NOISE' 페널티는 적용되지 않습니다."
      }
    ],
    "credits": [
      {
        "id": "STRATEGIC_ROADMAP_CLARITY",
        "value": "1.0",
        "reasoning": "수츠케버 창립자는 AI 연구의 방향성을 '연구 시대'와 '스케일링 시대'로 구분하고, 현재는 컴퓨팅을 생산적으로 사용하는 새로운 연구가 필요하다고 주장하며 AI 연구의 미래 방향에 대한 명확한 비전을 제시하고 있습니다."
      },
      {
        "id": "VIRAL_COMMUNITY_TOPIC",
        "value": "1.5",
        "reasoning": "본문은 AI 스케일링 논쟁이라는 주제를 다루고 있으며, 이는 AI 커뮤니티에서 활발하게 논의되는 주제입니다. 또한, 수츠케버 창립자와 피차이 CEO가 팟캐스트에 출연하여 이에 대한 입장을 밝힌 점은 해당 주제의 중요성과 관심을 반영합니다."
      }
    ]
  },
  "overall_review": "AI 스케일링 논쟁의 현재와 미래 방향에 대한 심도 있는 분석입니다.",
  "impact_score": 2.5,
  "zero_echo_score": 5.5,
  "evidence": {},
  "impact_evidence": {
    "schema_version": "V0.9-Hybrid"
  },
  "mll_status": "analyzed",
  "analyzed_at": "2025-12-17T15:47:49.146024+00:00",
  "staged_at": "2025-12-17T15:48:44.698167+00:00",
  "staged": true
}