{
  "article_id": "3af0fe",
  "author": "Emilia David",
  "cached_at": "2025-12-17T14:49:02.326839+00:00",
  "image": "https://images.ctfassets.net/jdtwqhzvc2n1/3TfXFusqQ5RzV9PDssQ8gA/33947ed5595424358bbc04a072008b79/crimedy7_illustration_of_robots_filming_a_movie_--ar_169_--v__db49164c-0f27-47ed-bd71-5dfc41265a4d_0.png?w=800&amp;q=75",
  "modified_at": "2025-12-16T20:45:51.551Z",
  "published_at": "2025-12-16T00:00-05:00",
  "summary": "앨런 AI 연구소(Ai2)가 비디오 이해 및 픽셀 수준의 그라운딩에 최적화된 오픈소스 멀티모달 모델 'Molmo 2'를 출시했습니다. 4B, 8B 등 소형 모델임에도 불구하고 특정 벤치마크에서 구글의 Gemini 3 Pro를 능가하는 성능을 보여주며 효율적인 비디오 분석 대안을 제시했습니다.",
  "text": "Fresh off releasing the latest version of its Olmo foundation model, the Allen Institute for AI (Ai2) launched its open-source video model, Molmo 2, on Tuesday, aiming to show that smaller, open models can be viable options for enterprises focused on video understanding and analysis. In a press release , the company said Molmo 2 “takes Molmo’s strengths in grounded vision and expands them to video and multi-image understanding,” a capability that has largely been dominated by larger proprietary models. Ai2 released three variants of Molmo 2: Molmo 2 8B , a Qwen-3–based model that Ai2 describes as its “best overall model for video grounding and QA” Molmo 2 4B , designed for more efficient deployments Molmo 2-O 7B, built on the Olmo model Molmo 2 supports single-image and multi-image inputs, as well as video clips of different lengths, enabling tasks such as video grounding, tracking, and question answering. “One of our core design goals was to close a major gap in open models: grounding,” Ai2 said in its press release. The company first introduced the Molmo family of open multimodal models last year, beginning with images. Ai2 said Molmo 2 surpasses previous versions in accuracy, temporal understanding, and pixel-level grounding, and in some cases performs competitively with larger models such as Google’s Gemini 3. How Molmo 2 compares Despite their smaller size, the Molmo 2 models outperformed Gemini 3 Pro and other open-weight competitors on video tracking benchmarks. Credit: Ai2 For image and multi-image reasoning, Ai2 said Molmo 2 8B “leads all open-weight models, with the 4B variant close behind.” The 8B and 4B models also showed strong performance in the open-weight Elo human preference evaluation, though Ai2 noted that larger proprietary models continue to lead that benchmark overall. But Molmo 2’s biggest gains are in video grounding and video counting, where it outscores similar open-weight models. “These results highlight both progress and remaining headroom — video grounding is still hard, and no model yet reaches 40% accuracy,\" Ai2 said, referring to current benchmarks. Many video models, such as Google's Veo 3.1 and OpenAI's Sora, are typically very large. Molmo 2 targets a different tradeoff: smaller, open models optimized for grounding and analysis rather than video generation.",
  "title": "Ai2’s Molmo 2 shows open-source models can rival proprietary giants in video understanding",
  "url": "https://venturebeat.com/infrastructure/ai2s-molmo-2-shows-open-source-models-can-rival-proprietary-giants-in-video",
  "title_ko": "Ai2, 구글에 맞서는 오픈소스 비디오 이해 모델 'Molmo 2' 발표",
  "tags": [],
  "impact_score": 7.5,
  "IS_Analysis": {
    "Score_Commentary": "PE(Ai2)는 비영리 연구소이나 기술적 영향력을 고려해 Academic Tier 2로 분류. SE는 비교 대상인 Google(T1) 적용.",
    "Calculations": {
      "IW_Analysis": {
        "Inputs": {
          "Pe_Selection_Rule": "P4",
          "Pe_Entity_Name": "Ai2 (Allen Institute for AI)",
          "Pe_Tier": 2,
          "Se_Entity_Name": "Google",
          "Se_Tier": 1
        },
        "Tier_Score": 2,
        "Gap_Score": 1,
        "IW_Score": 3
      },
      "IE_Analysis": {
        "Inputs": {
          "X_Magnitude_Code": 3,
          "Y_Evidence_Code": 4,
          "Scope_Matrix_Score": 3,
          "Criticality_C1_Provenness": 1,
          "Criticality_C2_Societal_Weight": 0.5,
          "Criticality_Total": 1.5,
          "SOTA_Check_Result": "True"
        },
        "IE_Score": 4.5
      }
    }
  },
  "zero_echo_score": 3.0,
  "ZES_Raw_Metrics": {
    "Signal": {
      "T1": 8,
      "T2": 7,
      "T3": 9,
      "Rationale": "모델 파라미터(4B, 7B, 8B), 기반 모델(Qwen-3, Olmo), 정확도 수치(40% 미만) 등 연구 데이터가 풍부함."
    },
    "Noise": {
      "P1": 2,
      "P2": 3,
      "P3": 1,
      "Rationale": "연구소의 공식 발표 기반으로 비교적 객관적이며, 한계점( accuracy < 40%)을 솔직하게 명시함."
    },
    "Utility": {
      "V1": 8,
      "V2": 9,
      "V3": 8,
      "Rationale": "고비용 독점 모델의 대안으로 소형 오픈소스 모델의 가능성을 증명하여 기업 사용자에게 높은 유용성 제공."
    },
    "Fine_Adjustment": {
      "Score": 0.3,
      "Reason": "오픈소스 AI 생태계의 기술적 진보를 보여주는 상징적인 릴리즈임."
    }
  },
  "schema_version": "V1.0",
  "raw_analysis": {
    "Article_ID": "3af0fe",
    "Meta": {
      "Specification_Version": "v 1.0.0",
      "Headline": "Ai2, 구글에 맞서는 오픈소스 비디오 이해 모델 'Molmo 2' 발표",
      "Summary": "앨런 AI 연구소(Ai2)가 비디오 이해 및 픽셀 수준의 그라운딩에 최적화된 오픈소스 멀티모달 모델 'Molmo 2'를 출시했습니다. 4B, 8B 등 소형 모델임에도 불구하고 특정 벤치마크에서 구글의 Gemini 3 Pro를 능가하는 성능을 보여주며 효율적인 비디오 분석 대안을 제시했습니다."
    },
    "IS_Analysis": {
      "Score_Commentary": "PE(Ai2)는 비영리 연구소이나 기술적 영향력을 고려해 Academic Tier 2로 분류. SE는 비교 대상인 Google(T1) 적용.",
      "Calculations": {
        "IW_Analysis": {
          "Inputs": {
            "Pe_Selection_Rule": "P4",
            "Pe_Entity_Name": "Ai2 (Allen Institute for AI)",
            "Pe_Tier": 2,
            "Se_Entity_Name": "Google",
            "Se_Tier": 1
          },
          "Tier_Score": 2,
          "Gap_Score": 1,
          "IW_Score": 3
        },
        "IE_Analysis": {
          "Inputs": {
            "X_Magnitude_Code": 3,
            "Y_Evidence_Code": 4,
            "Scope_Matrix_Score": 3,
            "Criticality_C1_Provenness": 1,
            "Criticality_C2_Societal_Weight": 0.5,
            "Criticality_Total": 1.5,
            "SOTA_Check_Result": "True"
          },
          "IE_Score": 4.5
        }
      }
    },
    "ZES_Raw_Metrics": {
      "Signal": {
        "T1": 8,
        "T2": 7,
        "T3": 9,
        "Rationale": "모델 파라미터(4B, 7B, 8B), 기반 모델(Qwen-3, Olmo), 정확도 수치(40% 미만) 등 연구 데이터가 풍부함."
      },
      "Noise": {
        "P1": 2,
        "P2": 3,
        "P3": 1,
        "Rationale": "연구소의 공식 발표 기반으로 비교적 객관적이며, 한계점( accuracy < 40%)을 솔직하게 명시함."
      },
      "Utility": {
        "V1": 8,
        "V2": 9,
        "V3": 8,
        "Rationale": "고비용 독점 모델의 대안으로 소형 오픈소스 모델의 가능성을 증명하여 기업 사용자에게 높은 유용성 제공."
      },
      "Fine_Adjustment": {
        "Score": 0.3,
        "Reason": "오픈소스 AI 생태계의 기술적 진보를 보여주는 상징적인 릴리즈임."
      }
    }
  },
  "source_id": "venturebeat",
  "original_title": "Ai2’s Molmo 2 shows open-source models can rival proprietary giants in video understanding",
  "evidence": {
    "breakdown": {
      "schema": "V1.0",
      "Signal": {
        "T1": 8.0,
        "T2": 7.0,
        "T3": 9.0,
        "S_Avg": 8.0,
        "Rationale": "모델 파라미터(4B, 7B, 8B), 기반 모델(Qwen-3, Olmo), 정확도 수치(40% 미만) 등 연구 데이터가 풍부함."
      },
      "Noise": {
        "P1": 2.0,
        "P2": 3.0,
        "P3": 1.0,
        "N_Avg": 2.0,
        "Rationale": "연구소의 공식 발표 기반으로 비교적 객관적이며, 한계점( accuracy < 40%)을 솔직하게 명시함."
      },
      "Utility": {
        "V1": 8.0,
        "V2": 9.0,
        "V3": 8.0,
        "U_Avg": 8.33,
        "Rationale": "고비용 독점 모델의 대안으로 소형 오픈소스 모델의 가능성을 증명하여 기업 사용자에게 높은 유용성 제공."
      },
      "Fine_Adjustment": 0.3,
      "Fine_Reason": "오픈소스 AI 생태계의 기술적 진보를 보여주는 상징적인 릴리즈임.",
      "ZS_Raw": 3.03,
      "ZS_Final": 3.0
    },
    "raw_metrics": {
      "Signal": {
        "T1": 8,
        "T2": 7,
        "T3": 9,
        "Rationale": "모델 파라미터(4B, 7B, 8B), 기반 모델(Qwen-3, Olmo), 정확도 수치(40% 미만) 등 연구 데이터가 풍부함."
      },
      "Noise": {
        "P1": 2,
        "P2": 3,
        "P3": 1,
        "Rationale": "연구소의 공식 발표 기반으로 비교적 객관적이며, 한계점( accuracy < 40%)을 솔직하게 명시함."
      },
      "Utility": {
        "V1": 8,
        "V2": 9,
        "V3": 8,
        "Rationale": "고비용 독점 모델의 대안으로 소형 오픈소스 모델의 가능성을 증명하여 기업 사용자에게 높은 유용성 제공."
      },
      "Fine_Adjustment": {
        "Score": 0.3,
        "Reason": "오픈소스 AI 생태계의 기술적 진보를 보여주는 상징적인 릴리즈임."
      }
    }
  },
  "impact_evidence": {
    "calculations": {
      "schema": "V1.0",
      "IW_Analysis": {
        "Tier_Score": 2.0,
        "Gap_Score": 1.0,
        "IW_Total": 3.0
      },
      "IE_Analysis": {
        "Scope_Total": 3.0,
        "Criticality_Total": 1.5,
        "IE_Total": 4.5
      },
      "IS_Raw": 7.5,
      "IS_Final": 7.5,
      "Score_Commentary": "PE(Ai2)는 비영리 연구소이나 기술적 영향력을 고려해 Academic Tier 2로 분류. SE는 비교 대상인 Google(T1) 적용."
    },
    "raw_inputs": {
      "Pe_Selection_Rule": "P4",
      "Pe_Entity_Name": "Ai2 (Allen Institute for AI)",
      "Pe_Tier": 2,
      "Se_Entity_Name": "Google",
      "Se_Tier": 1
    },
    "raw_ie_inputs": {
      "X_Magnitude_Code": 3,
      "Y_Evidence_Code": 4,
      "Scope_Matrix_Score": 3,
      "Criticality_C1_Provenness": 1,
      "Criticality_C2_Societal_Weight": 0.5,
      "Criticality_Total": 1.5,
      "SOTA_Check_Result": "True"
    },
    "schema_version": "V1.0"
  },
  "crawled_at": "2025-12-17T15:44:48.967596+00:00",
  "edition": "251217_WED_1",
  "saved": true,
  "saved_at": "2025-12-17T15:44:48.972361+00:00",
  "staged_at": "2025-12-17T15:45:39.426374+00:00",
  "staged": true
}