{
  "_header": {
    "version": "2.0",
    "article_id": "5993b23cabac",
    "state": "RELEASED",
    "state_history": [
      {
        "state": "COLLECTED",
        "at": "2025-12-28T06:51:09.770756+00:00",
        "by": "crawler"
      },
      {
        "state": "PUBLISHED",
        "at": "2025-12-28T17:10:44.443122+00:00",
        "by": "publisher"
      },
      {
        "state": "RELEASED",
        "at": "2025-12-29T09:03:21.535828+00:00",
        "by": "publisher"
      }
    ],
    "updated_at": "2025-12-29T09:03:21.535828+00:00"
  },
  "_original": {
    "title": "[AI의 역사] 98 인류를 위한 공개되고 안전한 AI라는 약속 – 오픈AI의 변화와 쿠테타 과정 - AI타임스",
    "description": "2023년 11월17일 라스베이거스에서 휴가를 즐기던 오픈AI CEO 샘 알트먼은 이사회와의 화상회의를 가졌다. 그리고 이사회와 일리야 수츠케버로부터 전격적인 C",
    "image": "https://cdn.aitimes.com/news/photo/202512/205124_206627_4332.png",
    "text": "(사진=X,Ilya Sutskever) 2023년 11월17일 라스베이거스에서 휴가를 즐기던 오픈AI CEO 샘 알트먼은 이사회와의 화상회의를 가졌다. 그리고 이사회와 일리야 수츠케버로부터 전격적인 CEO 해임 통보를 받았다. 이사회는 \"이사회와의 소통에서 일관되게 솔직하지 못했다\"라며 \"이사회가 더 이상 리더십에 대한 신뢰를 유지할 수 없다\"라는 짧은 성명을 밝혔다. 하지만 해임은 채 나흘도 가지 못했다. 직원들의 집단 반발, 마이크로소프트와 투자자들의 압박, 그리고 실리콘 밸리 인맥의 총동원 속에서 알트먼은 복귀했다. 또 해임 사태를 주도했던 2인의 독립 이사들은 모두 물러나야 했다. 이 극적인 사건은 '인류를 위한 비영리 AI 연구소'를 표방하며 출발한 오픈AI의 거버넌스가 사실상 실패했음을 보여주는 상징적 순간이었다. 그리고 그 이면에는 8년에 걸쳐 진행된 오픈AI의 변화 과정이 자리하고 있었다. 앞선 회에서 소개했듯 오픈AI는 2015년 초지능 AI가 소수 기업에 의해 통제되는 것을 막기 위한다는 기치 아래 설립됐다. 그런 배경에서 오픈AI는 비영리 연구소로 출발했으며, 연구 결과를 모두 공개하고 안전을 최우선으로 하며, 인류 전체의 이익을 위한 안전한 AI 개발한다는 원칙을 천명했다. 그러나 실제로 오픈AI는 출범 초기부터 이중성이 내재해 있었다. 내부 이메일에서는 AGI에 가까워질수록 덜 공개적으로 가야 한다는 인식이 있었다. 비영리, 개방, 안전이라는 공개적 약속과 달리, 핵심 구성원들은 이미 향후 전략 전환 가능성을 염두에 두고 있었다. 실제 변곡점은 2018년에 있었다. 당시 오픈AI는 구글의 트랜스포머 기술을 활용해 'GPT-1'을 개발했지만, 연구는 정체되고 자금은 빠르게 소진되고 있었다. 이때 수츠케버가 제시한 컴퓨팅 자원의 규모 확장 아이디어는 연구소 전체의 호응을 얻어냈지만, 현실적으로 오픈AI의 비영리 구조로는 불가능한 계획이었다. 이 과정에서 일론 머스크와 알트먼의 갈등이 표면화됐다. 머스크는 테슬라가 오픈AI를 흡수하는 방안을 제안했고, 알트먼은 자신이 CEO가 되는 독자 포지션을 요구했다. 결국 머스크는 오픈AI를 떠났고, 훗날 자신을 이용해 명성을 쌓았다고 비난하게 됐다. 머스크가 떠나자, 알트먼에게는 자금 조달의 숙제가 남겨졌다. 그는 혁신적인 구조로 바꿔 문제를 해결하려 했다. 그것은 영리 사업부 역할을 하는 유한 합자회사(LP)를 자회사로 설립하고, 투자금의 100배까지 수익을 허용하는 구조였다. 표면적으로 오픈AI의 사명을 지키고 권력 집중을 방지한다고 강조했지만, 실질적으로는 AGI가 만들어낼 막대한 가치에 대해 소수 투자자와 조직에 지분을 열어주는 틀이었다. 외부의 비판에도 불구하고 오픈AI LP에는 투자금이 쏟아져 들어왔고, 그렇게 구글이나 페이스북과 경쟁이 가능한 AI 연구소로서 거듭날 수 있었다. 이로써 표면상 비영리 조직을 유지하면서도 영리기업처럼 투자받는 하이브리드 조직으로 재탄생했다. 이를 기반으로 마이크로소프트(MS)의 거대 규모 투자도 유치할 수 있었다. MS와의 투자 계약은 오픈AI 기술을 독점적 라이선스로 제공하는 ‘전략적 파트너십’이 포함됐다. 이 계약으로 10억달러의 자금을 확보할 수 있게 되었고, MS로서는 검색 시장에서 구글을 쫓아갈 기회를 확보했다. 그러나 이런 독점적 기술 라이선싱은 초지능 AI가 소수의 기업에 의해 통제되는 것을 막기 위한다는 오픈AI의 설립 취지에 반하는 모습이었다. 그래서 MS와의 투자 계약에서 오픈AI는, AGI를 개발했다고 비영리 이사회가 판단하는 경우 기술 라이선스가 무효가 된다고 밝히기도 했다. 그런데 이런 논리는 허점을 드러냈다. 먼저 기술 라이선스는 일반 소비자가 아닌 더 큰 통제력을 가진 기업에 기술을 판매하는 것으로 AI가 소수, 아니 단 하나의 기업에 의해 통제되는 상황을 가져오는 것이다. 또 AI의 발전 상황과 관계없이 이사회가 아직 인공일반지능(AGI)에 이르지 못했다고 판단하는 한, MS는 계속 오픈AI의 기술을 독점적으로 사용할 수 있다는 의미였다. 결국 오픈AI는 MS와 독점적으로 깊이 결합한 조직이 될 것이 예상됐다. 연구 결과를 모두 공개하겠다던 초기의 약속도 2019년 'GPT-2' 개발과 함께 폐기됐다. GPT-2는 아직 서툴렀지만 인간처럼 보이는 장문의 글을 생성할 수 있었고, 동시에 음모론과 혐오 표현 등 데이터의 독성도 드러냈다. 이를 계기로 오픈AI는 AI 모델이 잘못된 정보를 대량 생산되는데 악용될 수 있다며 '위험해서 전부 공개할 수 없다'라는 전략을 채택했다. 이런 전략은 자체 AI 모델의 성능보다 위험성을 더 부각하면서, 대중들이 연구 결과 공개 약속의 폐기보다는 AI의 위험성에 더 큰 관심을 두게 하는 데 효과적이었다. 이 전략과 제한된 사용자들만 GPT-2를 사용해 볼 수 있게 한 전략은 대중들의 오픈AI와 GPT-2 모델에 대한 관심을 더 집중하게 한 뛰어난 홍보 전략이었다. 또 워싱턴 싱크 탱크와의 파트너십을 통해 ‘첨단 AI는 책임 있는 비공개가 필요하다’라는 규범을 확산시키기도 했다. 결국 오픈AI는 자신들에 대한 비난과 논란을 정면으로 받아들여 역이용하면서 비판자들의 목소리가 묻혀버리게 했다. (사진=오픈AI) 2020년에 공개된 'GPT-3' 개발은 더욱 과감했다. MS가 제공한 거대 규모의 GPU를 투입해, 기존의 연구계에서 상상할 수 없는 규모의 실험을 감행했다. 오픈AI의 개발 분위기도 비용, 환경, 거버넌스 부담보다 ‘AGI 선점’을 최우선의 목표로 하는 듯 보였다. GPT-3는 레딧, 위키백과, 불법 전자도서관, 커먼크롤 등에서 긁어모은 텍스트를 학습했고 데이터 필터링 기준은 점점 낮아지고 있었다. 당시 GPT-3 개발에 참여했던 다리오 아모데이는 이런 상황이 불편했다. 그는 2015년 여름 오픈AI 설립을 논의하던 최초의 회의에 참석했고, 구글에서 AI 안전을 연구했다. 이후에 위험할 수 있는 AI로부터 인류를 지킨다는 비전이 마음에 들어 합류하고, 오픈AI에서도 같은 연구를 이끌고 있었다. 그런 그에게 인류를 위한 AI를 개발하면서, 이윤 극대화를 추구하는 대기업에 독점적으로 기술을 제공하는 것은 모순적인 상황이었다. 특히 새로운 모델 공개에 더 힘을 쓰면서, 오픈AI는 데이터나 모델의 안전 연구에 대한 동력이 급격히 힘을 잃어가고 있었다. 결국 아모데이와 AI 안전팀 책임자였던 그의 여동생 그리고 몇몇 연구자들은 회사를 떠났다. 그들은 MS와의 파트너십 이후 상업적 초점을 강화하는 방향에 대한 비전 차이와 AI 안전에 대한 우려 때문에 퇴사를 결정했다고 밝히고, 이듬해인 2021년 앤트로픽(Anthropic)을 공동 설립했다. 앤트로픽은 인류의 안전과 이익을 보장하는 방식으로 AI를 연구하고 개발하는 것을 핵심 사명으로 내세웠다. 하지만 그들이 내세운 사명과는 별개로, 설립자들은 MS의 오픈AI에 대한 투자를 보면서 새로운 사업 기회를 엿본 것이기도 하다. 그들의 예상대로 1년도 안 돼 6억달러를 투자받았고, 2년 뒤에는 구글과 아마존으로부터 60억달러를 투자받으며 AI 개발 시장에서 신흥 강자로 떠오르기 시작했다. 결국 오픈AI에는 자신들의 핵심 기술을 아는 새로운 경쟁자가 출현한 셈이었다. 2022년 MS는 GPT-3의 파생 모델과 자체 플랫폼 깃허브(GitHub)를 활용해 AI 코딩 비서인 ‘깃허브 코파일럿’을 발표했다. 오픈AI도 GPT-3의 언어 능력을 이미지와 결합해, 수준 높은 이미지 생성 도구인 ‘달리-2(DALL-E 2)’를 공개하며 대중의 관심을 모으기 시작했다. 그러던 중에 앤트로픽이 챗봇을 공개할 거라는 소문이 돌았고, 이는 오픈AI의 경쟁심에 불을 댕겼다. 2022년 말, 오픈AI는 GPT-3.5를 기반으로 한 챗봇을 출시했다. 공식적인 제품의 출시라기 보다는 연구용 프리뷰 버전으로 공개될 '챗GPT'는 곧 선보일 훨씬 뛰어난 'GPT-4' 공개의 준비 단계이기도 했다. 그래서 챗GPT의 공개는 그다지 요란하지 않았고, 심지어 오픈AI의 많은 직원들조차 공개 사실을 몰랐다. 알트먼이 트윗으로 공개 사실을 알렸고, 처음에는 비교적 잠잠했다. 그러나 챗GPT는 하루가 채 지나지 않아 전 세계적으로 폭발적 반응을 일으켰다. 언론도 찬사를 보내기 시작했고, 출시 2개월 만에 1억 사용자를 달성하며 역사상 가장 빠르게 성장한 소비자 앱이 되었다. 이는 오픈AI의 기업가치를 290억달러로 끌어올렸고, MS는 추가로 100억달러를 투자했다. 생성 AI 열풍이 전 세계를 휩쓸었고, 구글은 ‘코드레드’를 발동하며 자신들이 개발한 트랜스포머 기술을 오픈AI가 선점했다는 위기감에 빠졌다. 하지만 성공의 이면에는 어두운 그림자가 있었다. 아모데이가 떠난 이후 AI 안전 관리에 대한 비난을 받아오던 알트먼은 2023년 수츠케버를 슈퍼얼라인먼트 팀의 리더로 임명하며 문제를 해결하고자 했다. 하지만 조직 내부에서는 안전 연구자들과 상업화를 밀어붙이는 경영진 사이의 갈등이 더 심화하고 있었다. 그런 가운데, 내부 조직의 정비보다는 외부 행사에 더욱 많은 시간을 보냈고, 이사회를 경력적으로나 재정적으로 자신과 관련이 있는 인사들로 채우려는 모습을 보였다. 내외적인 문제를 수습하던 수츠케버와 CTO인 미라 무라티는 그의 행보와 관리 방식에 어려움을 느꼈는데, 특히 투명하지 않았던 소통 방식에 실망하고 있었다. 2023년 11월의 이사회 쿠데타는 바로 이 갈등이 폭발한 순간이었다. 수츠케버와 독립 이사들은 \"반복적으로 거짓말과 조작을 하고, 안전과 거버넌스를 우회한다\"라는 판단 아래 해임을 결정했다. 그러나 쿠데타는 실패했다. 700명이 넘는 직원 대부분이 \"알트먼 복귀 없으면 집단 퇴사\"라는 공개서한에 서명했고, MS와 실리콘 밸리 투자자들이 총력을 기울여 압박했다. 직원들의 반발은 충성심 때문만은 아니었다. 다수의 직원은 주요 투자자에게 곧 매각할 수 있는 보유 주식의 가치 하락이 큰 문제였다. MS도 자신들의 사업에 미칠 영향 때문에 가만히 바라보고만 있을 수는 없었다. 회사의 분열이 커지는 모습을 더 바라볼 수 없던 수츠케버조차 결국 복귀 서명에 합류하면서 판도가 뒤집혔다. 나흘 만에 그는 복귀했고, 이사회의 독립 이사들은 물러났다. 새로운 이사회는 알트먼과 브록먼이 적임자라는 신임 성명을 발표했다. 이후 지위는 더욱 확고해졌고, 오픈AI는 더 폐쇄적이고 상업적인 조직으로 변모했다. 하지만 오픈AI는 다시 위기를 맞이했다. 슈퍼얼라인먼트 팀이 해체되며, 안전 연구자들이 연달아 퇴사했다. 2024년에는 퇴사자 비방 금지 조항과 지분 회수 조항이 폭로돼 논란과 함께 비난받았다. 일부 직원은 170만달러 상당의 지분을 포기하면서까지 조항 서명을 거부했다. 스칼렛 요한슨의 음성 무단 모방과 관련한 거짓 논란과 'GPT-4o' 출시 과정에서의 안전 평가 경시 등 스캔들이 이어 터졌다. 오픈AI의 위기가 누적되자 경영진들은 수츠케버를 찾아갔다. 알려진 바에 의하면, 그들은 눈물로 복귀를 요청했고, 수츠케버도 진지하게 검토하고 있었다. 하지만 회사의 권력 다툼으로 복귀 요청은 하루도 지나지 않아 철회돼 버렸다. 2024년 말, 오픈AI는 결정적 전환을 완료했다. 비영리 지배 구조를 해체하고 공익법인형 영리 회사로 전환을 선언한 것이다. 기업 가치는 1570억달러로 평가됐고, 이사회가 CEO를 해임할 수 있던 구조는 사실상 폐기됐다. \"AGI를 어떻게 만들지 이제 확신했고, 다음 목표는 초지능\"이라는 선언이 나왔다. 이런 과정은 '인류를 위한 안전한 AI'라는 약속이 지난 10년 동안 어떻게 변화됐는지 보여준다. 단면만 보는 것일 수도 있지만, 출범할 때 내세웠던 비영리, 개방, 안전은 어느 것도 남아있지 않아 보인다. 오히려 특정 기업의 자본에 의존하고, 기술을 독점 제공하며, 데이터를 무단으로 수집하며, 내부 비판을 억압하는 조직이 됐다. 챗GPT가 가져온 생성 AI 혁명은 기술의 진보이기도 했지만, 동시에 AI 개발이 소수의 권력 집중을 심화시키고 있다는 경고이기도 했다. 하지만 이런 점은 오픈AI만의 문제는 아닌 듯하다. 오픈AI의 상업화와 안전 무시를 이유로 독립해서 세워진 앤트로픽은 물론 구글, xAI, 메타와 같은 대부분의 주요 AI 기업들도 유사한 경로를 따르고 있어 보인다. 천문학적 자본과 컴퓨팅 자원을 가진 소수 기업만이 초거대 모델 개발 경쟁에 참여할 수 있고, 그 결과 기술 발전의 방향이 '인류의 필요'가 아닌 '자본의 논리'에 의해 결정되고 있다. 더 이상 누구도 인류를 위한 AI라는 약속을 믿기는 어려워진 시대다. 문병성 싸이텍 이사 moonux@gmail.com",
    "published_at": "2025-12-27T07:10:00+09:00",
    "url": "https://www.aitimes.com/news/articleView.html?idxno=205124",
    "source_id": "aitimes",
    "crawled_at": "2025-12-28T06:51:09.770756+00:00"
  },
  "_analysis": {
    "title_ko": "오픈AI의 변화와 쿠데타: 인류를 위한 약속에서 폐쇄적 영리화로",
    "summary": "오픈AI의 설립부터 샘 알트만 해임 쿠데타, MS와의 파트너십까지의 역사를 심층 분석. 비영리 원칙이 자금 조달과 경쟁 심화로 인해 어떻게 훼손되고 폐쇄적 영리 기업화되었는지 과정을 상세히 기술함.",
    "tags": [
      "Deep Dive",
      "Ethics",
      "OpenAI"
    ],
    "impact_score": 9.0,
    "zero_echo_score": 3.0,
    "analyzed_at": "2025-12-28T06:57:58.929150+00:00",
    "mll_raw": {
      "Article_ID": "5993b23cabac",
      "Meta": {
        "Specification_Version": "v 1.0.0",
        "Headline": "오픈AI의 변화와 쿠데타: 인류를 위한 약속에서 폐쇄적 영리화로",
        "Summary": "오픈AI의 설립부터 샘 알트만 해임 쿠데타, MS와의 파트너십까지의 역사를 심층 분석. 비영리 원칙이 자금 조달과 경쟁 심화로 인해 어떻게 훼손되고 폐쇄적 영리 기업화되었는지 과정을 상세히 기술함.",
        "Tags": [
          "Deep Dive",
          "Ethics",
          "OpenAI"
        ]
      },
      "IS_Analysis": {
        "Score_Commentary": "AI 산업의 권력 구조가 재편되는 과정을 다룬 핵심 기사. PE(OpenAI)와 SE(MS)의 결합은 Tier 1 간의 역학 관계를 보여주며, 이는 AI 패러다임(X4) 자체를 정의하는 사건임.",
        "Calculations": {
          "IW_Analysis": {
            "Inputs": {
              "Pe_Selection_Rule": "P1",
              "Pe_Entity_Name": "OpenAI",
              "Pe_Tier": 1,
              "Se_Entity_Name": "Microsoft",
              "Se_Tier": 2,
              "PE/SE_Rationale": "사건(쿠데타/구조개편)의 핵심 주체이자 원인 제공자 OpenAI(P1). 자금줄이자 구조적 변화의 핵심 파트너 Microsoft(SE, P3 협력/P2 인수제안)."
            },
            "Tier_Score": 3,
            "Gap_Score": 1,
            "IW_Score": 4
          },
          "IE_Analysis": {
            "Inputs": {
              "X_Magnitude_Code": 4,
              "Y_Evidence_Code": 4,
              "Scope_Matrix_Score": 3,
              "Criticality_C1_Provenness": 1,
              "Criticality_C2_Societal_Weight": 1,
              "Criticality_Total": 2,
              "SOTA_Check_Result": "True"
            },
            "IE_Score": 5
          }
        }
      },
      "ZES_Raw_Metrics": {
        "Signal": {
          "T1": 8,
          "T2": 9,
          "T3": 8,
          "Rationale": "내부 사정, 연도별 전략 변화, 이메일 내용 등 구체적 팩트 기반 서술."
        },
        "Noise": {
          "P1": 2,
          "P2": 3,
          "P3": 1,
          "Rationale": "비교적 객관적인 논조 유지."
        },
        "Utility": {
          "V1": 9,
          "V2": 5,
          "V3": 8,
          "Rationale": "오픈AI의 의사결정 구조 이해에 필수적인 인사이트 제공."
        },
        "Fine_Adjustment": {
          "Score": 1,
          "Reason": "역사적 맥락을 꿰뚫는 Deep Dive 기사로 가점 부여."
        }
      }
    }
  },
  "_classification": {
    "category": "Community",
    "is_selected": true,
    "classified_at": "2025-12-28T07:59:57.933465+00:00",
    "classified_by": "desk_user",
    "edition_code": null,
    "edition_name": null,
    "published_at": null,
    "released_at": null
  },
  "_publication": {
    "edition_code": "251228_6",
    "edition_name": "제6호",
    "published_at": "2025-12-28T12:06:36.831530+00:00",
    "released_at": null,
    "firestore_synced": true
  }
}