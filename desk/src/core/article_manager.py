# -*- coding: utf-8 -*-
"""
Article Manager - ê¸°ì‚¬ ì¤‘ì•™ ê´€ë¦¬ ì‹œìŠ¤í…œ
ëª¨ë“  ê¸°ì‚¬ CRUD ë° ìƒíƒœ ì „ì´ì˜ ë‹¨ì¼ ì§„ìž…ì 
"""
import os
import hashlib
from datetime import datetime, timezone
from typing import Optional, List, Dict, Any

from .article_state import ArticleState, can_transition
from .firestore_client import FirestoreClient
from src.core_logic import get_kst_now


class ArticleManager:
    """
    ê¸°ì‚¬ ì¤‘ì•™ ê´€ë¦¬ ì‹œìŠ¤í…œ
    
    ëª¨ë“  ê¸°ì‚¬ ë°ì´í„°ëŠ” 5ê°œ ì„¹ì…˜ìœ¼ë¡œ êµ¬ì„±:
    - _header: ë©”íƒ€ ì •ë³´ (ìƒíƒœ, ë²„ì „, ížˆìŠ¤í† ë¦¬)
    - _original: ì›ë³¸ ì •ë³´ (í¬ë¡¤ëŸ¬ê°€ ìž‘ì„±, ë¶ˆë³€)
    - _analysis: ë¶„ì„ ì •ë³´ (AI Analyzerê°€ ìž‘ì„±)
    - _classification: ë¶„ë¥˜ ì •ë³´ (Desk UIì—ì„œ ìž‘ì„±)
    - _publication: ë°œí–‰ ì •ë³´ (Publisherê°€ ìž‘ì„±)
    """
    
    @property
    def SCHEMA_VERSION(self) -> str:
        return os.getenv('SCHEMA_VERSION', '3.0')
    
    def __init__(self):
        self.db = FirestoreClient()
    
    # =========================================================================
    # Article ID Generation
    # =========================================================================
    
    @staticmethod
    def generate_article_id(url: str) -> str:
        """URLì—ì„œ article_id ìƒì„± (12ìžë¦¬ MD5 í•´ì‹œ)"""
        return hashlib.md5(url.encode()).hexdigest()[:12]
    
    # =========================================================================
    # CRUD Operations
    # =========================================================================
    
    def get(self, article_id: str) -> Optional[Dict[str, Any]]:
        """
        ê¸°ì‚¬ ì¡°íšŒ
        
        ìš°ì„ ìˆœìœ„:
        1. Registry ë©”ëª¨ë¦¬ ìºì‹œ (ë¹„ìš©: 0)
        2. Firestore ì¡°íšŒ (ë¹„ìš© ë°œìƒ) â†’ Registryì— ìºì‹œ
        """
        # 1. Registry ìºì‹œ ìš°ì„  ì¡°íšŒ (Firestore ë¹„ìš© ì ˆê°)
        try:
            from .article_registry import get_registry
            registry = get_registry()
            
            if registry.is_initialized():
                cached = registry.get_full_data(article_id)
                if cached:
                    return self._flatten_article(cached)
        except Exception:
            pass  # Fallback to Firestore
        
        # 2. Firestore ì¡°íšŒ (ì´ˆê¸°í™” ì „ ë˜ëŠ” ìºì‹œ ë¯¸ìŠ¤)
        article = self.db.get_article(article_id)
        if article:
            # [NEW] Lazy Load: Firestoreì—ì„œ ì¡°íšŒí•œ ê¸°ì‚¬ë¥¼ Registryì— ìºì‹œ
            # PUBLISHED/RELEASED ê¸°ì‚¬ë„ í•œ ë²ˆ ì¡°íšŒí•˜ë©´ ì´í›„ ë¹„ìš© ì ˆê°
            try:
                from .article_registry import get_registry
                registry = get_registry()
                if registry.is_initialized():
                    # Register to memory cache (without re-saving to Firestore)
                    info = registry._parse_article_data(article)
                    if info and info.article_id not in registry._articles:
                        info.firestore_synced = True
                        registry._register_article(info, source='lazy_firestore')
                        registry._full_data[info.article_id] = article
                        print(f"ðŸ“¥ [Lazy Load] Cached from Firestore: {article_id}")
            except Exception as e:
                print(f"âš ï¸ [Lazy Load] Cache failed: {e}")
            
            return self._flatten_article(article)
        return None
    
    def get_by_url(self, url: str) -> Optional[Dict[str, Any]]:
        """URLë¡œ ê¸°ì‚¬ ì¡°íšŒ"""
        article_id = self.generate_article_id(url)
        return self.get(article_id)
    
    def create(self, url: str, original_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        ìƒˆ ê¸°ì‚¬ ìƒì„± (Collectorìš©)
        
        Args:
            url: ê¸°ì‚¬ URL
            original_data: ì›ë³¸ ë°ì´í„° (title, text, image, source_id ë“±)
        
        Returns:
            ìƒì„±ëœ ê¸°ì‚¬ ë°ì´í„°
        """
        article_id = self.generate_article_id(url)
        source_id = original_data.get('source_id', 'unknown')
        now = get_kst_now() # [FIX] Use KST
        
        # Schema v3.1: url, source_idë¥¼ _headerì— ì €ìž¥ (ë¶ˆë³€ ì‹ë³„ìž)
        article = {
            '_header': {
                'version': '3.1',  # Schema v3.1
                'article_id': article_id,
                'url': url,                    # ë¶ˆë³€ - í—¤ë”ë¡œ ì´ë™
                'source_id': source_id,        # ë¶ˆë³€ - í—¤ë”ë¡œ ì´ë™
                'state': ArticleState.COLLECTED.value,
                'created_at': now,
                'updated_at': now,
                'state_history': [
                    {
                        'state': ArticleState.COLLECTED.value,
                        'at': now,
                        'by': 'collector'
                    }
                ]
            },
            '_original': {
                'title': original_data.get('title', ''),
                'text': original_data.get('text', ''),
                'image': original_data.get('image'),
                'description': original_data.get('description', ''),
                'published_at': original_data.get('published_at'),
                'crawled_at': now
            },
            '_analysis': None,
            '_classification': None,
            '_publication': None
        }
        
        # Firestoreì— ì €ìž¥
        self.db.save_article(article_id, article)
        
        # ížˆìŠ¤í† ë¦¬ì— URL ë“±ë¡
        self.db.update_history(url, article_id, ArticleState.COLLECTED.value)
        
        # Registryì—ë„ ë“±ë¡ (ë©”ëª¨ë¦¬ ìºì‹œ ë™ê¸°í™”)
        try:
            from .article_registry import get_registry
            registry = get_registry()
            if registry.is_initialized():
                registry.register(article, skip_firestore=True)  # ì´ë¯¸ Firestoreì— ì €ìž¥í–ˆìœ¼ë¯€ë¡œ ìŠ¤í‚µ
        except Exception as e:
            print(f"âš ï¸ [ArticleManager] Registry sync failed: {e}")
        
        return article

    
    def update_state(
        self, 
        article_id: str, 
        new_state: ArticleState, 
        by: str = 'system',
        section_data: Optional[Dict[str, Any]] = None
    ) -> bool:
        """
        ê¸°ì‚¬ ìƒíƒœ ë³€ê²½
        
        Args:
            article_id: ê¸°ì‚¬ ID
            new_state: ìƒˆ ìƒíƒœ
            by: ë³€ê²½ ì£¼ì²´ (collector, analyzer, desk, publisher)
            section_data: í•´ë‹¹ ì„¹ì…˜ì— ì €ìž¥í•  ë°ì´í„°
        
        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        article = self.get(article_id)
        if not article:
            return False
        
        current_state = ArticleState(article['_header']['state'])
        
        # ìƒíƒœ ì „ì´ ìœ íš¨ì„± ê²€ì‚¬
        if not can_transition(current_state, new_state):
            print(f"âš ï¸ Invalid state transition: {current_state} â†’ {new_state}")
            return False
        
        now = get_kst_now()
        
        # í—¤ë” ì—…ë°ì´íŠ¸
        updates = {
            '_header.state': new_state.value,
            '_header.updated_at': now,
        }
        
        # ìƒíƒœ ížˆìŠ¤í† ë¦¬ ì¶”ê°€
        new_history_entry = {
            'state': new_state.value,
            'at': now,
            'by': by
        }
        
        # ì„¹ì…˜ ë°ì´í„° ì—…ë°ì´íŠ¸ ì¤€ë¹„
        section_updates = {}
        if section_data:
            section_map = {
                ArticleState.ANALYZED: '_analysis',
                ArticleState.CLASSIFIED: '_classification',
                ArticleState.REJECTED: '_rejection',
                ArticleState.PUBLISHED: '_publication',
                ArticleState.RELEASED: '_publication',
            }
            if new_state in section_map:
                section_name = section_map[new_state]
                for key, value in section_data.items():
                    # Registryìš© ì  í‘œê¸°ë²• (ì˜ˆ: _analysis.summary)
                    section_updates[f'{section_name}.{key}'] = value
        
        # [Log] Start
        try:
             with open('debug_manager.log', 'a', encoding='utf-8') as f:
                 f.write(f"{datetime.now(timezone.utc)}: [UpdateState] {article_id} -> {new_state.value}\n")
        except: pass

        # Registry ì¸ë©”ëª¨ë¦¬ ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸ + DB/Local ì €ìž¥ (SSOT)
        try:
            from .article_registry import get_registry
            registry = get_registry()
            
            # [DEBUG] Log section_updates content
            print(f"   ðŸ” [ArticleManager] section_updates keys: {list(section_updates.keys()) if section_updates else 'EMPTY'}")
            if section_updates:
                print(f"      Sample values: title_ko={section_updates.get('_analysis.title_ko', 'N/A')[:20] if section_updates.get('_analysis.title_ko') else 'N/A'}...")
            
            # Registryê°€ ì´ˆê¸°í™”ë˜ì–´ ìžˆìœ¼ë©´ ì—…ë°ì´íŠ¸ ìœ„ìž„ (ê¶Œìž¥)
            if registry.is_initialized():
                success = registry.update_state(article_id, new_state.value, by, updates=section_updates)
                
                # ížˆìŠ¤í† ë¦¬ ì—…ë°ì´íŠ¸ (URL ì •ë³´ê°€ í•„ìš”í•˜ì§€ë§Œ ì¼ë‹¨ ìƒëžµí•˜ê±°ë‚˜ ì¶”í›„ ë³´ê°•)
                # self.db.update_history(...) í˜¸ì¶œì´ í•„ìš”í•˜ë‹¤ë©´ ì—¬ê¸°ì„œ ìˆ˜í–‰
                    
                return success
            else:
                # Fallback: Registry ë¯¸ì‚¬ìš© ì‹œ (ì˜ˆì™¸ì  ìƒí™© - ì„œë²„ ì‹œìž‘ ì „ ë“±)
                print("âš ï¸ [ArticleManager] Registry not initialized, skipping update")
                return False
                
        except Exception as e:
            print(f"âŒ [ArticleManager] State update failed: {e}")
            import traceback
            traceback.print_exc()
            return False
    
    def _flatten_article(self, article: Dict[str, Any]) -> Dict[str, Any]:
        """
        ê³„ì¸µí˜• ë°ì´í„°ë¥¼ UI/ë ˆê±°ì‹œ í˜¸í™˜ì„ ìœ„í•´ í‰íƒ„í™” (Flatten)
        Priorities: _publication > _classification > _analysis > _original > _header
        """
        if not article:
            return article
            
        # Start with a shallow copy to preserve original structure (backward compatibility)
        flat = article.copy()
        
        # Merge sections into the top level for frontend convenience
        # 1. Header (Meta)
        if '_header' in article and article['_header']:
            flat.update(article['_header'])
            
        # 2. Original
        if '_original' in article and article['_original']:
            flat.update(article['_original'])
            
        # 3. Analysis
        if '_analysis' in article and article['_analysis']:
            flat.update(article['_analysis'])
            
        # 4. Classification
        if '_classification' in article and article['_classification']:
            flat.update(article['_classification'])
            
        # 5. Publication
        if '_publication' in article and article['_publication']:
            flat.update(article['_publication'])
            
        # _raw is now strictly redundancy since we started with copy, 
        # but kept if explicitly needed by name.
        flat['_raw'] = article
        
        return flat
    
    def update_analysis(self, article_id: str, analysis_data: Dict[str, Any]) -> bool:
        """
        AI ë¶„ì„ ê²°ê³¼ ì €ìž¥ (Analyzerìš©)
        
        Args:
            article_id: ê¸°ì‚¬ ID
            analysis_data: ë¶„ì„ ê²°ê³¼ (title_ko, summary, tags, scores, mll_raw)
            - ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬ëœ í•„ë“œë§Œ ì—…ë°ì´íŠ¸ë¨ (ê¸°ì¡´ ë°ì´í„° ë³´ì¡´)
            
        Note:
            PUBLISHED/RELEASED ìƒíƒœì˜ ê¸°ì‚¬ëŠ” ìƒíƒœ ë³€ê²½ ì—†ì´ ë¶„ì„ ë°ì´í„°ë§Œ ì—…ë°ì´íŠ¸ë¨.
            ì´ë¯¸ ë°œí–‰ëœ ê¸°ì‚¬ì˜ ìƒíƒœê°€ ì˜¤ì—¼ë˜ëŠ” ê²ƒì„ ë°©ì§€í•˜ê¸° ìœ„í•¨.
        """
        # [FIX] í˜„ìž¬ ìƒíƒœ í™•ì¸: PUBLISHED/RELEASEDë©´ ìƒíƒœ ë³€ê²½ ìŠ¤í‚µ
        article = self.get(article_id)
        if not article:
            print(f"âš ï¸ [update_analysis] Article not found: {article_id}")
            return False
        
        current_state = article.get('_header', {}).get('state', '')
        protected_states = ['PUBLISHED', 'RELEASED']
        
        if current_state in protected_states:
            print(f"âš ï¸ [update_analysis] Skipping state change for {article_id} (current: {current_state})")
            # ìƒíƒœ ë³€ê²½ ì—†ì´ ë¶„ì„ ë°ì´í„°ë§Œ ì—…ë°ì´íŠ¸ (ì„ íƒì )
            # ì—¬ê¸°ì„œëŠ” ì•„ì˜ˆ ì—…ë°ì´íŠ¸ë¥¼ ìŠ¤í‚µí•¨ - ë°œí–‰ëœ ê¸°ì‚¬ëŠ” ê±´ë“œë¦¬ì§€ ì•ŠìŒ
            return True  # ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬ (ìž‘ì—… ìžì²´ëŠ” ë¬¸ì œì—†ìŒ)
        
        now = get_kst_now()
        
        # ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬ëœ í•„ë“œë§Œ section_dataì— í¬í•¨ (ê¸°ì¡´ ë°ì´í„° ë³´ì¡´)
        section_data = {}
        
        field_mapping = {
            'title_ko': 'title_ko',
            'summary': 'summary',
            'tags': 'tags',
            'impact_score': 'impact_score',
            'zero_echo_score': 'zero_echo_score',
            'mll_raw': 'mll_raw',
            'impact_evidence': 'impact_evidence',
            'evidence': 'evidence'
        }
        
        for key, field_name in field_mapping.items():
            if key in analysis_data:
                section_data[field_name] = analysis_data[key]
        
        # ì—…ë°ì´íŠ¸ ì‹œê°„ì€ í•­ìƒ ì¶”ê°€
        section_data['analyzed_at'] = now
        
        return self.update_state(
            article_id, 
            ArticleState.ANALYZED, 
            by='analyzer',
            section_data=section_data
        )
    
    def update_classification(self, article_id: str, category: str, is_selected: bool = True) -> bool:
        """
        ë¶„ë¥˜ ì •ë³´ ì €ìž¥ (Desk UIìš©)
        
        Args:
            article_id: ê¸°ì‚¬ ID
            category: ì¹´í…Œê³ ë¦¬
            is_selected: ì„ íƒ ì—¬ë¶€ (ì¤‘ë³µ ì œê±°ìš©)
        """
        now = get_kst_now()
        
        section_data = {
            'category': category,
            'is_selected': is_selected,
            'classified_at': now,
            'classified_by': 'desk_user'
        }
        
        return self.update_state(
            article_id,
            ArticleState.CLASSIFIED,
            by='desk',
            section_data=section_data
        )
    
    def publish(self, article_id: str, edition_code: str, edition_name: str) -> bool:
        """
        ë°œí–‰ ì²˜ë¦¬ (Publisherìš©)
        
        Args:
            article_id: ê¸°ì‚¬ ID
            edition_code: íšŒì°¨ ì½”ë“œ (ì˜ˆ: 251226_5)
            edition_name: íšŒì°¨ ì´ë¦„ (ì˜ˆ: 5í˜¸)
        """
        now = get_kst_now()
        
        section_data = {
            'edition_code': edition_code,
            'edition_name': edition_name,
            'published_at': now,
            'released_at': None,
            'status': 'preview',  # P1 Fix: publication status
            'firestore_synced': True
        }
        
        success = self.update_state(
            article_id,
            ArticleState.PUBLISHED,
            by='publisher',
            section_data=section_data
        )

        if success:
            # 1. Fetch full article data for snapshot
            full_article = self.get(article_id)
            if full_article:
                formatted_article = _format_article_for_snapshot(full_article)
            else:
                # Fallback if somehow missing
                 formatted_article = {'id': article_id, 'title': 'Unknown'}

            # 2. Update Publications Collection (Document)
            # Load existing to append
            pub_doc = self.db.get_publication(edition_code)
            
            if not pub_doc:
                # Parse index from edition_code (YYMMDD_INDEX format)
                edition_index = 1
                if '_' in edition_code:
                    try:
                        edition_index = int(edition_code.split('_')[1])
                    except (ValueError, IndexError):
                        edition_index = 1
                
                # Initialize new publication document
                # [FIX] nowê°€ datetime ê°ì²´ì¼ ìˆ˜ ìžˆìœ¼ë¯€ë¡œ ë¬¸ìžì—´ë¡œ ë³€í™˜
                now_str = now if isinstance(now, str) else now.isoformat() if hasattr(now, 'isoformat') else str(now)
                date_str = now_str[:10] if len(now_str) >= 10 else now_str
                
                pub_doc = {
                    'edition_code': edition_code,
                    'edition_name': edition_name,
                    'index': edition_index,  # ë°œí–‰ ë²ˆí˜¸ (ëˆ„ë½ ìˆ˜ì •)
                    'published_at': now_str,
                    'updated_at': now_str,
                    'status': 'preview',
                    'schema_version': '3.1',  # í•˜ë“œì½”ë”© (í™˜ê²½ë³€ìˆ˜ íŒŒì‹± ì˜¤ë¥˜ ë°©ì§€)
                    'article_count': 0,
                    'article_ids': [],
                    'articles': [],
                    'date': date_str
                }
            
            # Append new article if not exists
            if article_id not in pub_doc.get('article_ids', []):
                pub_doc['article_ids'] = pub_doc.get('article_ids', []) + [article_id]
                pub_doc['articles'] = pub_doc.get('articles', []) + [formatted_article]
                pub_doc['article_count'] = len(pub_doc['article_ids'])
                pub_doc['updated_at'] = now
            
            # Save SSOT
            print(f"ðŸ“ [Publish] Saving publication document: {edition_code}")
            try:
                self.db.save_publication(edition_code, pub_doc)
                print(f"âœ… [Publish] Publication document saved successfully")
            except Exception as e:
                print(f"âŒ [Publish] Failed to save publication: {e}")
                import traceback
                traceback.print_exc()
                # Rollback article state on failure
                self.update_state(article_id, ArticleState.CLASSIFIED, by='publish_rollback')
                return False
            
            # 3. Update _meta (Summary)
            print(f"ðŸ“ [Publish] Updating publications meta...")
            try:
                meta = self.db.get_publications_meta() or {'issues': [], 'lastIndex': 0}
                issues = meta.get('issues', [])
                
                # Get current index from pub_doc
                current_index = pub_doc.get('index', 1)
                
                # Update lastIndex (í•­ìƒ ìµœëŒ€ê°’ ìœ ì§€)
                meta['lastIndex'] = max(meta.get('lastIndex', 0), current_index)
                
                # Check existing
                existing_idx = next((i for i, x in enumerate(issues) if x.get('edition_code') == edition_code), -1)
                
                # pub_docì—ì„œ í•„ìš”í•œ í•„ë“œë§Œ ì¶”ì¶œ (ì¤‘ë³µ í•„ë“œ ì œê±°: code, name, count)
                issue_summary = {
                    'edition_code': edition_code,
                    'edition_name': edition_name,
                    'index': current_index,
                    'article_count': pub_doc['article_count'],
                    'published_at': pub_doc['published_at'],
                    'updated_at': now,
                    'status': pub_doc.get('status', 'preview'),
                    'schema_version': '3.1'
                }
                
                if existing_idx >= 0:
                    issues[existing_idx] = issue_summary
                else:
                    issues.insert(0, issue_summary)
                
                meta['issues'] = issues
                meta['latest_updated_at'] = now
                self.db.update_publications_meta(meta)
                print(f"âœ… [Publish] Publications meta updated successfully")
            except Exception as e:
                print(f"âŒ [Publish] Failed to update publications meta: {e}")
                import traceback
                traceback.print_exc()
                # Rollback article state on failure
                self.update_state(article_id, ArticleState.CLASSIFIED, by='publish_rollback')
                return False

            # Cache Warmup
            self._warmup_cache()
        
        return success

    def find_duplicates(self, article_id: str, threshold: float = 0.6) -> List[Dict[str, Any]]:
        """
        ì¤‘ë³µ ì˜ì‹¬ ê¸°ì‚¬ ê²€ìƒ‰ (Title similarity based)
        """
        from difflib import SequenceMatcher
        
        target = self.get_article(article_id)
        if not target:
            return []
            
        target_title = target.get('_analysis', {}).get('title_ko') or target.get('_original', {}).get('title', '')
        if not target_title:
            return []
            
        # Recent articles (e.g., last 1000)
        candidates = self.db.list_recent_articles(limit=1000)
        
        results = []
        for cand in candidates:
            if cand['id'] == article_id:
                continue
                
            cand_title = cand.get('_analysis', {}).get('title_ko') or cand.get('_original', {}).get('title', '')
            if not cand_title:
                continue
                
            ratio = SequenceMatcher(None, target_title, cand_title).ratio()
            if ratio >= threshold:
                results.append({
                    'id': cand['id'],
                    'title': cand_title,
                    'similarity': round(ratio * 100, 1),
                    'state': cand.get('_header', {}).get('state', 'unknown'),
                    'published_at': cand.get('_original', {}).get('published_at')
                })
        
        # Sort by similarity desc
        results.sort(key=lambda x: x['similarity'], reverse=True)
        return results
    
    def reject(self, article_id: str, reason: str = 'cutline', by: str = 'system') -> bool:
        """
        ê¸°ì‚¬ íê¸°
        
        Args:
            article_id: ê¸°ì‚¬ ID
            reason: íê¸° ì‚¬ìœ  (cutline: ì»¤íŠ¸ë¼ì¸, duplicate: ì¤‘ë³µ, manual: ìˆ˜ë™)
            by: íê¸° ì£¼ì²´
        """
        now = get_kst_now()
        
        return self.update_state(
            article_id,
            ArticleState.REJECTED,
            by=by,
            section_data={
                'reason': reason,
                'rejected_at': now,
                'rejected_by': by
            }
        )
    

    
    # =========================================================================
    # Query Operations
    # =========================================================================
    
    def find_by_state(self, state: ArticleState, limit: int = 100) -> List[Dict[str, Any]]:
        """
        ìƒíƒœë³„ ê¸°ì‚¬ ëª©ë¡ ì¡°íšŒ
        - Registry(ë©”ëª¨ë¦¬ ì¸ë±ìŠ¤) ìš°ì„  ì‚¬ìš©: ì‹¤í–‰ ì‹œ ê²°ì •ëœ ì •ë³¸ ëª©ë¡(SSOT) ì¤€ìˆ˜
        - ê° IDì— ëŒ€í•´ get() í˜¸ì¶œ: ì™„ì „í•œ ë°ì´í„° ë¡œë“œ
        """
        from src.core.article_registry import get_registry
        registry = get_registry()
        
        result = []
        
        # 1. Registry ì‚¬ìš© (ì´ˆê¸°í™”ëœ ê²½ìš° - ê¶Œìž¥)
        if registry.is_initialized():
            article_infos = registry.find_by_state(state.value, limit)
            print(f"ðŸ” [DEBUG] Registry.find_by_state('{state.value}'): {len(article_infos)} infos")
            for info in article_infos:
                # Registryê°€ ì´ë¯¸ ì •ë³¸ IDë¥¼ ì•Œê³  ìžˆìŒ -> get()ìœ¼ë¡œ ë°ì´í„° ë¡œë“œ
                article = self.get(info.article_id)
                if article:
                    result.append(article)
                else:
                    print(f"âš ï¸ [DEBUG] get('{info.article_id}') returned None!")
            print(f"ðŸ” [DEBUG] Final result: {len(result)} articles")
            return result

        # 2. Fallback (DB ì§ì ‘ ì¡°íšŒ - ì´ˆê¸°í™” ì „)
        # 1. article_id ëª©ë¡ ì¡°íšŒ (ë³‘í•©ëœ ëª©ë¡)
        raw_articles = self.db.list_articles_by_state(state.value, limit)
        
        # 2. ê° articleì— ëŒ€í•´ get()ìœ¼ë¡œ ì™„ì „í•œ ë°ì´í„° ì¡°íšŒ
        for raw in raw_articles:
            article_id = raw.get('_header', {}).get('article_id') or raw.get('id')
            if article_id:
                complete = self.get(article_id)
                if complete:
                    result.append(complete)
                else:
                    result.append(raw)
            else:
                result.append(raw)
        
        return result

    
    def find_collected(self, limit: int = 100) -> List[Dict[str, Any]]:
        """ìˆ˜ì§‘ëœ ê¸°ì‚¬ ëª©ë¡ (AI ë¶„ì„ ëŒ€ê¸°)"""
        return self.find_by_state(ArticleState.COLLECTED, limit)
    
    def find_analyzed(self, limit: int = 100) -> List[Dict[str, Any]]:
        """ë¶„ì„ ì™„ë£Œ ê¸°ì‚¬ ëª©ë¡ (ë¶„ë¥˜ ëŒ€ê¸°)"""
        return self.find_by_state(ArticleState.ANALYZED, limit)
    
    def find_classified(self, limit: int = 100) -> List[Dict[str, Any]]:
        """ë¶„ë¥˜ ì™„ë£Œ ê¸°ì‚¬ ëª©ë¡ (ë°œí–‰ ëŒ€ê¸°)"""
        return self.find_by_state(ArticleState.CLASSIFIED, limit)
    
    def find_recent(self, limit: int = 100) -> List[Dict[str, Any]]:
        """ìµœê·¼ ê¸°ì‚¬ ëª©ë¡"""
        return self.db.list_recent_articles(limit)
    
    # =========================================================================
    # URL Check
    # =========================================================================
    
    def is_url_processed(self, url: str) -> bool:
        """URLì´ ì´ë¯¸ ì²˜ë¦¬ë˜ì—ˆëŠ”ì§€ í™•ì¸"""
        result = self.db.check_url_exists(url)
        return result is not None
    
    def get_url_status(self, url: str) -> Optional[str]:
        """URLì˜ ì²˜ë¦¬ ìƒíƒœ ì¡°íšŒ"""
        result = self.db.check_url_exists(url)
        if result:
            return result.get('status')
        return None

    # =========================================================================
    # Publication / Edition Operations (In-Memory Cache)
    # =========================================================================
    
    _local_cache = {
        'meta': None,
        'articles': {}  # edition_code -> list[dict]
    }
    
    def _warmup_cache(self):
        """ìµœê·¼ 2íšŒì°¨ ë°ì´í„° ë©”ëª¨ë¦¬ ë¡œë“œ"""
        try:
            # 1. Meta ë¡œë“œ
            meta = self.db.get_publications_meta()
            if not meta:
                print("[ArticleManager] No publications meta found.")
                return
            
            self._local_cache['meta'] = meta
            
            # 2. ìµœê·¼ 2íšŒì°¨ ê¸°ì‚¬ ë¡œë“œ
            issues = meta.get('issues', [])
            # published_at ì—­ìˆœ ì •ë ¬ ë³´ìž¥
            issues.sort(key=lambda x: x.get('published_at', ''), reverse=True)
            
            recent_codes = [issue.get('edition_code') or issue.get('code') for issue in issues[:2]]
            recent_codes = [c for c in recent_codes if c]  # None ì œê±°
            
            for code in recent_codes:
                articles = self.db.list_articles_by_edition(code)
                self._local_cache['articles'][code] = articles
                
            print(f"[ArticleManager] Cached {len(recent_codes)} recent editions: {recent_codes}")
            
        except Exception as e:
            print(f"[ArticleManager] Cache warmup failed: {e}")

    def get_editions(self, limit: int = 20) -> List[Dict[str, Any]]:
        """ë°œí–‰ëœ íšŒì°¨ ëª©ë¡ ì¡°íšŒ (_meta ê¸°ë°˜ + Cache, í˜¸í™˜ì„± ë³´ìž¥)"""
        # 1. Cache Hit Check - use get_issues_from_meta for proper formatting
        if self._local_cache.get('meta'):
            # Already have meta, use the optimized method
            issues = self.db.get_issues_from_meta()
            return issues[:limit]

        # 2. Fallback to DB (get_issues_from_meta handles everything)
        issues = self.db.get_issues_from_meta()
        if issues:
            # Cache the meta for future use
            self._local_cache['meta'] = self.db.get_publications_meta()
        return issues[:limit]


    def get_edition_articles(self, edition_code: str) -> List[Dict[str, Any]]:
        """íŠ¹ì • íšŒì°¨ì˜ ê¸°ì‚¬ ëª©ë¡ ì¡°íšŒ (Cache ìš°ì„ )"""
        # 1. Cache Hit Check
        if edition_code in self._local_cache.get('articles', {}):
            return self._local_cache['articles'][edition_code]

        # 2. DB Query
        articles = self.db.list_articles_by_edition(edition_code)
        return articles

    def release_edition(self, edition_code: str) -> Dict[str, Any]:
        """
        íšŒì°¨ ì •ì‹ ë°œí–‰ (Preview -> Released)
        1. ë©”íƒ€ ë°ì´í„° ìƒíƒœ ë³€ê²½
        2. ì†Œì† ê¸°ì‚¬ ìƒíƒœ ì¼ê´„ ë³€ê²½ (PUBLISHED -> RELEASED)
        """
        now = get_kst_now()
        
        # 1. ë©”íƒ€ ë°ì´í„° í™•ì¸ ë° ì—…ë°ì´íŠ¸
        meta = self.db.get_publications_meta()
        if not meta:
            return {'success': False, 'error': 'Meta not found'}
            
        issues = meta.get('issues', [])
        target_issue = None
        target_idx = -1
        
        for idx, iss in enumerate(issues):
            if iss.get('edition_code') == edition_code or iss.get('code') == edition_code:
                target_issue = iss
                target_idx = idx
                break
                
        if not target_issue:
            return {'success': False, 'error': 'Edition not found'}
            
        if target_issue.get('status') == 'released':
            return {'success': True, 'message': 'Already released', 'released_count': 0}
            
        # Update Meta Status
        target_issue['status'] = 'released'
        target_issue['released_at'] = now
        issues[target_idx] = target_issue
        
        # IMPORTANT: Update latest_updated_at so Web can detect the change
        meta['latest_updated_at'] = now
        
        self.db.update_publications_meta(meta)
        
        # Update Individual Publication Doc
        pub_doc = self.db.get_publication(edition_code) or {}
        pub_doc['status'] = 'released'
        pub_doc['released_at'] = now
        self.db.save_publication(edition_code, pub_doc)
        
        # 2. Update Articles' _publication.status (ìƒíƒœëŠ” PUBLISHED ìœ ì§€)
        # ê¸°ì‚¬ ìƒíƒœ(PUBLISHEDâ†’RELEASED)ëŠ” ë³€ê²½í•˜ì§€ ì•ŠìŒ
        # ë°œí–‰ì •ë³´(_publication.status)ë§Œ previewâ†’releasedë¡œ ë³€ê²½
        articles = self.get_edition_articles(edition_code)
        updated_count = 0
        
        for art in articles:
            art_id = art.get('article_id') or art.get('id')
            if art_id:
                # _publication.statusë§Œ ì—…ë°ì´íŠ¸ (ê¸°ì‚¬ ìƒíƒœëŠ” PUBLISHED ìœ ì§€)
                try:
                    self.db.update_article(art_id, {
                        '_publication.status': 'released',
                        '_publication.released_at': now
                    })
                    updated_count += 1
                except Exception as e:
                    print(f"âš ï¸ [Release] Failed to update article {art_id}: {e}")
                
        # 3. Warmup Cache
        self._warmup_cache()
        
        return {
            'success': True,
            'edition_code': edition_code,
            'released_count': updated_count,
            'released_at': now
        }

    def delete_edition(self, edition_code: str) -> Dict[str, Any]:
        """
        íšŒì°¨ íŒŒê¸° (Unpublish/Rollback)
        1. ë©”íƒ€ ë°ì´í„°ì—ì„œ í•´ë‹¹ íšŒì°¨ ì œê±°
        2. publications ì»¬ë ‰ì…˜ì—ì„œ ë¬¸ì„œ ì‚­ì œ
        3. ì†Œì† ê¸°ì‚¬ë“¤ì˜ ìƒíƒœë¥¼ CLASSIFIEDë¡œ ì›ë³µ (Draft ëª©ë¡ìœ¼ë¡œ ë³µê·€)
        """
        # 1. ë©”íƒ€ ë°ì´í„° í™•ì¸
        meta = self.db.get_publications_meta()
        if not meta:
            return {'success': False, 'error': 'Meta not found'}
            
        issues = meta.get('issues', [])
        
        # í•´ë‹¹ íšŒì°¨ í•„í„°ë§ (ì œê±°)
        initial_len = len(issues)
        issues = [i for i in issues if not (i.get('edition_code') == edition_code or i.get('code') == edition_code)]
        
        if len(issues) == initial_len:
             return {'success': False, 'error': 'Edition not found in meta'}

        # Meta ì—…ë°ì´íŠ¸
        meta['issues'] = issues
        meta['latest_updated_at'] = datetime.now(timezone.utc).isoformat()
        self.db.update_publications_meta(meta)
        
        # 2. ê¸°ì‚¬ ëª©ë¡ í™•ë³´ (ë¬¸ì„œ ì‚­ì œ ì „)
        # ì‚­ì œ ëŒ€ìƒ ê¸°ì‚¬ë“¤ì„ ì°¾ê¸° ìœ„í•´ publication ë¬¸ì„œ ì¡°íšŒ
        # ë§Œì•½ ì´ë¯¸ ë¬¸ì„œê°€ ì—†ìœ¼ë©´ index ê²€ìƒ‰ ì‹œë„
        pub_doc = self.db.get_publication(edition_code)
        target_article_ids = []
        
        if pub_doc:
            target_article_ids = pub_doc.get('article_ids', [])
        
        # í˜¹ì‹œ pub_docì— ì—†ë”ë¼ë„ indexë¡œ ì°¾ì•„ë³¸ë‹¤ (Safety)
        if not target_article_ids:
             query = self.db._get_collection('articles').where('_publication.edition_code', '==', edition_code)
             docs = query.stream()
             target_article_ids = [doc.id for doc in docs]

        # 3. ê°œë³„ íšŒì°¨ ë¬¸ì„œ ì‚­ì œ
        doc_ref = self.db._get_collection('publications').document(edition_code)
        doc_ref.delete()
        
        # 4. ê¸°ì‚¬ ìƒíƒœ ì›ë³µ (Revert Articles)
        reverted_count = 0
        
        print(f"ðŸ“‚ [DeleteEdition] Reverting {len(target_article_ids)} articles to CLASSIFIED")
            
        for art_id in target_article_ids:
            print(f"   ðŸ”„ Reverting {art_id}...")
            
            # ìƒíƒœë§Œ CLASSIFIEDë¡œ ë³€ê²½ (section_data ì—†ì´! _classification ë³´ì¡´)
            success = self.update_state(
                art_id, 
                ArticleState.CLASSIFIED, 
                by='publisher'
                # section_data ì œê±° - _classification ë°ì´í„°ë¥¼ ë®ì–´ì“°ì§€ ì•ŠìŒ
            )
            
            if success:
                reverted_count += 1
                print(f"      âœ… Reverted to CLASSIFIED")
            else:
                print(f"      âŒ Failed to revert")
            
        # Cache Warmup
        self._warmup_cache()
        
        return {
            'success': True,
            'edition_code': edition_code,
            'reverted_count': reverted_count
        }


# =============================================================================
# Helper Functions (Module Level)
# =============================================================================

def _format_article_for_snapshot(article: dict) -> dict:
    """ê¸°ì‚¬ ë°ì´í„°ë¥¼ ë°œí–‰ ìŠ¤ëƒ…ìƒ·ìš©ìœ¼ë¡œ ë³€í™˜ (User Schema ì¤€ìˆ˜)"""
    header = article.get('_header', {})
    original = article.get('_original', {})
    analysis = article.get('_analysis', {}) or {}
    classification = article.get('_classification', {}) or {}
    
    # [FIX] DatetimeWithNanosecondsë¥¼ ë¬¸ìžì—´ë¡œ ë³€í™˜
    def to_str(val):
        if val is None:
            return ''
        if isinstance(val, str):
            return val
        if hasattr(val, 'isoformat'):
            return val.isoformat()
        return str(val)
    
    published_at = to_str(original.get('published_at')) or to_str(header.get('created_at'))
    date_str = published_at[:10] if len(published_at) >= 10 else ''
    
    return {
        'id': header.get('article_id'),
        'source_id': original.get('source_id'),
        'title': original.get('title'),
        'title_ko': analysis.get('title_ko'),
        'title_en': analysis.get('title_en', ''),
        'url': original.get('url'),
        'published_at': published_at,
        'category': classification.get('category'),
        'impact_score': analysis.get('impact_score'),
        'zero_echo_score': analysis.get('zero_echo_score'),
        'summary': analysis.get('summary'),
        'tags': analysis.get('tags', []),
        'layout_type': classification.get('layout_type', 'Standard'),
        'date': date_str,
        'filename': f"{original.get('source_id')}_{header.get('article_id')}.json"
    }

