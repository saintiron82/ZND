{
  "title": "Waymo's leaked system prompt reveals a 1,200-line rulebook for its in-car Gemini assistant",
  "description": "Jane Manchun Wong just found a 1,200-line system prompt for Waymo's unreleased Gemini assistant buried in their app code. A strong example of prompt engineering for anyone building AI assistants.",
  "image": "https://the-decoder.com/wp-content/uploads/2025/12/waymo_press_shot-scaled.jpg",
  "text": "Prompt engineers, take note: Jane Manchun Wong has uncovered the system prompt for Waymo's unreleased Gemini AI assistant, a specification over 1,200 lines long buried in the Waymo app's code. The assistant (still) runs on Gemini 2.5 Flash and helps passengers during their ride. It can answer questions, adjust the air conditioning, and change the music, but it can't steer the vehicle or alter the route. The instructions draw a clear line between the AI assistant (Gemini) and the autonomous driving system (Waymo Driver). The prompt uses a trigger-instruction-response pattern throughout: each rule defines a trigger, an action instruction, and often example responses. Wrong and correct answers appear side by side to clarify the desired behavior. For ambiguous questions: first clarify, then draw conclusions, finally deflect. Hard limits are enforced through prohibition lists with alternative answers. Wong's full analysis has many more details. Ad DEC_D_Incontent-1",
  "published_at": "2025-12-25T12:43:20+00:00",
  "url": "https://the-decoder.com/waymos-leaked-system-prompt-reveals-a-1200-line-rulebook-for-its-in-car-gemini-assistant/",
  "source_id": "the_decoder",
  "article_id": "21c7d24ace56",
  "cached_at": "2025-12-25T15:52:45.119545+00:00",
  "updated_at": "2025-12-25T15:52:45.119545+00:00"
}