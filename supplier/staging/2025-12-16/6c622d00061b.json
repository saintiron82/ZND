{
  "article_id": "6c622d",
  "author": [
    "임대준 기자"
  ],
  "cached_at": "2025-12-16T07:59:28.289394+00:00",
  "image": "https://cdn.aitimes.com/news/photo/202512/204804_206172_2917.jpg",
  "modified_at": "2025-12-15T18:41:41+09:00",
  "published_at": "2025-12-15T18:00:00+09:00",
  "summary": "오픈AI 연구원은 팟캐스트에서 AGI 달성의 병목은 데이터나 계산이 아닌 '인간의 피드백 속도'라고 주장. 향후 AI와의 상호작용이 근본적으로 변화할 것이라 예측.",
  "text": "기사를 읽어드립니다. 오픈AI의 연구원이 AI 개발의 지연 이유로 '인간'을 꼽았다. AI 개발에서 발생하는 병목 현상의 이유가 더 이상 데이터나 계산 규모가 아니라, 인간적인 요소라는 주장이다. 알렉산더 앰비리코스 오픈AI 코덱스 제품 책임자는 15일 공개된 '레니의 팟캐스트'에 출연, \"인공일반지능(AGI) 달성에 있어 가장 저평가된 병목 현상은 사람(people)\"이라고 말했다. 그는 \"모델을 훨씬 더 개선하는 데 여전히 필요한 '고품질의 인간 피드백'의 양 때문\"이라며 \"아직 피드백 루프를 완전 자동화하는 데 근접하지 못했다\"라고 설명했다. 이는 일반적인 모델 훈련 과정에서 이뤄지는 '인간 피드백을 통한 강화 학습(RLHF)'을 의미하는 것이다. 인간 평가자는 AI가 생성한 수많은 답변을 일일이 읽고, 인지적으로 판단하고, 가치관과 안전 기준에 따라 순위를 매겨야 한다. 이 과정은 AI의 처리 속도에 비해 근본적으로 느리다. 또 이 작업을 수행하려면 수많은 숙련된 평가자를 고용하고 관리해야 하므로, 모델을 반복적으로 개선할 때마다 막대한 인건비가 발생한다. 이런 느리고 비싼 과정 때문에 AI 모델의 반복(Iteration)과 개선 속도가 제한되고, AGI로 가는 길이 늦춰진다는 말이다. 그는 AI 개발뿐만 아니라, 활용에서도 인간이 AI를 따라잡지 못한다고 지적했다. \"인간이 프롬프트를 얼마나 빨리 입력할 수 있는지, 인간이 응답을 얼마나 빨리 읽을 수 있는지, 그리고 인간이 얼마나 빨리 반복 작업을 결정할 수 있는지 등은 인간이 병목현상에 부딪혔다는 증거\"라는 것이다. 이어 \"모델은 이제 충분히 빨라져서 '우리'가 병목 현상이 됐다. 더 이상 모델이나 응답 시간이 아니다\"라고 말했다. \"따라서 우리가 모델과 상호 작용하는 방식은 앞으로 몇년 동안 근본적으로 바뀔 것이며, 앞으로는 프롬프트를 입력하는 것이 피자를 주문하기 위해 1-800 번호로 전화하는 것만큼 구식으로 느껴질 것\"이라고 말했다. 이처럼 그는 모델 개발부터 사용까지 인간의 인지와 처리 속도가 이제는 모델을 따라가지 못한다는 점을 강조했다. 이로 인해 AI와 상호작용하는 방식도 음성이나 생각을 읽어내는 방식으로 바뀔 것이라는 예측이다. 그리고 그 시작이 2026년이라고 강조했다. 나아가 이런 제약에서 벗어날 수 있도록 인간이 모델 출력을 검증하는 방식도 바꿔야 한다고 주장했다. \"우리는 에이전트의 모든 작업을 지켜볼 수 있지만, 작업의 유효성을 검증하지 않으면 여전히 병목 현상이 발생한다. 예를 들어, 인간이 모든 코드를 검토할 수 있을까\"라고 반문했다. 따라서 \"에이전트가 유용하게 작동하도록 시스템을 재구축할 수 있다면, 급격한 효율 향상이 시작될 것\"이라고 설명했다. 이처럼 모델 개발의 핵심 과제는 성능 향상을 넘어, 인간의 가치와 의도를 정렬(align)하는 것으로 변해가고 있다는 말이다. 그 과정에서 인간의 가치 시스템을 AI에 반영하는 것이 어렵다는 설명이다. 이 때문에 다음 큰 병목은 '신뢰'가 될 것으로 봤다. 인간이 복잡한 다단계 작업을 AI 에이전트에게 기꺼이 신뢰하고 위임할 수 있어야 한다는 것이다. 한편, 이날 인터뷰에서는 오픈AI가 '코덱스'를 활용해 동영상 공유 앱 '소라'를 개발한 사례도 소개됐다. 오픈AI는 엔지니어 4명과 코덱스의 협업으로 28일 만에 초고속으로 소라 안드로이드 앱을 개발했다는 것이다. 이 과정에 코덱스는 프로젝트 전체 코드의 85%를 담당했다. 임대준 기자 ydj@aitimes.com",
  "title": "오픈AI &quot;AI 개발의 병목 현상은 '인간'...상호작용 방식 바뀔 것&quot;",
  "url": "https://www.aitimes.com/news/articleView.html?idxno=204804",
  "title_ko": "오픈AI 'AI 개발의 병목 현상은 인간...상호작용 방식 바뀔 것'",
  "tags": [
    "OpenAI",
    "AGI",
    "Future Tech Insight"
  ],
  "impact_score": 4.5,
  "Impact_Analysis_IS": {
    "Analysis_Log": {
      "WHO_Primary_Entity": "OpenAI",
      "WHO_Primary_Tier_Source": "Software_LLM_Dev (Tier 1)",
      "WHO_Entity_Tier": 1,
      "WHO_Secondary_Entity": "N/A",
      "WHO_Secondary_Tier": null,
      "Gap_Calculation_Log": "|1 (Entity) - 2 (Evidence)| = 1 -> Score 0.5",
      "WHAT_X_Magnitude": 3,
      "WHAT_Y_Evidence": 2,
      "SOTA_Check_Result": "Global Insight"
    },
    "Scores": {
      "IW_Score": 1.5,
      "Gap_Score": 0.5,
      "Context_Bonus": 1.5,
      "IE_Breakdown_Total": {
        "Scope_Total": 0.5,
        "Criticality_Total": 0.5
      },
      "Adjustment_Score": 0
    },
    "Reasoning": {
      "Score_Justification": "Tier 1 entity discussing Macro paradigm shift (Paradigm Shift Bonus +1.5)."
    }
  },
  "zero_echo_score": 2.2,
  "Evidence_Analysis_ZES": {
    "ZES_Penalty_Check": {
      "Penalty_Focus_Raw_Sum": 0,
      "Penalty_Clipping_Indicator": false
    },
    "ZES_Score_Vector": {
      "Positive_Scores": [
        {
          "ID": "P_3_Deep_Tech_Insight",
          "Raw_Score": 1,
          "Weight": 1.8,
          "Evidence": "Human Bottleneck Theory"
        },
        {
          "ID": "P_6_Latest_Trends",
          "Raw_Score": 1,
          "Weight": 0.96,
          "Evidence": "AGI Roadmap"
        }
      ],
      "Negative_Scores": []
    },
    "Analysis_Commentary": {
      "ZES_Summary": "기술적 통찰력이 매우 높은 기사. AI 개발 단계의 병목 현상을 구체적 근거(RLHF의 한계)와 함께 제시함."
    }
  },
  "raw_analysis": {
    "Article_ID": "6c622d",
    "Meta": {
      "Headline": "오픈AI 'AI 개발의 병목 현상은 인간...상호작용 방식 바뀔 것'",
      "summary": "오픈AI 연구원은 팟캐스트에서 AGI 달성의 병목은 데이터나 계산이 아닌 '인간의 피드백 속도'라고 주장. 향후 AI와의 상호작용이 근본적으로 변화할 것이라 예측.",
      "Tag": [
        "OpenAI",
        "AGI",
        "Future Tech Insight"
      ]
    },
    "PR_Scanner_Log": {
      "Detected_Triggers": [
        "근본적으로 (Fundamentally)",
        "초고속 (Ultra-speed)"
      ],
      "Marketing_Jargon_Count": 2,
      "Qualifier_Check": "Clean",
      "Sales_Intent": "Low"
    },
    "Impact_Analysis_IS": {
      "Analysis_Log": {
        "WHO_Primary_Entity": "OpenAI",
        "WHO_Primary_Tier_Source": "Software_LLM_Dev (Tier 1)",
        "WHO_Entity_Tier": 1,
        "WHO_Secondary_Entity": "N/A",
        "WHO_Secondary_Tier": null,
        "Gap_Calculation_Log": "|1 (Entity) - 2 (Evidence)| = 1 -> Score 0.5",
        "WHAT_X_Magnitude": 3,
        "WHAT_Y_Evidence": 2,
        "SOTA_Check_Result": "Global Insight"
      },
      "Scores": {
        "IW_Score": 1.5,
        "Gap_Score": 0.5,
        "Context_Bonus": 1.5,
        "IE_Breakdown_Total": {
          "Scope_Total": 0.5,
          "Criticality_Total": 0.5
        },
        "Adjustment_Score": 0
      },
      "Reasoning": {
        "Score_Justification": "Tier 1 entity discussing Macro paradigm shift (Paradigm Shift Bonus +1.5)."
      }
    },
    "Evidence_Analysis_ZES": {
      "ZES_Penalty_Check": {
        "Penalty_Focus_Raw_Sum": 0,
        "Penalty_Clipping_Indicator": false
      },
      "ZES_Score_Vector": {
        "Positive_Scores": [
          {
            "ID": "P_3_Deep_Tech_Insight",
            "Raw_Score": 1,
            "Weight": 1.8,
            "Evidence": "Human Bottleneck Theory"
          },
          {
            "ID": "P_6_Latest_Trends",
            "Raw_Score": 1,
            "Weight": 0.96,
            "Evidence": "AGI Roadmap"
          }
        ],
        "Negative_Scores": []
      },
      "Analysis_Commentary": {
        "ZES_Summary": "기술적 통찰력이 매우 높은 기사. AI 개발 단계의 병목 현상을 구체적 근거(RLHF의 한계)와 함께 제시함."
      }
    }
  },
  "source_id": "aitimes",
  "original_title": "오픈AI &quot;AI 개발의 병목 현상은 '인간'...상호작용 방식 바뀔 것&quot;",
  "evidence": {
    "score_vector": {
      "Positive_Scores": [
        {
          "ID": "P_3_Deep_Tech_Insight",
          "Raw_Score": 1,
          "Weight": 1.8,
          "Evidence": "Human Bottleneck Theory"
        },
        {
          "ID": "P_6_Latest_Trends",
          "Raw_Score": 1,
          "Weight": 0.96,
          "Evidence": "AGI Roadmap"
        }
      ],
      "Negative_Scores": []
    },
    "commentary": {
      "ZES_Summary": "기술적 통찰력이 매우 높은 기사. AI 개발 단계의 병목 현상을 구체적 근거(RLHF의 한계)와 함께 제시함."
    }
  },
  "impact_evidence": {
    "scores": {
      "IW_Score": 1.5,
      "Gap_Score": 0.5,
      "Context_Bonus": 1.5,
      "IE_Breakdown_Total": {
        "Scope_Total": 0.5,
        "Criticality_Total": 0.5
      },
      "Adjustment_Score": 0
    },
    "analysis_log": {
      "WHO_Primary_Entity": "OpenAI",
      "WHO_Primary_Tier_Source": "Software_LLM_Dev (Tier 1)",
      "WHO_Entity_Tier": 1,
      "WHO_Secondary_Entity": "N/A",
      "WHO_Secondary_Tier": null,
      "Gap_Calculation_Log": "|1 (Entity) - 2 (Evidence)| = 1 -> Score 0.5",
      "WHAT_X_Magnitude": 3,
      "WHAT_Y_Evidence": 2,
      "SOTA_Check_Result": "Global Insight"
    },
    "reasoning": {
      "Score_Justification": "Tier 1 entity discussing Macro paradigm shift (Paradigm Shift Bonus +1.5)."
    }
  },
  "crawled_at": "2025-12-16T09:17:16.758088+00:00",
  "edition": "251216_TUE_1",
  "saved": true,
  "saved_at": "2025-12-16T09:17:16.762245+00:00",
  "staged_at": "2025-12-16T10:01:04.391480+00:00",
  "staged": true
}