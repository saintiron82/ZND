# -*- coding: utf-8 -*-
"""
ë°œí–‰ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸
- ê¸°ì¡´ ë°œí–‰ëœ íšŒì°¨ì˜ articles ë°°ì—´ì„ ìµœì‹  í¬ë§·ìœ¼ë¡œ ì—…ë°ì´íŠ¸
- ë¡œì»¬ ìºì‹œì—ì„œ ìƒì„¸ ì •ë³´ë¥¼ ì½ì–´ì™€ì„œ Firebase ë¬¸ì„œ ì—…ë°ì´íŠ¸

ì‚¬ìš©ë²•:
    python migrate_publications.py              # ì‹œë®¬ë ˆì´ì…˜ (ë³€ê²½ ì—†ìŒ)
    python migrate_publications.py --execute    # ì‹¤ì œ ë§ˆì´ê·¸ë ˆì´ì…˜
"""
import os
import sys
import json
from datetime import datetime, timezone

# Add parent directory to path for imports
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.db_client import DBClient

BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
CACHE_DIR = os.path.join(BASE_DIR, 'cache')


def find_article_in_cache(article_id: str) -> dict | None:
    """ìºì‹œì—ì„œ article_idë¡œ ê¸°ì‚¬ ì°¾ê¸°"""
    if not os.path.exists(CACHE_DIR):
        return None
    
    # ëª¨ë“  ë‚ ì§œ í´ë” ê²€ìƒ‰
    for date_folder in os.listdir(CACHE_DIR):
        date_path = os.path.join(CACHE_DIR, date_folder)
        if not os.path.isdir(date_path):
            continue
        
        for filename in os.listdir(date_path):
            if not filename.endswith('.json'):
                continue
            
            # íŒŒì¼ëª…ì—ì„œ article_id ì¶”ì¶œ (ì˜ˆ: the_decoder_abc123.json â†’ abc123)
            file_id = filename.replace('.json', '').split('_')[-1]
            
            # ID ë§¤ì¹­ (6ìë¦¬ ë˜ëŠ” 12ìë¦¬)
            if file_id == article_id or article_id in filename:
                filepath = os.path.join(date_path, filename)
                try:
                    with open(filepath, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        # íŒŒì¼ ë‚´ë¶€ì˜ article_idë„ í™•ì¸
                        if data.get('article_id') == article_id:
                            return data
                except Exception:
                    pass
    
    return None


def build_enriched_article(article: dict, cache_data: dict) -> dict:
    """ìºì‹œ ë°ì´í„°ë¡œ articles ë°°ì—´ í•­ëª© ë³´ê°•"""
    return {
        'id': article.get('id', ''),
        'title': cache_data.get('title_ko') or cache_data.get('title') or article.get('title', ''),
        'title_ko': cache_data.get('title_ko', ''),
        'title_en': cache_data.get('title', ''),
        'summary': cache_data.get('summary', ''),
        'url': cache_data.get('url') or article.get('url', ''),
        'source_id': cache_data.get('source_id', ''),
        'zero_echo_score': cache_data.get('zero_echo_score'),
        'impact_score': cache_data.get('impact_score'),
        'layout_type': cache_data.get('layout_type', 'Standard'),
        'tags': cache_data.get('tags', []),
        'category': cache_data.get('category', 'ë¯¸ë¶„ë¥˜'),
        'filename': article.get('filename', ''),
        'date': article.get('date', ''),
        'published_at': cache_data.get('published_at', article.get('published_at', ''))
    }


def migrate_publications(dry_run: bool = True):
    """ë°œí–‰ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜"""
    print("=" * 60)
    print("ğŸ“¦ ë°œí–‰ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜")
    print(f"   ëª¨ë“œ: {'ì‹œë®¬ë ˆì´ì…˜ (Dry Run)' if dry_run else 'âš ï¸ ì‹¤ì œ ì‹¤í–‰'}")
    print("=" * 60)
    
    db = DBClient()
    
    # ëª¨ë“  íšŒì°¨ ì¡°íšŒ
    issues = db.get_issues_from_meta()
    print(f"\nğŸ“‹ ì´ {len(issues)}ê°œ íšŒì°¨ ë°œê²¬\n")
    
    total_updated = 0
    total_articles_enriched = 0
    
    for issue in issues:
        publish_id = issue.get('id') or issue.get('edition_code')
        edition_name = issue.get('edition_name', publish_id)
        
        print(f"â”€â”€â”€ {edition_name} ({publish_id}) â”€â”€â”€")
        
        # íšŒì°¨ ìƒì„¸ ì¡°íšŒ
        pub_data = db.get_publication(publish_id)
        if not pub_data:
            print(f"   âš ï¸ ë¬¸ì„œ ì—†ìŒ\n")
            continue
        
        articles = pub_data.get('articles', [])
        article_ids = pub_data.get('article_ids', [])
        
        # articles ë°°ì—´ì´ ì—†ê±°ë‚˜ ë¹„ì–´ìˆìœ¼ë©´ article_idsë¡œ êµ¬ì„±
        if not articles and article_ids:
            print(f"   ğŸ“ articles ë°°ì—´ ì—†ìŒ, article_idsì—ì„œ {len(article_ids)}ê°œ ë³µì› í•„ìš”")
            articles = [{'id': aid} for aid in article_ids]
        
        # ê° ê¸°ì‚¬ ë³´ê°•
        enriched_articles = []
        enriched_count = 0
        
        for article in articles:
            article_id = article.get('id', '')
            
            # ì´ë¯¸ summaryê°€ ìˆìœ¼ë©´ ë³´ê°•ë¨
            if article.get('summary'):
                enriched_articles.append(article)
                continue
            
            # ìºì‹œì—ì„œ ì°¾ê¸°
            cache_data = find_article_in_cache(article_id)
            
            if cache_data:
                enriched = build_enriched_article(article, cache_data)
                enriched_articles.append(enriched)
                enriched_count += 1
                print(f"   âœ… {article_id}: ë³´ê°•ë¨ (score: {cache_data.get('zero_echo_score', 'N/A')})")
            else:
                # ìºì‹œì— ì—†ìœ¼ë©´ ê¸°ì¡´ ë°ì´í„° ìœ ì§€
                enriched_articles.append(article)
                print(f"   âš ï¸ {article_id}: ìºì‹œì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŒ")
        
        # ì—…ë°ì´íŠ¸ í•„ìš” ì—¬ë¶€
        if enriched_count > 0:
            print(f"   â†’ {enriched_count}ê°œ ê¸°ì‚¬ ë³´ê°•")
            
            if not dry_run:
                # Firestore ì—…ë°ì´íŠ¸
                db.update_publication_record(publish_id, {
                    'articles': enriched_articles,
                    'updated_at': datetime.now(timezone.utc).isoformat()
                })
                print(f"   ğŸ’¾ Firestore ì—…ë°ì´íŠ¸ ì™„ë£Œ")
            
            total_updated += 1
            total_articles_enriched += enriched_count
        else:
            print(f"   âœ¨ ì´ë¯¸ ìµœì‹  í¬ë§·")
        
        print()
    
    # ìš”ì•½
    print("=" * 60)
    print(f"ğŸ“Š ë§ˆì´ê·¸ë ˆì´ì…˜ ìš”ì•½")
    print(f"   - ì—…ë°ì´íŠ¸ëœ íšŒì°¨: {total_updated}ê°œ")
    print(f"   - ë³´ê°•ëœ ê¸°ì‚¬: {total_articles_enriched}ê°œ")
    
    if dry_run:
        print("\nâš ï¸ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œì…ë‹ˆë‹¤. ì‹¤ì œ ì ìš©í•˜ë ¤ë©´:")
        print("   python migrate_publications.py --execute")
    else:
        print("\nâœ… ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!")
    
    print("=" * 60)


if __name__ == "__main__":
    dry_run = '--execute' not in sys.argv
    migrate_publications(dry_run)
