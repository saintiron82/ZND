# -*- coding: utf-8 -*-
"""
Scheduler Pipeline - í†µí•© ìë™í™” íŒŒì´í”„ë¼ì¸

í•µì‹¬ ì›ì¹™: ì½”ë“œ ë³µì‚¬ ê¸ˆì§€!
ëª¨ë“  ì €ì¥/ë°œí–‰ ëª¨ë“ˆì€ desk ì½”ì–´ë¥¼ ì§ì ‘ importí•˜ì—¬ í˜¸ì¶œ

íŒŒì´í”„ë¼ì¸ ë‹¨ê³„:
    COLLECT â†’ EXTRACT â†’ ANALYZE â†’ SCORE â†’ CLASSIFY â†’ REJECT â†’ PUBLISH â†’ RELEASE
"""
import os
import sys
from enum import Enum
from datetime import datetime
from typing import Optional, Callable, Dict, Any, List
from dataclasses import dataclass, field

# Path setup for desk core imports
DESK_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if DESK_DIR not in sys.path:
    sys.path.insert(0, DESK_DIR)

# ============================================================================
# Desk Core Imports (ì§ì ‘ í˜¸ì¶œ, ë³µì‚¬ ê¸ˆì§€!)
# ============================================================================
from src.core.article_manager import ArticleManager
from src.core.article_state import ArticleState
from src.core.firestore_client import FirestoreClient
from src.core_logic import (
    save_to_cache,
    load_from_cache,
    get_article_id,
    get_kst_now,
)
from src.pipeline import extract_article


# ============================================================================
# Pipeline Definitions
# ============================================================================

class PipelinePhase(Enum):
    """íŒŒì´í”„ë¼ì¸ ë‹¨ê³„ ì •ì˜"""
    COLLECT = "collect"      # ë§í¬ ìˆ˜ì§‘
    EXTRACT = "extract"      # ë³¸ë¬¸ ì¶”ì¶œ  
    ANALYZE = "analyze"      # AI ë¶„ì„ (êµ¬í˜„ ì˜ˆì •)
    SCORE = "score"          # ì ìˆ˜ ì¬ê³„ì‚° (êµ¬í˜„ ì˜ˆì •)
    CLASSIFY = "classify"    # ìë™ ë¶„ë¥˜
    REJECT = "reject"        # ë°°ì œ ì²˜ë¦¬
    PUBLISH = "publish"      # ë°œí–‰
    RELEASE = "release"      # ë¦´ë¦¬ì¦ˆ


@dataclass
class PipelineResult:
    """íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê²°ê³¼"""
    success: bool = True
    phase: PipelinePhase = None
    collected: int = 0
    extracted: int = 0
    analyzed: int = 0
    classified: int = 0
    rejected: int = 0
    published: int = 0
    released: bool = False
    errors: List[str] = field(default_factory=list)
    message: str = ""
    
    def to_dict(self) -> dict:
        return {
            'success': self.success,
            'phase': self.phase.value if self.phase else None,
            'collected': self.collected,
            'extracted': self.extracted,
            'analyzed': self.analyzed,
            'classified': self.classified,
            'rejected': self.rejected,
            'published': self.published,
            'released': self.released,
            'errors': self.errors,
            'message': self.message
        }


# ============================================================================
# Pipeline Executor
# ============================================================================

class SchedulerPipeline:
    """
    í†µí•© ìŠ¤ì¼€ì¤„ëŸ¬ íŒŒì´í”„ë¼ì¸
    
    desk ì½”ì–´ë¥¼ ì§ì ‘ í˜¸ì¶œí•˜ì—¬ ìˆ˜ì§‘â†’ë°œí–‰ê¹Œì§€ ìë™í™”
    """
    
    def __init__(self):
        self.manager = ArticleManager()
        self.db = FirestoreClient()
        self.result = PipelineResult()
        
    def run(
        self,
        phases: List[PipelinePhase] = None,
        schedule_name: str = "Scheduled",
        progress_callback: Callable[[Dict], None] = None,
        dry_run: bool = False
    ) -> PipelineResult:
        """
        íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        
        Args:
            phases: ì‹¤í–‰í•  ë‹¨ê³„ë“¤ (None = ì „ì²´ ì‹¤í–‰)
            schedule_name: ìŠ¤ì¼€ì¤„ ì´ë¦„ (ë¡œê¹…/ì•Œë¦¼ìš©)
            progress_callback: ì§„í–‰ ìƒí™© ì½œë°±
            dry_run: Trueë©´ ì‹¤ì œ ì €ì¥ ì—†ì´ ì‹œë®¬ë ˆì´ì…˜
            
        Returns:
            PipelineResult
        """
        if phases is None:
            phases = list(PipelinePhase)
        
        self.result = PipelineResult()
        self._log(f"ğŸš€ Pipeline starting: {schedule_name}")
        self._log(f"   Phases: {[p.value for p in phases]}")
        
        try:
            for phase in phases:
                self.result.phase = phase
                
                if progress_callback:
                    progress_callback({
                        'status': 'running',
                        'phase': phase.value,
                        'message': f'Processing {phase.value}...'
                    })
                
                # ë‹¨ê³„ë³„ ì‹¤í–‰
                if phase == PipelinePhase.COLLECT:
                    self._phase_collect()
                elif phase == PipelinePhase.EXTRACT:
                    self._phase_extract()
                elif phase == PipelinePhase.ANALYZE:
                    self._phase_analyze()
                elif phase == PipelinePhase.SCORE:
                    self._phase_score()
                elif phase == PipelinePhase.CLASSIFY:
                    self._phase_classify()
                elif phase == PipelinePhase.REJECT:
                    self._phase_reject()
                elif phase == PipelinePhase.PUBLISH:
                    self._phase_publish(dry_run)
                elif phase == PipelinePhase.RELEASE:
                    self._phase_release(dry_run)
                    
        except Exception as e:
            self.result.success = False
            self.result.errors.append(str(e))
            self._log(f"âŒ Pipeline error: {e}")
            import traceback
            traceback.print_exc()
            
        # ìµœì¢… ë©”ì‹œì§€ ìƒì„±
        self.result.message = self._generate_summary()
        self._log(f"âœ… Pipeline completed: {self.result.message}")
        
        return self.result
    
    # ========================================================================
    # Phase Implementations
    # ========================================================================
    
    def _phase_collect(self):
        """Phase 1: ë§í¬ ìˆ˜ì§‘"""
        self._log("ğŸ“¡ [COLLECT] Starting link collection...")
        
        # crawler/core/collector.py í˜¸ì¶œ
        try:
            # TODO: crawler ëª¨ë“ˆì—ì„œ collect_links ê°€ì ¸ì˜¤ê¸°
            # í˜„ì¬ëŠ” placeholder
            ZND_ROOT = os.path.dirname(DESK_DIR)
            sys.path.insert(0, os.path.join(ZND_ROOT, 'crawler'))
            from core.collector import collect_links
            
            result = collect_links()
            if result.get('success'):
                self._collected_links = result.get('links', [])
                self.result.collected = len(self._collected_links)
                self._log(f"   Collected {self.result.collected} links")
            else:
                self._collected_links = []
                self._log(f"   No links collected")
        except Exception as e:
            self._log(f"âš ï¸ [COLLECT] Error: {e}")
            self._collected_links = []
    
    def _phase_extract(self):
        """Phase 2: ë³¸ë¬¸ ì¶”ì¶œ"""
        self._log("ğŸ“„ [EXTRACT] Starting content extraction...")
        
        import asyncio
        
        links = getattr(self, '_collected_links', [])
        if not links:
            self._log("   No links to extract")
            return
        
        extracted_articles = []
        
        async def extract_all():
            nonlocal extracted_articles
            for item in links:
                url = item['url'] if isinstance(item, dict) else item
                source_id = item.get('source_id', 'unknown') if isinstance(item, dict) else 'unknown'
                
                # desk ì½”ì–´ì˜ extract_article ì§ì ‘ í˜¸ì¶œ!
                try:
                    content = await extract_article(url)
                    if content and len(content.get('text', '')) >= 200:
                        content['source_id'] = source_id
                        content['url'] = url
                        
                        # desk ì½”ì–´ì˜ save_to_cache ì§ì ‘ í˜¸ì¶œ!
                        save_to_cache(url, content)
                        
                        # ArticleManager.create í˜¸ì¶œí•˜ì—¬ Firestore ì €ì¥
                        article = self.manager.create(url, content)
                        if article:
                            extracted_articles.append(article)
                            
                except Exception as e:
                    self._log(f"âš ï¸ Extract failed: {url[:50]}... - {e}")
        
        asyncio.run(extract_all())
        self._extracted_articles = extracted_articles
        self.result.extracted = len(extracted_articles)
        self._log(f"   Extracted {self.result.extracted} articles")
    
    def _phase_analyze(self):
        """Phase 3: AI ë¶„ì„ (êµ¬í˜„ ì˜ˆì •)"""
        self._log("ğŸ¤– [ANALYZE] AI analysis...")
        
        # TODO: ìƒˆë¡œìš´ ë¶„ì„ ì—”ì§„ ì—°ë™ ì˜ˆì •
        # í˜„ì¬ëŠ” COLLECTED ìƒíƒœì˜ ê¸°ì‚¬ë¥¼ ê°€ì ¸ì™€ì„œ ë¶„ì„ ëŒ€ê¸°
        articles = getattr(self, '_extracted_articles', [])
        if not articles:
            # Firestoreì—ì„œ COLLECTED ìƒíƒœ ê¸°ì‚¬ ì¡°íšŒ
            articles = self.manager.find_collected(limit=50)
        
        self._log(f"   {len(articles)} articles pending analysis")
        self._articles_to_analyze = articles
        # ë¶„ì„ì€ ì¶”í›„ êµ¬í˜„
        self.result.analyzed = 0
    
    def _phase_score(self):
        """Phase 4: ì ìˆ˜ ì¬ê³„ì‚° (êµ¬í˜„ ì˜ˆì •)"""
        self._log("ğŸ“Š [SCORE] Score recalculation...")
        # TODO: ì ìˆ˜ ì¬ê³„ì‚° ë¡œì§
        pass
    
    def _phase_classify(self):
        """Phase 5: ìë™ ë¶„ë¥˜"""
        self._log("ğŸ·ï¸ [CLASSIFY] Auto classification...")
        
        # ANALYZED ìƒíƒœ ê¸°ì‚¬ ê°€ì ¸ì˜¤ê¸°
        articles = self.manager.find_analyzed(limit=100)
        
        classified_count = 0
        for article in articles:
            article_id = article.get('_header', {}).get('article_id') or article.get('article_id')
            if not article_id:
                continue
            
            # ê¸°ë³¸ ì¹´í…Œê³ ë¦¬ ìë™ ë¶„ë¥˜ (íƒœê·¸ ê¸°ë°˜)
            tags = article.get('_analysis', {}).get('tags', [])
            if not tags:
                tags = article.get('tags', [])
            
            category = self._determine_category(tags)
            
            # desk ì½”ì–´ì˜ update_classification ì§ì ‘ í˜¸ì¶œ!
            if self.manager.update_classification(article_id, category):
                classified_count += 1
        
        self.result.classified = classified_count
        self._log(f"   Classified {classified_count} articles")
    
    def _phase_reject(self):
        """Phase 6: ë°°ì œ ì²˜ë¦¬ (ì»¤íŠ¸ë¼ì¸ ë¯¸ë‹¬)"""
        self._log("ğŸ—‘ï¸ [REJECT] Rejecting high-noise articles...")
        
        # ANALYZED ìƒíƒœì—ì„œ ì ìˆ˜ ë¯¸ë‹¬ ê¸°ì‚¬ ë°°ì œ
        articles = self.manager.find_analyzed(limit=100)
        
        rejected_count = 0
        # [v1.2.0] ZES ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ! 6.0 ì´ˆê³¼ë©´ ë…¸ì´ì¦ˆ ê³¼ë‹¤
        max_acceptable_zes = 6.0
        
        for article in articles:
            article_id = article.get('_header', {}).get('article_id') or article.get('article_id')
            if not article_id:
                continue
            
            # ì ìˆ˜ í™•ì¸
            analysis = article.get('_analysis', {})
            score = analysis.get('zero_echo_score', 10)  # Default to worst
            if not score:
                score = article.get('zero_echo_score', 10)
            
            if float(score) > max_acceptable_zes:
                # desk ì½”ì–´ì˜ reject ì§ì ‘ í˜¸ì¶œ!
                if self.manager.reject(article_id, reason='cutline'):
                    rejected_count += 1
        
        self.result.rejected = rejected_count
        self._log(f"   Rejected {rejected_count} articles")
    
    def _phase_publish(self, dry_run: bool = False):
        """Phase 7: ë°œí–‰"""
        self._log("ğŸ“¤ [PUBLISH] Publishing articles...")
        
        if dry_run:
            self._log("   (Dry run - skipping actual publish)")
            return
        
        # CLASSIFIED ìƒíƒœ ê¸°ì‚¬ ê°€ì ¸ì˜¤ê¸°
        articles = self.manager.find_classified(limit=20)
        
        if not articles:
            self._log("   No articles to publish")
            return
        
        # ë°œí–‰ íšŒì°¨ ìƒì„±
        now = get_kst_now()
        date_str = now.strftime('%y%m%d')
        
        # ê¸°ì¡´ íšŒì°¨ í™•ì¸í•˜ì—¬ ë‹¤ìŒ ë²ˆí˜¸ ê²°ì •
        meta = self.db.get_publications_meta() or {'issues': []}
        today_issues = [i for i in meta.get('issues', []) if i.get('edition_code', '').startswith(date_str)]
        next_index = len(today_issues) + 1
        
        edition_code = f"{date_str}_{next_index}"
        edition_name = f"{next_index}í˜¸"
        
        published_count = 0
        for article in articles:
            article_id = article.get('_header', {}).get('article_id') or article.get('article_id')
            if not article_id:
                continue
            
            # desk ì½”ì–´ì˜ publish ì§ì ‘ í˜¸ì¶œ!
            if self.manager.publish(article_id, edition_code, edition_name):
                published_count += 1
        
        self.result.published = published_count
        self._log(f"   Published {published_count} articles to {edition_code}")
    
    def _phase_release(self, dry_run: bool = False):
        """Phase 8: ë¦´ë¦¬ì¦ˆ (Git push)"""
        self._log("ğŸš€ [RELEASE] Releasing to production...")
        
        if dry_run:
            self._log("   (Dry run - skipping actual release)")
            return
        
        # TODO: Git ë¦´ë¦¬ì¦ˆ ë¸Œëœì¹˜ í‘¸ì‹œ
        # /release-branch ì›Œí¬í”Œë¡œìš° í˜¸ì¶œ ì˜ˆì •
        self.result.released = False
        self._log("   Release pending (manual trigger required)")
    
    # ========================================================================
    # Helper Methods
    # ========================================================================
    
    def _determine_category(self, tags: List[str]) -> str:
        """íƒœê·¸ ê¸°ë°˜ ì¹´í…Œê³ ë¦¬ ê²°ì •"""
        # ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ ë¶„ë¥˜
        tag_str = ' '.join(tags).lower()
        
        if any(k in tag_str for k in ['ai', 'machine learning', 'gpt', 'llm']):
            return 'ai'
        elif any(k in tag_str for k in ['crypto', 'bitcoin', 'blockchain']):
            return 'crypto'
        elif any(k in tag_str for k in ['startup', 'funding', 'vc']):
            return 'startup'
        else:
            return 'tech'
    
    def _generate_summary(self) -> str:
        """ì‹¤í–‰ ê²°ê³¼ ìš”ì•½ ìƒì„±"""
        parts = []
        if self.result.collected:
            parts.append(f"ìˆ˜ì§‘:{self.result.collected}")
        if self.result.extracted:
            parts.append(f"ì¶”ì¶œ:{self.result.extracted}")
        if self.result.analyzed:
            parts.append(f"ë¶„ì„:{self.result.analyzed}")
        if self.result.classified:
            parts.append(f"ë¶„ë¥˜:{self.result.classified}")
        if self.result.rejected:
            parts.append(f"ë°°ì œ:{self.result.rejected}")
        if self.result.published:
            parts.append(f"ë°œí–‰:{self.result.published}")
        
        return ', '.join(parts) if parts else 'No actions taken'
    
    def _log(self, message: str):
        """ë¡œê·¸ ì¶œë ¥"""
        timestamp = datetime.now().strftime('%H:%M:%S')
        print(f"[{timestamp}] {message}")


# ============================================================================
# Convenience Functions
# ============================================================================

def run_pipeline(
    phases: List[PipelinePhase] = None,
    schedule_name: str = "Scheduled",
    progress_callback: Callable[[Dict], None] = None,
    dry_run: bool = False
) -> PipelineResult:
    """
    íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (í¸ì˜ í•¨ìˆ˜)
    
    Examples:
        # ìˆ˜ì§‘ë§Œ
        run_pipeline([PipelinePhase.COLLECT, PipelinePhase.EXTRACT])
        
        # ë¶„ì„ê¹Œì§€
        run_pipeline([
            PipelinePhase.COLLECT, 
            PipelinePhase.EXTRACT, 
            PipelinePhase.ANALYZE
        ])
        
        # ì „ì²´ ìë™í™”
        run_pipeline()
    """
    pipeline = SchedulerPipeline()
    return pipeline.run(phases, schedule_name, progress_callback, dry_run)


# í¸ì˜ ìƒìˆ˜
PHASES_COLLECT_ONLY = [PipelinePhase.COLLECT, PipelinePhase.EXTRACT]
PHASES_UNTIL_ANALYZE = [
    PipelinePhase.COLLECT, 
    PipelinePhase.EXTRACT, 
    PipelinePhase.ANALYZE,
    PipelinePhase.SCORE
]
PHASES_UNTIL_PUBLISH = [
    PipelinePhase.COLLECT,
    PipelinePhase.EXTRACT,
    PipelinePhase.ANALYZE,
    PipelinePhase.SCORE,
    PipelinePhase.CLASSIFY,
    PipelinePhase.REJECT,
    PipelinePhase.PUBLISH
]
PHASES_FULL = list(PipelinePhase)


if __name__ == '__main__':
    import argparse
    
    parser = argparse.ArgumentParser(description='ZND ìŠ¤ì¼€ì¤„ëŸ¬ íŒŒì´í”„ë¼ì¸ ì¦‰ì‹œ ì‹¤í–‰')
    parser.add_argument(
        '--phases', '-p',
        nargs='+',
        choices=['collect', 'extract', 'analyze', 'score', 'classify', 'reject', 'publish', 'release'],
        default=['collect', 'extract'],
        help='ì‹¤í–‰í•  ë‹¨ê³„ë“¤ (ê¸°ë³¸: collect extract)'
    )
    parser.add_argument(
        '--dry-run', '-d',
        action='store_true',
        help='ì‹¤ì œ ì €ì¥ ì—†ì´ ì‹œë®¬ë ˆì´ì…˜'
    )
    parser.add_argument(
        '--name', '-n',
        default='Manual Run',
        help='ì‹¤í–‰ ì´ë¦„ (ë¡œê¹…ìš©)'
    )
    
    args = parser.parse_args()
    
    # phases ë¬¸ìì—´ì„ Enumìœ¼ë¡œ ë³€í™˜
    phases = [PipelinePhase(p) for p in args.phases]
    
    print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘       ğŸš€ ZND Pipeline - ì¦‰ì‹œ ì‹¤í–‰                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ì‹¤í–‰ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
ì‹¤í–‰ ì´ë¦„: {args.name}
ì‹¤í–‰ ë‹¨ê³„: {args.phases}
Dry Run: {args.dry_run}
""")
    
    result = run_pipeline(
        phases=phases,
        schedule_name=args.name,
        dry_run=args.dry_run
    )
    
    print(f"\n{'='*50}")
    print(f"ì‹¤í–‰ ê²°ê³¼: {result.to_dict()}")
    print(f"{'='*50}")

