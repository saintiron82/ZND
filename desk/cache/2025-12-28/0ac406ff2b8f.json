{
  "_header": {
    "version": "2.0",
    "article_id": "0ac406ff2b8f",
    "state": "PUBLISHED",
    "state_history": [
      {
        "state": "COLLECTED",
        "at": "2025-12-28T06:51:33.506576+00:00",
        "by": "crawler"
      },
      {
        "state": "PUBLISHED",
        "at": "2025-12-28T17:10:46.117731+00:00",
        "by": "publisher"
      }
    ],
    "updated_at": "2025-12-28T17:10:46.117731+00:00"
  },
  "_original": {
    "title": "China proposes rules to combat AI companion addiction",
    "description": "China wants to crack down on emotionally manipulative AI chatbots. Under proposed rules, providers would have to detect addictive behavior and step in when users show psychological warning signs. California is taking similar steps after tragic stories linked to AI companions.",
    "image": "https://the-decoder.com/wp-content/uploads/2025/12/china_neural_network.jpeg",
    "text": "Ask about this article… Search China's cyber authority released draft regulations on Saturday that would tighten oversight of AI services designed to mimic human interaction. The proposed rules take aim at AI products that mimic human personalities, thought patterns, and communication styles; systems designed to form emotional connections with users through text, images, audio, or video. Under the draft, providers would need to warn users against excessive use and step in when signs of addictive behavior appear. They'd also have to monitor users' emotional states and addiction levels, taking action when things get extreme. Providers would be responsible for safety throughout their products' entire lifecycle, with requirements for algorithm review, data security, and \"personal information protection.\" Content that \"endangers national security, spreads rumours or promotes violence or obscenity\" would be banned, according to Reuters. Ad California takes similar steps to protect users California's bill SB 243 marks the first state-level regulation targeting AI companion chatbots. Starting January 1, 2026, providers must ensure their chatbots don't engage in conversations about suicide, self-harm, or sexually explicit content. Beginning July 2027, companies will also face annual transparency and reporting requirements designed to help regulators understand the psychological risks these systems create. New York is working on similar legislation. Ad DEC_D_Incontent-1 This puts companies like OpenAI in a tough spot. Emotional, human-like interactions drive strong user engagement and commercial success. But regulatory and social pressure to make these systems safer—especially for vulnerable groups like minors—keeps growing. The regulations come after several high-profile incidents highlighted the dangers. Adam Raine committed suicide after prolonged conversations with OpenAI's ChatGPT, though the exact role the chatbot played in his death remains a matter of debate. Similar cases have sparked multiple lawsuits against Character AI. Internal leaks at Meta made things worse - documents showed their chatbots could have romantic or sexual conversations with minors. Ad Danish psychiatrist Soren Dinesen Ostergaard, writing in Acta Psychiatrica Scandinavica, warns of a sharp rise in cases where AI chatbots intensify delusions or create emotional dependency in mentally unstable users.",
    "published_at": "2025-12-27T10:39:36+00:00",
    "url": "https://the-decoder.com/china-proposes-rules-to-combat-ai-companion-addiction/",
    "source_id": "the_decoder",
    "crawled_at": "2025-12-28T06:51:33.506576+00:00"
  },
  "_analysis": {
    "title_ko": "중국, AI 컴패니언 '중독 방지' 규제 초안 발표",
    "summary": "중국 당국이 인간을 모방하는 AI 서비스에 대한 규제 초안을 발표했다. 공급자는 사용자의 중독 행동을 감지하고 개입해야 하며, 알고리즘 검토 및 데이터 보안 의무를 진다. 캘리포니아 등 미국 주 정부들도 유사한 입법을 추진 중이다.",
    "tags": [
      "Regulation",
      "Safety",
      "Ethics"
    ],
    "impact_score": 5.5,
    "zero_echo_score": 4.3,
    "analyzed_at": "2025-12-28T07:01:27.263623+00:00",
    "mll_raw": {
      "Article_ID": "0ac406ff2b8f",
      "Meta": {
        "Specification_Version": "v 1.0.0",
        "Headline": "중국, AI 컴패니언 '중독 방지' 규제 초안 발표",
        "Summary": "중국 당국이 인간을 모방하는 AI 서비스에 대한 규제 초안을 발표했다. 공급자는 사용자의 중독 행동을 감지하고 개입해야 하며, 알고리즘 검토 및 데이터 보안 의무를 진다. 캘리포니아 등 미국 주 정부들도 유사한 입법을 추진 중이다.",
        "Tags": [
          "Regulation",
          "Safety",
          "Ethics"
        ]
      },
      "IS_Analysis": {
        "Score_Commentary": "중국(Tier 2)의 규제 초안(Y3) 발표는 국가 내 주요 법규 변화(X2)에 해당함. AI 중독과 정신 건강이라는 사회적 안전(C2) 문제를 직접적으로 다루고 있어 영향도가 높음.",
        "Calculations": {
          "IW_Analysis": {
            "Inputs": {
              "Pe_Selection_Rule": "P5",
              "Pe_Entity_Name": "China (Cyber Authority)",
              "Pe_Tier": 2,
              "Se_Entity_Name": "None",
              "Se_Tier": 0,
              "PE/SE 선정이유": "규제를 공식 발표하고 통제하는 주체(P5)인 중국 정부를 PE로 선정. 대상이 불특정 다수 AI 기업이므로 SE는 None."
            },
            "Tier_Score": 2,
            "Gap_Score": 0,
            "IW_Score": 2
          },
          "IE_Analysis": {
            "Inputs": {
              "X_Magnitude_Code": 2,
              "Y_Evidence_Code": 3,
              "Scope_Matrix_Score": 1.5,
              "Criticality_C1_Provenness": 1,
              "Criticality_C2_Societal_Weight": 1,
              "Criticality_Total": 2,
              "SOTA_Check_Result": "False"
            },
            "IE_Score": 3.5
          }
        }
      },
      "ZES_Raw_Metrics": {
        "Signal": {
          "T1": 7,
          "T2": 6,
          "T3": 8,
          "Rationale": "규제의 구체적인 요구사항(경고, 모니터링)이 명시됨."
        },
        "Noise": {
          "P1": 1,
          "P2": 1,
          "P3": 0,
          "Rationale": "사실 전달 위주의 드라이한 톤 유지."
        },
        "Utility": {
          "V1": 8,
          "V2": 7,
          "V3": 6,
          "Rationale": "중국 시장 진출 AI 기업들에게 필수적인 규제 정보."
        },
        "Fine_Adjustment": {
          "Score": 0,
          "Reason": "보정 없음."
        }
      }
    }
  },
  "_classification": {
    "category": "Community",
    "is_selected": true,
    "classified_at": "2025-12-28T07:59:57.822795+00:00",
    "classified_by": "desk_user",
    "edition_code": null,
    "edition_name": null,
    "published_at": null,
    "released_at": null
  },
  "_publication": {
    "edition_code": "251228_6",
    "edition_name": "제6호",
    "published_at": "2025-12-28T12:06:38.607675+00:00",
    "released_at": null,
    "firestore_synced": true
  }
}