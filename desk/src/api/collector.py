# -*- coding: utf-8 -*-
"""
Collector API - ìˆ˜ì§‘ ê´€ë ¨ API
"""
import os
import sys
from flask import Blueprint, jsonify

collector_bp = Blueprint('collector', __name__)


def _setup_paths():
    """í¬ë¡¤ëŸ¬ ëª¨ë“ˆ ê²½ë¡œ ì„¤ì • - ìƒˆ desk í´ë” ê¸°ë°˜"""
    # í˜„ì¬ íŒŒì¼: desk/src/api/collector.py
    # desk í´ë”: 3ë‹¨ê³„ ìœ„
    desk_dir = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
    project_root = os.path.dirname(desk_dir)
    crawler_path = os.path.join(project_root, 'crawler')
    src_path = os.path.join(desk_dir, 'src')  # src í´ë”ë„ ì¶”ê°€
    
    print(f"ğŸ”§ [Collector] desk_dir: {desk_dir}")
    print(f"ğŸ”§ [Collector] crawler_path: {crawler_path}")
    print(f"ğŸ”§ [Collector] src_path: {src_path}")
    
    # ê²½ë¡œ ì¶”ê°€ (desk ë¨¼ì €, ê·¸ ë‹¤ìŒ src, ê·¸ ë‹¤ìŒ crawler)
    paths_to_add = [desk_dir, src_path, crawler_path]
    for path in paths_to_add:
        if path not in sys.path and os.path.exists(path):
            sys.path.insert(0, path)
            print(f"ğŸ”§ [Collector] Added to sys.path: {path}")
    
    return desk_dir, crawler_path


@collector_bp.route('/api/collector/run', methods=['POST'])
def run_collector():
    """
    ì¦‰ì‹œ ìˆ˜ì§‘ ì‹¤í–‰
    """
    print("ğŸš€ [Collector] API called - starting collection...")
    
    try:
        desk_dir, crawler_path = _setup_paths()
        
        # .env ë¡œë“œ (ìƒˆ desk í´ë”ì—ì„œ)
        env_file = os.path.join(desk_dir, '.env')
        print(f"ğŸ”§ [Collector] Loading .env from: {env_file}")
        if os.path.exists(env_file):
            from dotenv import load_dotenv
            load_dotenv(env_file)
            print("âœ… [Collector] .env loaded")
        else:
            print("âš ï¸ [Collector] .env not found")
        
        # í¬ë¡¤ëŸ¬ ì‹¤í–‰
        print("ğŸ”§ [Collector] Importing run_full_pipeline...")
        from core.extractor import run_full_pipeline
        
        print("ğŸ”§ [Collector] Calling run_full_pipeline...")
        result = run_full_pipeline(schedule_name="ì¦‰ì‹œ ìˆ˜ì§‘")
        print(f"âœ… [Collector] Pipeline result: {result}")
        
        # ê²°ê³¼ ì¶”ì¶œ
        collected = result.get('collected', 0) or result.get('total', 0)
        extracted = result.get('extracted', 0)
        
        return jsonify({
            'success': True,
            'collected': collected,
            'extracted': extracted,
            'message': f'ìˆ˜ì§‘ {collected}ê°œ, ì¶”ì¶œ {extracted}ê°œ ì™„ë£Œ'
        })
            
    except ImportError as e:
        print(f"âŒ [Collector] Import error: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'success': False,
            'error': f'Crawler module import failed: {e}'
        }), 500
    except Exception as e:
        print(f"âŒ [Collector] Error: {e}")
        import traceback
        with open('debug_collector.log', 'a', encoding='utf-8') as f:
            f.write(f"\n[{datetime.now()}] Error:\n")
            traceback.print_exc(file=f)
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500


@collector_bp.route('/api/collector/status', methods=['GET'])
def get_status():
    """ìˆ˜ì§‘ ìƒíƒœ ì¡°íšŒ"""
    return jsonify({
        'success': True,
        'status': 'idle',
        'message': 'No collection running'
    })
