# src/crawler_state.py
# í¬ë¡¤ë§ ìƒíƒœ ê´€ë¦¬ - ë…ë¦½ í¬ë¡¤ëŸ¬ ëª¨ë“ˆê³¼ í†µí•©
import sys
import os

# Add crawler module to path
CRAWLER_DIR = os.path.join(os.path.dirname(os.path.dirname(os.path.dirname(__file__))), 'crawler')
if CRAWLER_DIR not in sys.path:
    sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(__file__))))

# ìƒíƒœ ë³€ìˆ˜ (ë©”ëª¨ë¦¬ ë‚´)
_is_crawling = False
_current_task = ""


def set_crawling(status: bool, task: str = ""):
    """í¬ë¡¤ë§ ìƒíƒœ ì„¤ì •"""
    global _is_crawling, _current_task
    _is_crawling = status
    _current_task = task if status else ""


def get_crawling_status():
    """í¬ë¡¤ë§ ìƒíƒœ ì¡°íšŒ"""
    global _is_crawling, _current_task
    return {
        "is_crawling": _is_crawling,
        "current_task": _current_task
    }


# ë¡œê¹… í•¨ìˆ˜ - crawler/logs/crawler_history.jsonlì— ê¸°ë¡
def log_crawl_event(action: str, result: str, duration: float, success: bool = True):
    """ì‹¤í–‰ ì´ë ¥ ê¸°ë¡ (crawler/logs/crawler_history.jsonl)"""
    import json
    from datetime import datetime
    
    # ë…ë¦½ ìŠ¤ì¼€ì¤„ëŸ¬ì˜ ë¡œê·¸ íŒŒì¼ ê²½ë¡œ
    ZND_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
    LOG_FILE = os.path.join(ZND_ROOT, 'crawler', 'logs', 'crawler_history.jsonl')
    
    try:
        os.makedirs(os.path.dirname(LOG_FILE), exist_ok=True)
        entry = {
            "timestamp": datetime.now().isoformat(),
            "action": action, 
            "result": result,
            "duration": round(duration, 2),
            "success": success
        }
        with open(LOG_FILE, 'a', encoding='utf-8') as f:
            f.write(json.dumps(entry, ensure_ascii=False) + '\n')
        print(f"ğŸ“ [Log] {action}: {result} ({duration:.2f}s)")
    except Exception as e:
        print(f"âŒ Log save failed: {e}")


def get_crawl_logs(limit: int = 10):
    """ìµœê·¼ ë¡œê·¸ ì¡°íšŒ (crawler/logs/crawler_history.jsonl)"""
    import json
    
    # ë…ë¦½ ìŠ¤ì¼€ì¤„ëŸ¬ì˜ ë¡œê·¸ íŒŒì¼ ê²½ë¡œ
    ZND_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
    LOG_FILE = os.path.join(ZND_ROOT, 'crawler', 'logs', 'crawler_history.jsonl')
    
    if not os.path.exists(LOG_FILE):
        return []
    
    logs = []
    try:
        with open(LOG_FILE, 'r', encoding='utf-8') as f:
            for line in f:
                if line.strip():
                    logs.append(json.loads(line))
    except:
        return []
    
    return sorted(logs, key=lambda x: x.get('timestamp', ''), reverse=True)[:limit]


