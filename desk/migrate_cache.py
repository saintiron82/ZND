# -*- coding: utf-8 -*-
"""
ë¡œì»¬ ìºì‹œ ìƒíƒœ ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸
PUBLISHED ìƒíƒœ ê¸°ì‚¬ë“¤ì„ CLASSIFIEDë¡œ ë³€ê²½
"""
import os
import glob
import json
from datetime import datetime, timezone

CACHE_ROOT = r"c:\Users\saint\ZND\desk\cache"

def migrate_cache(dry_run=True):
    """ë¡œì»¬ ìºì‹œ íŒŒì¼ë“¤ì˜ ìƒíƒœë¥¼ PUBLISHED -> CLASSIFIEDë¡œ ë³€ê²½"""
    
    print("="*60)
    print("ë¡œì»¬ ìºì‹œ ìƒíƒœ ë§ˆì´ê·¸ë ˆì´ì…˜")
    print(f"Dry Run: {dry_run}")
    print("="*60)
    
    files = glob.glob(os.path.join(CACHE_ROOT, '*', '*.json'))
    
    migrated = 0
    skipped = 0
    errors = 0
    
    for fpath in files:
        try:
            with open(fpath, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # V2 Schema í™•ì¸
            if '_header' not in data:
                skipped += 1
                continue
            
            current_state = data['_header'].get('state')
            
            if current_state == 'PUBLISHED':
                print(f"ğŸ“ {os.path.basename(fpath)}: PUBLISHED -> CLASSIFIED")
                
                if not dry_run:
                    # ìƒíƒœ ë³€ê²½
                    data['_header']['state'] = 'CLASSIFIED'
                    data['_header']['updated_at'] = datetime.now(timezone.utc).isoformat()
                    
                    # state_history ì¶”ê°€
                    if 'state_history' not in data['_header']:
                        data['_header']['state_history'] = []
                    data['_header']['state_history'].append({
                        'state': 'CLASSIFIED',
                        'at': datetime.now(timezone.utc).isoformat(),
                        'by': 'migration_script',
                        'reason': 'unpublish_all'
                    })
                    
                    # _publication ì •ë³´ ì´ˆê¸°í™”
                    data['_publication'] = None
                    
                    # ì €ì¥
                    with open(fpath, 'w', encoding='utf-8') as f:
                        json.dump(data, f, ensure_ascii=False, indent=2)
                    
                migrated += 1
            else:
                skipped += 1
                
        except Exception as e:
            print(f"âŒ Error: {fpath}: {e}")
            errors += 1
    
    print("\n" + "="*60)
    print(f"ê²°ê³¼:")
    print(f"   ë³€ê²½ë¨: {migrated}")
    print(f"   ìŠ¤í‚µë¨: {skipped}")
    print(f"   ì—ëŸ¬: {errors}")
    print("="*60)
    
    if dry_run:
        print("\nâš ï¸  Dry Run ëª¨ë“œì…ë‹ˆë‹¤. ì‹¤ì œ ë³€ê²½í•˜ë ¤ë©´:")
        print("    python migrate_cache.py --apply")

if __name__ == '__main__':
    import sys
    
    dry_run = '--apply' not in sys.argv
    migrate_cache(dry_run=dry_run)
