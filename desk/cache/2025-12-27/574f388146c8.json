{
  "_header": {
    "version": "2.0",
    "article_id": "574f388146c8",
    "state": "RELEASED",
    "state_history": [
      {
        "state": "COLLECTED",
        "at": "2025-12-26T16:45:14.074806+00:00",
        "by": "crawler"
      },
      {
        "state": "PUBLISHED",
        "at": "2025-12-28T17:11:24.394672+00:00",
        "by": "publisher"
      },
      {
        "state": "RELEASED",
        "at": "2025-12-29T09:03:29.973520+00:00",
        "by": "publisher"
      }
    ],
    "updated_at": "2025-12-29T09:03:29.973520+00:00"
  },
  "_original": {
    "title": "스탠포드·하버드, 에이전트의 실제 환경 적응 돕는 프레임워크 소개 - AI타임스",
    "description": "대형언어모델(LLM) 기반 AI 에이전트가 실제 상황에서 제작 의도와 달리 제대로 작동하지 못하는 문제를 해결하기 위한 프레임워크가 등장했다. AI가 임무를 통해",
    "image": "https://cdn.aitimes.com/news/photo/202512/205106_206597_744.png",
    "text": "에이전트형 AI에서의 적응 개요. (사진=arXiv) 대형언어모델(LLM) 기반 AI 에이전트가 실제 상황에서 제작 의도와 달리 제대로 작동하지 못하는 문제를 해결하기 위한 프레임워크가 등장했다. AI가 임무를 통해 자신을 '적응(adaptation)'시킨다는 것이 핵심으로, 도구를 효과적으로 사용하는 것이 중요하다는 결론이다. 스탠포드대학교와 하버드대학교, UC버클리, 칼텍 연구진은 24일(현지시간) 논문 ‘ 에이전트형 AI의 적응(Adaptation of Agentic AI) ’를 통해 에이전트형 AI가 성능과 신뢰성, 범용성을 높이기 위해 어떤 방식으로 ‘적응’해야 하는지를 정의한 통합 프레임워크를 제시했다. 연구진은 에이전트를 크게 세가지 부분으로 나눠 설명했다. 먼저 '계획 모듈'은 “무엇을 해야 할까”라는 질문에 답하는 역할로, 주어진 목표를 여러 단계의 행동으로 분리한다. 다음으로 '도구 사용 모듈'은 웹 검색이나 API 호출, 코드 실행, 브라우저 자동화처럼 AI가 외부 세계와 실제로 상호작용하도록 돕는다. 마지막 '메모리 모듈'은 방금 나눈 대화 같은 단기 정보부터 오래 쌓아둔 지식까지 저장하고 필요할 때 다시 꺼내 쓰는 역할을 한다. 네가지 적응 패러다임(A1, A2, T1, T2) (사진=arXiv) 연구진이 말하는 ‘적응’이란 이 세가지 모듈이 더 잘 작동하도록 설정을 조정하는 과정이다. 질문을 던지는 방식(프롬프트)을 바꾸거나, 내부 가중치 같은 매개변수를 조금씩 수정한다. 이를 위해 정답을 알려주며 학습하는 지도 미세조정(SFT) 방식, 더 나은 답을 선호하도록 가르치는 방법(DPO), 보상을 통해 스스로 배우게 하는 강화 학습(RL), 그리고 적은 수정만으로 효율적으로 학습하는 로라(LoRA) 같은 기법들이 활용된다. 이런 과정을 통해 AI는 안정적인 에이전트로 진화한다. 연구진은 AI가 어떻게 적응해야 성능과 신뢰성, 범용성을 높일 수 있는지를 설명하기 위해 두가지 질문을 던진다. 바로 “무엇을 바꿀 것인가”와 “무엇을 기준으로 잘됐다고 판단할 것인가”다. 첫번째는 AI의 두뇌 역할을 하는 에이전트 자체를 개선할 것인지, 아니면 에이전트가 사용하는 검색·계산 같은 도구를 개선할 것인지에 대한 선택이다. 두번째는 학습의 기준이 도구를 실제로 써본 결과인지, 아니면 최종적으로 내놓은 답변의 품질인지에 관한 것이다. 이 두가지 기준을 조합하면 네가지 방식이 나온다. 2×2 적응 지형도. x축은 단일(모놀리식) 구조에서 모듈식 구조로의 진화를 나타내고, y축은 국소적 조율에서 시스템 전반의 조율로의 확장을 의미한다. A1과 A2는 에이전트 중심 영역에 위치하는 반면, T1과 T2는 모듈화와 시스템 수준의 유연성을 구현한다. (사진=arXiv) 먼저 'A1' 방식은 에이전트가 도구를 사용해 보고, 그 결과가 잘됐는지를 보고 자신 학습하는 방법이다. 검색 도구를 썼을 때 정말로 좋은 정보를 찾아왔는지, 코드 실행이 제대로 됐는지 같은 결과가 평가 기준이 된다. 툴포머(Toolformer)나 툴알파카(ToolAlpaca) 같은 기법은 실제 도구 사용이 성공한 사례만 골라 따라 하도록 학습한다. 딥리트리벌(DeepRetrieval)처럼 강화 학습을 쓸 때는 검색 정확도가 보상 기준이 된다. 'A2' 방식은 과정은 보지 않고 결과만 평가하는 접근이다. 에이전트가 어떤 도구를 썼는지는 따지지 않고, 최종 답변이 얼마나 정확한지만 보고 학습한다. 이렇게 하면 에이전트가 도구를 아예 쓰지 않고도 점수를 올릴 수 있기 때문에, 실제로는 도구 사용을 유도하는 보조 신호나 드문드문 주는 보상을 함께 쓰는 경우가 많다. 'T1' 방식은 에이전트는 그대로 둔 채, 도구 자체를 더 좋게 만드는 방법이다. 검색 도구의 정확도나 결과 정렬 품질을 높이는 데 집중하는 식이다. 이렇게 개선된 도구는 특정 AI에만 쓰이는 것이 아니라, 다른 에이전트 시스템에서도 그대로 재사용할 수 있다는 장점이 있다. 마지막으로 'T2' 방식은 이미 강력하지만 바꿀 수 없는 에이전트가 있을 때 주로 쓰인다. 에이전트는 고정해 두고, 그 에이전트가 내놓는 최종 답변의 품질이 좋아지도록 도구를 학습하는 방식이다. 내부 구조를 건드릴 수 없는 폐쇄형 대형 모델을 활용하는 현실 환경에 적합하다. 연구진은 \"이 네가지 방식이 복잡해 보이던 에이전트 AI 학습 방법을 한눈에 이해할 수 있게 해주며, 상황에 맞는 전략을 선택하는 데 도움을 준다\"라고 설명한다. 또, 장기 메모리를 T2 방식의 특별한 케이스로 봤다. 여기서 메모리는 AI 내부에 있는 것이 아니라, 바깥에 따로 마련된 저장소로 유지된다. AI 본체는 그대로 두고, 이 저장소에 정보를 어떻게 쓰고, 어떻게 읽어올지에 해당하는 부분만 학습하는 방식이다. 이는 답변을 만들어내는 핵심 모델은 고정한 채, 대신 검색기나 계획을 세우는 플래너를 학습해 전체 성능을 높이는 것이다. 즉, ‘뇌’는 그대로 두고 ‘기억을 찾고 활용하는 방법’만 개선해도 AI의 능력을 크게 끌어올릴 수 있다는 설명이다. 연구진은 \"강력한 기본 모델에 대한 A1, A2 업데이트는 드물게 적용하고, 검색 정책, 시뮬레이터, 메모리와 같은 모듈에 대한 T1, T2 적응을 자주 결합하는 것이 견고성(Robustness)과 확장성(Scalability)을 위한 실질적인 전략\"이라고 결론 내렸다. 즉, 에이전트 자체보다 도구와 모듈의 적응이 중요하다는 것을 강조한 것이다. 또 \"이번에 제시한 프레임워크는 에이전트를 설계할 때 선택할 방법들을 한눈에 정리해 주고, 상황에 맞춰 어떤 적응 전략을 쓰거나 다른 방식으로 바꿔야 할지 판단하는 데 실질적인 도움을 준다\"라고 설명했다. 박찬 기자 cpark@aitimes.com",
    "published_at": "2025-12-26T18:00:00+09:00",
    "url": "https://www.aitimes.com/news/articleView.html?idxno=205106",
    "source_id": "aitimes",
    "crawled_at": "2025-12-26T16:45:14.074806+00:00"
  },
  "_analysis": {
    "title_ko": "스탠포드·하버드 등, 에이전트 AI 적응 프레임워크 발표",
    "summary": "스탠포드, 하버드 등 주요 대학 연구진이 에이전트 AI의 성능 최적화를 위한 4가지 적응 패러다임(A1, A2, T1, T2)을 정의한 통합 프레임워크를 제시했다. 에이전트 자체보다 도구와 모듈의 개선이 효율적임을 강조했다.",
    "tags": [
      "Agent",
      "Framework",
      "Fine-tuning"
    ],
    "impact_score": 5.5,
    "zero_echo_score": 3.5,
    "analyzed_at": "2025-12-28T03:51:09.111931+00:00",
    "mll_raw": {
      "Article_ID": "574f388146c8",
      "Meta": {
        "Specification_Version": "v 1.0.0",
        "Headline": "스탠포드·하버드 등, 에이전트 AI 적응 프레임워크 발표",
        "Summary": "스탠포드, 하버드 등 주요 대학 연구진이 에이전트 AI의 성능 최적화를 위한 4가지 적응 패러다임(A1, A2, T1, T2)을 정의한 통합 프레임워크를 제시했다. 에이전트 자체보다 도구와 모듈의 개선이 효율적임을 강조했다.",
        "Tags": [
          "Agent",
          "Framework",
          "Fine-tuning"
        ]
      },
      "IS_Analysis": {
        "Score_Commentary": "Tier 2 학계(Academic Research)의 연구 성과로, 산업계 전반에 적용 가능한 프레임워크(X3)를 제시함. 아직 논문/개념 단계(Y2)이나 전략적 중요도가 높음.",
        "Calculations": {
          "IW_Analysis": {
            "Inputs": {
              "Pe_Selection_Rule": "P4",
              "Pe_Entity_Name": "Stanford/Harvard",
              "Pe_Tier": 2,
              "Se_Entity_Name": "None",
              "Se_Tier": 0,
              "PE/SE 선정이유": "연구 발표의 주체인 주요 대학(Academic T2)을 PE로 선정. 특정 대상과의 대립/협력보다는 일반적 프레임워크 제안이므로 SE는 None."
            },
            "Tier_Score": 2,
            "Gap_Score": 0,
            "IW_Score": 2
          },
          "IE_Analysis": {
            "Inputs": {
              "X_Magnitude_Code": 3,
              "Y_Evidence_Code": 2,
              "Scope_Matrix_Score": 2,
              "Criticality_C1_Provenness": 1,
              "Criticality_C2_Societal_Weight": 0.5,
              "Criticality_Total": 1.5,
              "SOTA_Check_Result": "True"
            },
            "IE_Score": 3.5
          }
        }
      },
      "ZES_Raw_Metrics": {
        "Signal": {
          "T1": 4,
          "T2": 9,
          "T3": 8,
          "Rationale": "프레임워크의 4가지 분류와 원리를 매우 상세하게 설명함."
        },
        "Noise": {
          "P1": 1,
          "P2": 1,
          "P3": 0,
          "Rationale": "학술적 내용 위주로 노이즈가 거의 없음."
        },
        "Utility": {
          "V1": 7,
          "V2": 6,
          "V3": 8,
          "Rationale": "에이전트 시스템 설계에 즉시 참고 가능한 고수준의 가이드라인."
        },
        "Fine_Adjustment": {
          "Score": 0.8,
          "Reason": "복잡한 에이전트 설계 개념을 체계화한 깊이 있는 정보(Deep Dive)에 가점."
        }
      }
    }
  },
  "_classification": {
    "category": "AI/ML",
    "is_selected": true,
    "classified_at": "2025-12-28T03:53:15.595499+00:00",
    "classified_by": "desk_user",
    "edition_code": null,
    "edition_name": null,
    "published_at": null,
    "released_at": null
  },
  "_publication": {
    "edition_code": "251228_6",
    "edition_name": "제6호",
    "published_at": "2025-12-28T12:07:16.801902+00:00",
    "released_at": null,
    "firestore_synced": true
  }
}