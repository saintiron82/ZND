{
  "article_id": "0cf64f",
  "cached_at": "2025-12-18T15:33:44.879108+00:00",
  "image": "https://the-decoder.com/wp-content/uploads/2025/12/google_gemini_logo_wall-1.jpg",
  "published_at": "Wed, 17 Dec 2025 19:15:35 GMT",
  "summary": "구글이 추론 능력을 유지하면서 속도와 비용 효율을 개선한 Gemini 3 Flash를 출시하고 구글 검색의 기본 모델로 적용했다. 시각적 추론 및 코드 실행 기능이 강화되었으며 개발자 접근성을 높였다.",
  "text": "Matthias is the co-founder and publisher of THE DECODER, exploring how AI is fundamentally changing the relationship between humans and computers. Content Summary Google's latest model focuses on price and speed. Gemini 3 Flash aims to deliver reasoning similar to more expensive models at a lower cost. The main question is whether this faster, cheaper model is good enough to replace mid-tier alternatives. Ad Google has released Gemini 3 Flash, the latest model in its Gemini series. According to Google, it’s designed to offer similar reasoning capabilities as the larger Gemini 3 Pro, but at a significantly lower price. The target audience is developers who previously had to pick between speed and advanced features. Model Input (per 1M tokens) Output (per 1M tokens) Gemini 3 Flash $0.50 $3.00 Gemini 3 Pro $2.00 $12.00 Claude Sonnet 4.5 $3.00 $15.00 GPT-5.2 Extra High (OpenAI) $1.75 $14.00 Developers can squeeze out more savings through context caching, which cuts costs by up to 90 percent when reusing tokens. The batch API takes another 50 percent off for async jobs. According to an analysis by Artificial Analysis, 3 Flash beats Gemini 2.5 Pro, runs three times faster, and costs way less. Google says even the model's lowest \"thinking level\" often outperforms older versions cranked up to their maximum settings. Ad Ad THE DECODER Newsletter The most important AI news straight to your inbox. ✓ Weekly ✓ Free ✓ Cancel at any time Please leave this field empty Share Recommend our article Share Google Search now runs on Gemini 3 Flash worldwide Google has made Gemini 3 Flash the standard model for AI Mode in Google Search, so it's now handling the bulk of daily search queries. According to Google, Gemini 3 Flash is better at interpreting user intent, pulling in up-to-date information and links, and organizing answers with visuals and suggestions. This model is also supposed to handle more complex, multi-part questions, such as planning a trip or quickly learning a new topic. External media content (www.youtube.com) has been blocked here. When loading or playing, connections are established to the servers of the respective providers. Personal data may be communicated to the providers in the process. You can find more information in our privacy policy. Allow external media content Google's published benchmarks show Gemini 3 Flash hitting 90.4 percent on GPQA Diamond, a PhD-level science test. On Humanity's Last Exam, it scored 33.7 percent solo and 43.5 percent with search and code tools. The AIME 2025 math test came in at 95.2 percent without tools and 99.7 percent with code execution. On SWE-bench Verified, a highly competitive coding benchmark, 3 Flash reaches 78 percent. Google says that's actually better than Gemini 3 Pro, though it still falls short of GPT-5.2 and Claude Opus 4.5. What matters more to developers is whether a model works reliably on everyday tasks. Google claims 3 Flash can adjust how long it thinks based on difficulty, and typically chews through fewer tokens than 2.5 Pro on normal workloads. External media content (www.youtube.com) has been blocked here. When loading or playing, connections are established to the servers of the respective providers. Personal data may be communicated to the providers in the process. You can find more information in our privacy policy. Allow external media content Visual reasoning and code execution get an upgrade Google says Gemini 3 Flash handles visual and spatial reasoning better than before, which should help with video analysis. The model can also run code to zoom into images, count objects, or make edits. Developers need to turn on \"thought signatures\" in the API or use the new Interactions API to access these features. External media content (www.youtube.com) has been blocked here. When loading or playing, connections are established to the servers of the respective providers. Personal data may be communicated to the providers in the process. You can find more information in our privacy policy. Allow external media content The model is available through Google AI Studio, the Gemini API, Google Antigravity, Gemini CLI, and Android Studio. Enterprise users can get it through Vertex AI. Google calls out the Gemini CLI as a good fit for developers who spend a lot of time in the terminal. A few companies have started building on Gemini 3 Flash. Gaming platform Astrocade uses it to power a system that generates full game plans and working code from a single prompt. Nick Walton, who runs Latitude, says the model lets his team handle harder tasks in their AI game engine without paying for expensive models like Sonnet 4.5. Resemble AI uses 3 Flash for spotting deepfakes in real time. The company says it analyzes multimodal content four times faster than Gemini 2.5 Pro did. Google also recently shipped a \"Deep Think\" mode for Gemini Ultra subscribers, which sits at the opposite end of the speed spectrum. It lets the model reason in parallel for tougher problems, but takes much longer to respond. That trade-off limits it to niche use cases for now—most users aren't willing to wait for better AI answers, as OpenAI's router rollback shows. Ad",
  "title": "Google makes Gemini 3 Flash the default for search and slashes reasoning costs",
  "url": "https://the-decoder.com/google-makes-gemini-3-flash-the-default-for-search-and-slashes-reasoning-costs/",
  "title_ko": "구글, 검색 기본 모델로 'Gemini 3 Flash' 채택 및 추론 비용 인하",
  "tags": [],
  "impact_score": 8.0,
  "IS_Analysis": {
    "Score_Commentary": "구글 검색이라는 전 지구적 인프라의 핵심 엔진 교체(X3) 및 즉시 상용화(Y4)로 IE 점수가 높다. 비용 효율성과 성능의 균형을 맞춘 실용적 혁신이다.",
    "Calculations": {
      "IW_Analysis": {
        "Inputs": {
          "Pe_Selection_Rule": "P4",
          "Pe_Entity_Name": "Google",
          "Pe_Tier": 1,
          "Se_Entity_Name": "None",
          "Se_Tier": 0,
          "PE/SE 선정이유": "PE: 모델 출시 및 서비스 적용 주체. SE: 경쟁사(OpenAI 등)와 비교되나 직접적 거래/분쟁 없음."
        },
        "Tier_Score": 3,
        "Gap_Score": 0,
        "IW_Score": 3
      },
      "IE_Analysis": {
        "Inputs": {
          "X_Magnitude_Code": 3,
          "Y_Evidence_Code": 4,
          "Scope_Matrix_Score": 3,
          "Criticality_C1_Provenness": 1,
          "Criticality_C2_Societal_Weight": 1,
          "Criticality_Total": 2,
          "SOTA_Check_Result": "Par"
        },
        "IE_Score": 5
      }
    }
  },
  "zero_echo_score": 3.2,
  "ZES_Raw_Metrics": {
    "Signal": {
      "T1": 8,
      "T2": 7,
      "T3": 7,
      "Rationale": "가격($0.50), 벤치마크 점수 등 정량적 데이터 풍부."
    },
    "Noise": {
      "P1": 2,
      "P2": 2,
      "P3": 1,
      "Rationale": "자사 모델 우위 강조 표현이 다소 있으나 벤치마크로 뒷받침됨."
    },
    "Utility": {
      "V1": 9,
      "V2": 9,
      "V3": 6,
      "Rationale": "즉시 사용 가능한 API 및 검색 적용으로 실용성 극대화."
    },
    "Fine_Adjustment": {
      "Score": 0.5,
      "Reason": "구체적인 가격 정책과 벤치마크 데이터 제공으로 정보 가치 높음."
    }
  },
  "schema_version": "V1.0",
  "raw_analysis": {
    "Article_ID": "0cf64f",
    "Meta": {
      "Specification_Version": "v 1.0.0",
      "Headline": "구글, 검색 기본 모델로 'Gemini 3 Flash' 채택 및 추론 비용 인하",
      "Summary": "구글이 추론 능력을 유지하면서 속도와 비용 효율을 개선한 Gemini 3 Flash를 출시하고 구글 검색의 기본 모델로 적용했다. 시각적 추론 및 코드 실행 기능이 강화되었으며 개발자 접근성을 높였다."
    },
    "IS_Analysis": {
      "Score_Commentary": "구글 검색이라는 전 지구적 인프라의 핵심 엔진 교체(X3) 및 즉시 상용화(Y4)로 IE 점수가 높다. 비용 효율성과 성능의 균형을 맞춘 실용적 혁신이다.",
      "Calculations": {
        "IW_Analysis": {
          "Inputs": {
            "Pe_Selection_Rule": "P4",
            "Pe_Entity_Name": "Google",
            "Pe_Tier": 1,
            "Se_Entity_Name": "None",
            "Se_Tier": 0,
            "PE/SE 선정이유": "PE: 모델 출시 및 서비스 적용 주체. SE: 경쟁사(OpenAI 등)와 비교되나 직접적 거래/분쟁 없음."
          },
          "Tier_Score": 3,
          "Gap_Score": 0,
          "IW_Score": 3
        },
        "IE_Analysis": {
          "Inputs": {
            "X_Magnitude_Code": 3,
            "Y_Evidence_Code": 4,
            "Scope_Matrix_Score": 3,
            "Criticality_C1_Provenness": 1,
            "Criticality_C2_Societal_Weight": 1,
            "Criticality_Total": 2,
            "SOTA_Check_Result": "Par"
          },
          "IE_Score": 5
        }
      }
    },
    "ZES_Raw_Metrics": {
      "Signal": {
        "T1": 8,
        "T2": 7,
        "T3": 7,
        "Rationale": "가격($0.50), 벤치마크 점수 등 정량적 데이터 풍부."
      },
      "Noise": {
        "P1": 2,
        "P2": 2,
        "P3": 1,
        "Rationale": "자사 모델 우위 강조 표현이 다소 있으나 벤치마크로 뒷받침됨."
      },
      "Utility": {
        "V1": 9,
        "V2": 9,
        "V3": 6,
        "Rationale": "즉시 사용 가능한 API 및 검색 적용으로 실용성 극대화."
      },
      "Fine_Adjustment": {
        "Score": 0.5,
        "Reason": "구체적인 가격 정책과 벤치마크 데이터 제공으로 정보 가치 높음."
      }
    }
  },
  "source_id": "the_decoder",
  "original_title": "Google makes Gemini 3 Flash the default for search and slashes reasoning costs",
  "evidence": {
    "breakdown": {
      "Signal": {
        "T1": 8.0,
        "T2": 7.0,
        "T3": 7.0,
        "S_Avg": 7.33
      },
      "Noise": {
        "P1": 2.0,
        "P2": 2.0,
        "P3": 1.0,
        "N_Avg": 1.67
      },
      "Utility": {
        "V1": 9.0,
        "V2": 9.0,
        "V3": 6.0,
        "U_Avg": 8.0
      },
      "Fine_Adjustment": 0.5,
      "ZS_Raw": 3.23,
      "ZS_Final": 3.2
    },
    "raw_metrics": {
      "Signal": {
        "T1": 8,
        "T2": 7,
        "T3": 7,
        "Rationale": "가격($0.50), 벤치마크 점수 등 정량적 데이터 풍부."
      },
      "Noise": {
        "P1": 2,
        "P2": 2,
        "P3": 1,
        "Rationale": "자사 모델 우위 강조 표현이 다소 있으나 벤치마크로 뒷받침됨."
      },
      "Utility": {
        "V1": 9,
        "V2": 9,
        "V3": 6,
        "Rationale": "즉시 사용 가능한 API 및 검색 적용으로 실용성 극대화."
      },
      "Fine_Adjustment": {
        "Score": 0.5,
        "Reason": "구체적인 가격 정책과 벤치마크 데이터 제공으로 정보 가치 높음."
      }
    }
  },
  "impact_evidence": {
    "calculations": {
      "IW_Analysis": {
        "Tier_Score": 3.0,
        "Gap_Score": 0.0,
        "IW_Total": 3.0
      },
      "IE_Analysis": {
        "Scope_Total": 3.0,
        "Criticality_Total": 2.0,
        "IE_Total": 5.0
      },
      "IS_Raw": 8.0,
      "IS_Final": 8.0,
      "Score_Commentary": "구글 검색이라는 전 지구적 인프라의 핵심 엔진 교체(X3) 및 즉시 상용화(Y4)로 IE 점수가 높다. 비용 효율성과 성능의 균형을 맞춘 실용적 혁신이다."
    },
    "raw_inputs": {
      "Pe_Selection_Rule": "P4",
      "Pe_Entity_Name": "Google",
      "Pe_Tier": 1,
      "Se_Entity_Name": "None",
      "Se_Tier": 0,
      "PE/SE 선정이유": "PE: 모델 출시 및 서비스 적용 주체. SE: 경쟁사(OpenAI 등)와 비교되나 직접적 거래/분쟁 없음."
    },
    "raw_ie_inputs": {
      "X_Magnitude_Code": 3,
      "Y_Evidence_Code": 4,
      "Scope_Matrix_Score": 3,
      "Criticality_C1_Provenness": 1,
      "Criticality_C2_Societal_Weight": 1,
      "Criticality_Total": 2,
      "SOTA_Check_Result": "Par"
    }
  },
  "crawled_at": "2025-12-18T15:41:11.845702+00:00",
  "edition": "251218_THU_1",
  "status": "ACCEPTED",
  "saved": true,
  "saved_at": "2025-12-18T15:41:11.849325+00:00",
  "version": "V1.0",
  "staged_at": "2025-12-18T16:28:02.145682+00:00",
  "staged": true,
  "category": "AI/ML",
  "dedup_status": "selected"
}