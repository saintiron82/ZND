{
  "title": "스타클라우드, 세계 최초 우주에서 고성능 GPU로 LLM 훈련·실행 성공",
  "summary": "엔비디아의 지원을 받는 미국 스타트업 스타클라우드(Starcloud)가 세계 최초로 우주 공간에서 고성능 인공지능(AI) 모델을 훈련하고 실행하는 데 성공했다. 이는 지상 데이터센터의 에너지·환경 부담을 근본적으로 해결할 차세대 ‘궤도(orbital) 데이터센터’ 시대의 서막으로 평가됐다.스타클라우드는 10일(현지시간) 클라우드 인프라 스타트업 크루소와 지난달 발사한 엔비디아 'H100' GPU 탑재 위성 ‘스타클라우드-1(Starcloud-1)’에서 구글의 오픈 소스 소형언어모델(sLM) ‘젬마(Gemma)’를 실행해 응답 생성에",
  "published_at": "2025-12-11T18:00:00+09:00",
  "modified_at": "2025-12-11T18:39:08+09:00",
  "author": [
    "박찬 기자"
  ],
  "image": "https://cdn.aitimes.com/news/photo/202512/204710_206037_1324.png",
  "text": "기사를 읽어드립니다. 스타클라우드-1 위성은 11월2일 스페이스X 로켓에 실려 우주로 발사됐다. (사진=스페이스X/스타클라우드) 엔비디아의 지원을 받는 미국 스타트업 스타클라우드(Starcloud)가 세계 최초로 우주 공간에서 고성능 인공지능(AI) 모델을 훈련하고 실행하는 데 성공했다. 이는 지상 데이터센터의 에너지·환경 부담을 근본적으로 해결할 차세대 ‘궤도(orbital) 데이터센터’ 시대의 서막으로 평가됐다. 스타클라우드는 10일(현지시간) 클라우드 인프라 스타트업 크루소와 지난달 발사한 엔비디아 'H100' GPU 탑재 위성 ‘스타클라우드-1(Starcloud-1)’에서 구글의 오픈 소스 소형언어모델(sLM) ‘젬마(Gemma)’를 실행해 응답 생성에 성공했다고 발표했다. 이는 고성능 엔비디아 GPU를 이용한 모델이 지구 밖에서 가동된 최초의 사례로 기록됐다. 스타클라우드-1에 탑재된 젬마는 “지구인들에게 인사한다”라며 우주에서 첫 메시지를 전송한 것으로 알려졌다. 필립 존스턴 스타클라우드 CEO는 “우주 데이터센터는 지상 대비 에너지 비용을 10배 낮출 수 있다”라며 “태양광이 24시간 끊기지 않고, 냉각과 유지비가 크게 줄어드는 점이 핵심”이라고 말했다. 국제에너지기구(IEA)에 따르면 전 세계 데이터센터 전력 소비는 2030년까지 2배 이상 증가할 전망이다. 이미 지상 데이터센터는 전력망 부담, 물 사용, 탄소 배출 등 각종 환경 문제의 주요 원인으로 지목된다. 존스턴 CEO는 “지상에서 가능한 모든 AI 작업을 우주에서도 수행할 수 있다”라며 “앞으로 대규모 AI 트레이닝 클러스터는 지상보다 우주에서 구축하는 것이 유리해질 것”이라고 강조했다. 스타클라우드는 H100 GPU로 안드레이 카르파시 오픈AI 공동 창립자가 제작한 '나노GPT(NanoGPT)'를 학습하는 데도 성공했다. 데이터로는 셰익스피어 전집이 사용됐으며, 모델은 셰익스피어식 영어로 말하는 능력을 획득했다. 스타클라우드는 앞으로 너비와 높이가 각각 4킬로미터(km)에 달하는 태양광·냉각 패널을 갖춘 5기가와트(GW)급 우주 데이터센터를 구축할 계획이다. 이는 미국 내 최대 발전소보다 큰 규모로, 지상에서 동일한 용량의 태양광 단지를 건설하는 것보다 훨씬 작고 경제적이다. 다음 위성 발사는 2026년 10월로 예정돼 있으며, 여러개의 H100 칩과 ‘블랙웰’ 칩이 탑재될 예정이다. 또 크루소의 플랫폼을 얹어, 고객들이 우주에서 직접 AI 워크로드를 운영할 수 있는 기능이 포함된다. 디온 해리스 엔비디아 AI 인프라 총괄은 “작은 데이터센터 하나에서 시작했지만, 이번 발사는 ‘무한한 태양 에너지 시대의 우주 컴퓨팅’으로 가는 거대한 도약”이라고 말했다. 박찬 기자 cpark@aitimes.com",
  "url": "https://www.aitimes.com/news/articleView.html?idxno=204710",
  "article_id": "07fcc6",
  "cached_at": "2025-12-11T16:38:16.750652+00:00",
  "mll_status": "error: API Error: [invoke_v2] LLM 호출 실패: Error code: 400 ",
  "version": "V1.0"
}