# -*- coding: utf-8 -*-
"""
Article Registry - ì¤‘ì•™ ê¸°ì‚¬ ì •ë³´ ì‹œìŠ¤í…œ
ëª¨ë“  ê¸°ì‚¬ ë©”íƒ€ë°ì´í„°ì˜ SSOT (Single Source of Truth)

ì„œë²„ ì‹œì‘ ì‹œ ë¡œì»¬ ìºì‹œì™€ Firestoreì—ì„œ ê¸°ì‚¬ë¥¼ ë¡œë“œí•˜ì—¬
ì¸ë©”ëª¨ë¦¬ ìƒ‰ì¸ì„ êµ¬ì¶•í•˜ê³ , ëª¨ë“  ìƒíƒœ ë³€ê²½ì„ ì¤‘ì•™ì—ì„œ ê´€ë¦¬í•©ë‹ˆë‹¤.
"""
import os
import glob
import json
from dataclasses import dataclass, field, asdict
from datetime import datetime, timezone, timedelta
from typing import Dict, List, Optional, Set, Any
from enum import Enum



@dataclass
class ArticleInfo:
    """ê¸°ì‚¬ ë©”íƒ€ë°ì´í„° (ê²½ëŸ‰í™”ëœ ì¸ë±ìŠ¤ìš©)"""
    article_id: str
    url: str
    state: str
    title: str
    source_id: str
    created_at: str
    updated_at: str
    # ì ìˆ˜ ì •ë³´ (ì¡°íšŒ/ì •ë ¬ìš©)
    impact_score: float = 0.0
    zero_echo_score: float = 0.0
    # ë¶„ë¥˜ ì •ë³´
    category: str = ""
    # ì›ë³¸ ë°ì´í„° ê²½ë¡œ (ìƒì„¸ ì¡°íšŒ ì‹œ ì‚¬ìš©)
    cache_path: Optional[str] = None
    firestore_synced: bool = False
    # ë°œí–‰ ì •ë³´
    edition_code: str = ""
    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)


class ArticleRegistry:
    """
    ì¤‘ì•™ ê¸°ì‚¬ ë ˆì§€ìŠ¤íŠ¸ë¦¬ (ì‹±ê¸€í†¤)
    
    ëª¨ë“  ê¸°ì‚¬ ì¡°íšŒ/ë³€ê²½ì€ ì´ í´ë˜ìŠ¤ë¥¼ í†µí•´ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    
    _instance = None
    _initialized = False
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        if ArticleRegistry._initialized:
            return
        
        # ì¸ë±ìŠ¤ êµ¬ì¡°
        self._articles: Dict[str, ArticleInfo] = {}  # article_id -> ArticleInfo (ë©”íƒ€ë°ì´í„°)
        self._full_data: Dict[str, Dict] = {}         # article_id -> ì „ì²´ JSON ë°ì´í„° (ìºì‹œ)
        self._by_state: Dict[str, Set[str]] = {}     # state -> Set[article_id]
        self._by_url: Dict[str, str] = {}            # url_hash -> article_id
        self._by_edition: Dict[str, Set[str]] = {}   # edition_code -> Set[article_id]
        
        # ì„¤ì •
        self._max_age_days = int(os.getenv('REGISTRY_MAX_AGE_DAYS', 7))
        self._cache_root = None
        self._db = None
        
        # í†µê³„
        self._stats = {
            'local_loaded': 0,
            'firestore_loaded': 0,
            'duplicates_merged': 0,
            'initialized_at': None
        }
    
    # =========================================================================
    # Initialization
    # =========================================================================
    
    def initialize(self, cache_root: str = None, db_client = None):
        """
        ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì´ˆê¸°í™” - ì„œë²„ ì‹œì‘ ì‹œ í•œ ë²ˆ í˜¸ì¶œ
        
        Args:
            cache_root: ë¡œì»¬ ìºì‹œ ë£¨íŠ¸ ê²½ë¡œ
            db_client: FirestoreClient ì¸ìŠ¤í„´ìŠ¤
        """
        if ArticleRegistry._initialized:
            print("âš ï¸ [Registry] Already initialized, skipping.")
            return
        
        print("ğŸš€ [Registry] Initializing Article Registry...")
        start_time = datetime.now()
        
        # ê²½ë¡œ ì„¤ì •
        if cache_root:
            self._cache_root = cache_root
        else:
            base_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
            env = os.getenv('ZND_ENV', 'dev')
            self._cache_root = os.path.join(base_dir, 'cache', env)
        
        self._db = db_client
        
        
        # 1. ë¡œì»¬ ìºì‹œ ë¡œë“œ (í¬ë¡¤ë§ ì›ë³¸ ë°±ì—…ìš©)
        self._load_from_local_cache()
        
        # 2. Firestoreì—ì„œ ë¯¸ë°œí–‰ ê¸°ì‚¬ ë™ê¸°í™” (í•„ìˆ˜)
        # - ë¯¸ë°œí–‰ ê¸°ì‚¬ëŠ” ì„œë²„ì™€ í•­ìƒ ë™ê¸°í™”ë˜ì–´ì•¼ í•¨
        # - REGISTRY_SKIP_FIRESTORE=true ë¡œ ê°•ì œ ë¹„í™œì„±í™” ê°€ëŠ¥ (ê°œë°œ/í…ŒìŠ¤íŠ¸ìš©)
        skip_firestore = os.getenv('REGISTRY_SKIP_FIRESTORE', 'false').lower() == 'true'
        
        if self._db and not skip_firestore:
            self._load_from_firestore()
        
        # ì™„ë£Œ
        elapsed = (datetime.now() - start_time).total_seconds()
        self._stats['initialized_at'] = datetime.now(timezone.utc).isoformat()
        
        ArticleRegistry._initialized = True
        
        print(f"âœ… [Registry] Initialized in {elapsed:.2f}s")
        print(f"   ğŸ“‚ Local: {self._stats['local_loaded']} articles")
        print(f"   â˜ï¸ Firestore: {self._stats['firestore_loaded']} articles")
        print(f"   ğŸ”„ Merged Duplicates: {self._stats['duplicates_merged']}")
        print(f"   ğŸ“Š Total: {len(self._articles)} unique articles")
    
    def _load_from_local_cache(self):
        """ë¡œì»¬ ìºì‹œì—ì„œ ê¸°ì‚¬ ë¡œë“œ (ì‹œê°„ ì œí•œ ì ìš©)"""
        print(f"ğŸ” [DEBUG] cache_root = '{self._cache_root}'")
        print(f"ğŸ” [DEBUG] os.path.exists = {os.path.exists(self._cache_root)}")
        
        if not os.path.exists(self._cache_root):
            print(f"âš ï¸ [Registry] Cache root not found: {self._cache_root}")
            return
        
        cutoff_date = datetime.now() - timedelta(days=self._max_age_days)
        cutoff_str = cutoff_date.strftime('%Y-%m-%d')
        print(f"ğŸ” [DEBUG] now = {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print(f"ğŸ” [DEBUG] cutoff_str = '{cutoff_str}' (max_age_days={self._max_age_days})")
        
        # ë‚ ì§œë³„ í´ë” ìˆœíšŒ
        date_folders = glob.glob(os.path.join(self._cache_root, '*'))
        print(f"ğŸ” [DEBUG] Found folders: {[os.path.basename(f) for f in date_folders]}")
        
        for folder in sorted(date_folders, reverse=True):  # ìµœì‹ ìˆœ
            folder_name = os.path.basename(folder)
            
            # ë‚ ì§œ í˜•ì‹ ì²´í¬ ë° ì‹œê°„ ì œí•œ ì ìš©
            if folder_name < cutoff_str:
                print(f"   â­ï¸ [Registry] Skipping old folder: {folder_name} (< {cutoff_str})")
                continue
            
            # í´ë” ë‚´ JSON íŒŒì¼ ë¡œë“œ
            json_files = glob.glob(os.path.join(folder, '*.json'))
            
            for fpath in json_files:
                try:
                    with open(fpath, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    
                    # register()ë¡œ ë¡œì»¬ + Firestore ë‘˜ ë‹¤ ë™ê¸°í™”
                    info = self.register(data, cache_path=fpath)
                    if info:
                        self._stats['local_loaded'] += 1
                        
                except Exception as e:
                    print(f"âš ï¸ [Registry] Error loading {fpath}: {e}")
    
    def _load_from_firestore(self):
        """Firestoreì—ì„œ ë¯¸ë°œí–‰ ê¸°ì‚¬ë§Œ ë¡œë“œ (PUBLISHEDëŠ” Lazy Load)"""
        cutoff_date = datetime.now(timezone.utc) - timedelta(days=self._max_age_days)
        cutoff_iso = cutoff_date.isoformat()
        
        # ë¯¸ë°œí–‰ ìƒíƒœë§Œ ë¡œë“œ (PUBLISHEDëŠ” ìš”ì²­ ì‹œ Lazy Load)
        states_to_load = ['COLLECTED', 'ANALYZED', 'CLASSIFIED', 'REJECTED']
        print(f"   ğŸ“¡ [Registry] Loading unpublished from Firestore: {states_to_load}")
        
        for state in states_to_load:
            try:
                # FirestoreClient ì§ì ‘ í˜¸ì¶œ
                articles = self._db.list_articles_by_state(state, limit=500) if self._db else []
                
                for data in articles:
                    # ì‹œê°„ ì²´í¬ (published_at ìš°ì„ , ì—†ìœ¼ë©´ created_at)
                    published_at = data.get('_original', {}).get('published_at', '')
                    created_at = data.get('_header', {}).get('created_at', '')
                    date_source = published_at or created_at
                    if date_source and date_source < cutoff_iso:
                        continue  # ì˜¤ë˜ëœ ê¸°ì‚¬ ìŠ¤í‚µ
                    
                    info = self._parse_article_data(data)
                    if info:
                        existing = self._articles.get(info.article_id)
                        if existing:
                            # ì´ë¯¸ ë¡œì»¬ì—ì„œ ë¡œë“œë¨ - Firestore ìƒíƒœë¡œ ê°±ì‹ 
                            existing.firestore_synced = True
                            
                            # REJECTEDëŠ” ìµœìš°ì„  ì ìš© (íê¸°ëœ ê¸°ì‚¬ëŠ” ë³µêµ¬ ë¶ˆê°€)
                            if info.state == 'REJECTED' and existing.state != 'REJECTED':
                                self._update_article_state(existing, 'REJECTED')
                                print(f"   âš ï¸ [Registry] Synced REJECTED: {info.article_id}")
                            # Firestore ìƒíƒœê°€ ë” ì§„í–‰ëœ ê²½ìš° ì ìš©
                            elif self._is_more_advanced_state(info.state, existing.state):
                                self._update_article_state(existing, info.state)
                                print(f"   ğŸ”„ [Registry] Synced state: {info.article_id} ({existing.state} â†’ {info.state})")
                            
                            self._stats['duplicates_merged'] += 1
                        else:
                            # Firestoreì—ë§Œ ìˆëŠ” ë°ì´í„° â†’ ë¡œì»¬ì—ë„ ì €ì¥
                            info.firestore_synced = True
                            
                            # ì „ì²´ ë°ì´í„° ìºì‹œì— ì €ì¥ (ë©”ëª¨ë¦¬)
                            self._full_data[info.article_id] = data
                            
                            # ë¡œì»¬ ìºì‹œì— ì €ì¥
                            cache_path = self._save_to_local_cache(data, info.article_id)
                            if cache_path:
                                info.cache_path = cache_path
                            
                            self._register_article(info, source='firestore')
                            self._stats['firestore_loaded'] += 1
                            
            except Exception as e:
                print(f"âš ï¸ [Registry] Firestore load error for {state}: {e}")
    
    def _parse_article_data(self, data: Dict, cache_path: str = None) -> Optional[ArticleInfo]:
        """ì›ì‹œ ë°ì´í„°ë¥¼ ArticleInfoë¡œ ë³€í™˜"""
        try:
            # V2 Schema (with _header)
            if '_header' in data:
                header = data['_header']
                original = data.get('_original', {})
                analysis = data.get('_analysis', {}) or {}
                classification = data.get('_classification', {}) or {}
                
                # Extract edition_code from various possible locations
                edition_code = (
                    header.get('edition_code', '') or
                    data.get('edition_code', '') or
                    classification.get('edition_code', '')
                )
                
                return ArticleInfo(
                    article_id=header.get('article_id', ''),
                    url=original.get('url', ''),
                    state=header.get('state', 'UNKNOWN'),
                    title=original.get('title', '') or analysis.get('title_ko', ''),
                    source_id=original.get('source_id', 'unknown'),
                    created_at=header.get('created_at', ''),
                    updated_at=header.get('updated_at', ''),
                    impact_score=float(analysis.get('impact_score', 0) or 0),
                    zero_echo_score=float(analysis.get('zero_echo_score', 0) or 0),
                    category=classification.get('category', ''),
                    cache_path=cache_path,
                    firestore_synced=False,
                    edition_code=edition_code
                )
            
            # V1 Schema (Legacy flat structure)
            else:
                return ArticleInfo(
                    article_id=data.get('article_id', ''),
                    url=data.get('url', ''),
                    state=data.get('state', 'COLLECTED'),
                    title=data.get('title_ko', '') or data.get('title', ''),
                    source_id=data.get('source_id', 'unknown'),
                    created_at=data.get('crawled_at', ''),
                    updated_at=data.get('crawled_at', ''),
                    impact_score=float(data.get('impact_score', 0) or 0),
                    zero_echo_score=float(data.get('zero_echo_score', 0) or 0),
                    category=data.get('category', ''),
                    cache_path=cache_path,
                    firestore_synced=False,
                    edition_code=data.get('edition_code', '')
                )
        except Exception as e:
            print(f"âš ï¸ [Registry] Parse error: {e}")
            return None
    
    def _register_article(self, info: ArticleInfo, source: str = 'unknown'):
        """ê¸°ì‚¬ë¥¼ ì¸ë±ìŠ¤ì— ë“±ë¡"""
        if not info.article_id:
            return
        
        # ë©”ì¸ ì¸ë±ìŠ¤
        self._articles[info.article_id] = info
        
        # ìƒíƒœë³„ ì¸ë±ìŠ¤
        if info.state not in self._by_state:
            self._by_state[info.state] = set()
        self._by_state[info.state].add(info.article_id)
        
        # URL ì¸ë±ìŠ¤
        if info.url:
            url_hash = self._url_to_hash(info.url)
            self._by_url[url_hash] = info.article_id
        
        # íšŒì°¨ ì¸ë±ìŠ¤
        if info.edition_code:
            if info.edition_code not in self._by_edition:
                self._by_edition[info.edition_code] = set()
            self._by_edition[info.edition_code].add(info.article_id)
    
    def _url_to_hash(self, url: str) -> str:
        """URLì„ í•´ì‹œë¡œ ë³€í™˜"""
        import hashlib
        return hashlib.md5(url.encode()).hexdigest()[:12]
    
    def _is_more_advanced_state(self, new_state: str, current_state: str) -> bool:
        """ìƒˆ ìƒíƒœê°€ í˜„ì¬ ìƒíƒœë³´ë‹¤ ë” ì§„í–‰ëœ ìƒíƒœì¸ì§€ í™•ì¸"""
        # ìƒíƒœ ì§„í–‰ ìˆœì„œ (ë†’ì„ìˆ˜ë¡ ë” ì§„í–‰ë¨)
        state_order = {
            'COLLECTED': 1,
            'ANALYZED': 2,
            'CLASSIFIED': 3,
            'PUBLISHED': 4,
            'REJECTED': 0  # REJECTEDëŠ” ë³„ë„ ì²˜ë¦¬ (ìµœìš°ì„ )
        }
        return state_order.get(new_state, 0) > state_order.get(current_state, 0)
    
    def _update_article_state(self, info: ArticleInfo, new_state: str):
        """ê¸°ì‚¬ ìƒíƒœ ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸ (ë‚´ë¶€ìš©)"""
        old_state = info.state
        
        # ì´ì „ ìƒíƒœ ì¸ë±ìŠ¤ì—ì„œ ì œê±°
        if old_state in self._by_state:
            self._by_state[old_state].discard(info.article_id)
        
        # ìƒˆ ìƒíƒœ ì„¤ì •
        info.state = new_state
        
        # ìƒˆ ìƒíƒœ ì¸ë±ìŠ¤ì— ì¶”ê°€
        if new_state not in self._by_state:
            self._by_state[new_state] = set()
        self._by_state[new_state].add(info.article_id)
    
    def _save_to_local_cache(self, data: Dict, article_id: str) -> Optional[str]:
        """Firestore ë°ì´í„°ë¥¼ ë¡œì»¬ ìºì‹œì— ì €ì¥"""
        try:
            # ë‚ ì§œ í´ë” ê²°ì • (published_at ìš°ì„ , ì—†ìœ¼ë©´ created_at, ìµœí›„ì— ì˜¤ëŠ˜)
            published_at = data.get('_original', {}).get('published_at', '')
            created_at = data.get('_header', {}).get('created_at', '')
            
            date_source = published_at or created_at
            if date_source:
                date_str = date_source.split('T')[0]
            else:
                date_str = datetime.now().strftime('%Y-%m-%d')
            
            # ìºì‹œ ê²½ë¡œ ìƒì„±
            cache_folder = os.path.join(self._cache_root, date_str)
            os.makedirs(cache_folder, exist_ok=True)
            
            cache_path = os.path.join(cache_folder, f'{article_id}.json')
            
            with open(cache_path, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            print(f"   ğŸ’¾ [Registry] Saved to local: {cache_path}")
            return cache_path
        except Exception as e:
            print(f"   âš ï¸ [Registry] Local save failed: {e}")
            return None
    
    # =========================================================================
    # Query Operations
    # =========================================================================
    
    def get(self, article_id: str) -> Optional[ArticleInfo]:
        """ê¸°ì‚¬ ë©”íƒ€ë°ì´í„° ì¡°íšŒ (IDë¡œ)"""
        return self._articles.get(article_id)
    
    def get_full_data(self, article_id: str) -> Optional[Dict[str, Any]]:
        """ì „ì²´ ê¸°ì‚¬ ë°ì´í„° ë°˜í™˜ (ë©”ëª¨ë¦¬ ìºì‹œ)"""
        return self._full_data.get(article_id)

    def find_and_register(self, article_id: str) -> Optional[ArticleInfo]:
        """
        [Lazy Load] Registryì— ì—†ëŠ” ê¸°ì‚¬ë¥¼ ë””ìŠ¤í¬(cache)ì—ì„œ ì°¾ì•„ ë“±ë¡.
        (ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ì•„ì§ ë¡œë“œë˜ì§€ ì•Šì€ ê²½ìš° ëŒ€ë¹„)
        """
        import glob
        import json
        import os
        
        # Cache Root ì°¾ê¸° (ë¯¸ì´ˆê¸°í™” ëŒ€ë¹„)
        if self._cache_root:
            cache_root = self._cache_root
        else:
            base_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
            env = os.getenv('ZND_ENV', 'dev')
            cache_root = os.path.join(base_dir, 'cache', env)
            
        if not os.path.exists(cache_root):
            return None
            
        # Recursive Search
        # [Fix] íŒŒì¼ëª… íŒ¨í„´ ìœ ì—°í™” (source_id ìœ ë¬´ ìƒê´€ì—†ì´ ë§¤ì¹­)
        # ê¸°ì¡´: *_{article_id}.json -> ìˆ˜ì •: *{article_id}.json
        pattern = f"*{article_id}.json"
        search_pattern = os.path.join(cache_root, "**", pattern)
        files = glob.glob(search_pattern, recursive=True)
        
        if not files:
            return None
            
        target_file = files[0]
        
        try:
            with open(target_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            info = self._parse_article_data(data, cache_path=target_file)
            if info:
                self._register_article(info, source='lazy_disk')
                print(f"ğŸ“¦ [Registry] Lazy loaded: {article_id} from {target_file}")
                return info
        except Exception as e:
            print(f"âš ï¸ [Registry] Lazy load failed for {article_id}: {e}")
            
        return None
    
    def get_by_url(self, url: str) -> Optional[ArticleInfo]:
        """ê¸°ì‚¬ ì¡°íšŒ (URLë¡œ)"""
        url_hash = self._url_to_hash(url)
        article_id = self._by_url.get(url_hash)
        if article_id:
            return self._articles.get(article_id)
        return None
    
    def get_full_data(self, article_id: str) -> Optional[dict]:
        """
        ê¸°ì‚¬ ì „ì²´ ë°ì´í„° ì¡°íšŒ (ë©”ëª¨ë¦¬ ìºì‹œ)
        
        Firestore ë¹„ìš© ì ˆê°ì„ ìœ„í•´ ArticleManager.get()ì—ì„œ ìš°ì„  í˜¸ì¶œ
        
        Returns:
            ìºì‹œëœ ì „ì²´ ê¸°ì‚¬ ë°ì´í„° ë˜ëŠ” None (ìºì‹œ ë¯¸ìŠ¤)
        """
        return self._full_data.get(article_id)
    
    def find_by_state(self, state: str, limit: int = 100) -> List[ArticleInfo]:
        """ìƒíƒœë³„ ê¸°ì‚¬ ëª©ë¡ ì¡°íšŒ (+ ì‹¤ì‹œê°„ ìºì‹œ ìŠ¤ìº”)"""
        # 1. ë©”ëª¨ë¦¬ ì¸ë±ìŠ¤ì—ì„œ ì¡°íšŒ
        article_ids = self._by_state.get(state, set())
        articles = [self._articles[aid] for aid in article_ids if aid in self._articles]
        
        # 2. ìµœê·¼ ìºì‹œ íŒŒì¼ ìŠ¤ìº” (ì„œë²„ ì‹œì‘ ì´í›„ ì¶”ê°€ëœ íŒŒì¼)
        try:
            if self._cache_root and os.path.exists(self._cache_root):
                cutoff_date = datetime.now() - timedelta(days=self._max_age_days)
                cutoff_str = cutoff_date.strftime('%Y-%m-%d')
                
                for folder in glob.glob(os.path.join(self._cache_root, '*')):
                    folder_name = os.path.basename(folder)
                    if not folder_name.startswith('20') or folder_name < cutoff_str:
                        continue
                    
                    for fpath in glob.glob(os.path.join(folder, '*.json')):
                        try:
                            article_id = os.path.basename(fpath).replace('.json', '')
                            if article_id in self._articles:
                                continue  # ì´ë¯¸ ì¸ë±ìŠ¤ì— ìˆìŒ
                            
                            with open(fpath, 'r', encoding='utf-8') as f:
                                data = json.load(f)
                            
                            file_state = data.get('_header', {}).get('state')
                            if file_state == state:
                                # register()ë¡œ ë¡œì»¬ + Firestore ë‘˜ ë‹¤ ì €ì¥
                                info = self.register(data, cache_path=fpath)
                                if info:
                                    articles.append(info)
                        except Exception:
                            continue
        except Exception as e:
            print(f"âš ï¸ [Registry] Live scan error: {e}")
        
        # 3. ìµœì‹ ìˆœ ì •ë ¬
        articles.sort(key=lambda x: x.updated_at or '', reverse=True)
        
        return articles[:limit]
    
    def find_by_states(self, states: List[str], limit: int = 100) -> List[ArticleInfo]:
        """ì—¬ëŸ¬ ìƒíƒœì˜ ê¸°ì‚¬ ëª©ë¡ ì¡°íšŒ"""
        all_articles = []
        for state in states:
            all_articles.extend(self.find_by_state(state, limit))
        
        # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
        seen = set()
        unique = []
        for a in all_articles:
            if a.article_id not in seen:
                seen.add(a.article_id)
                unique.append(a)
        
        unique.sort(key=lambda x: x.updated_at or '', reverse=True)
        return unique[:limit]
    
    def get_all(self, limit: int = 500) -> List[ArticleInfo]:
        """ì „ì²´ ê¸°ì‚¬ ëª©ë¡"""
        articles = list(self._articles.values())
        articles.sort(key=lambda x: x.updated_at or '', reverse=True)
        return articles[:limit]
    
    def count(self) -> int:
        """ì „ì²´ ê¸°ì‚¬ ìˆ˜"""
        return len(self._articles)
    
    def count_by_state(self, state: str) -> int:
        """ìƒíƒœë³„ ê¸°ì‚¬ ìˆ˜"""
        return len(self._by_state.get(state, set()))
    
    def get_by_edition(self, edition_code: str) -> List[ArticleInfo]:
        """íšŒì°¨ë³„ ê¸°ì‚¬ ëª©ë¡ ì¡°íšŒ"""
        article_ids = self._by_edition.get(edition_code, set())
        articles = [self._articles[aid] for aid in article_ids if aid in self._articles]
        articles.sort(key=lambda x: x.updated_at or '', reverse=True)
        return articles
    
    def get_stats(self) -> Dict[str, Any]:
        """ë ˆì§€ìŠ¤íŠ¸ë¦¬ í†µê³„"""
        return {
            **self._stats,
            'total_articles': len(self._articles),
            'by_state': {state: len(ids) for state, ids in self._by_state.items()}
        }
    
    # =========================================================================
    # Write Operations
    # =========================================================================
    
    def register(self, data: Dict[str, Any], cache_path: str = None) -> Optional[ArticleInfo]:
        """
        ìƒˆ ê¸°ì‚¬ ë“±ë¡ (í¬ë¡¤ë§/ë¶„ì„ ì™„ë£Œ ì‹œ)
        - ìˆ˜ì§‘ë„ ìƒíƒœ ë³€í™”ì´ë¯€ë¡œ ë¡œì»¬ + Firestore ë‘˜ ë‹¤ ì €ì¥
        - íˆìŠ¤í† ë¦¬ë„ ë™ê¸°í™”
        """
        info = self._parse_article_data(data, cache_path)
        if info:
            self._register_article(info, source='new')
            
            # ì „ì²´ ë°ì´í„° ìºì‹œì— ì €ì¥ (ë©”ëª¨ë¦¬)
            self._full_data[info.article_id] = data
            
            # Firestoreì—ë„ ì €ì¥ (ìˆ˜ì§‘ = ìƒíƒœ ë³€í™” = ì €ì¥)
            if self._db:
                try:
                    self._db.save_article(info.article_id, data)
                    
                    # íˆìŠ¤í† ë¦¬ë„ ì €ì¥ (URLì´ ìˆëŠ” ê²½ìš°)
                    url = info.url or data.get('_original', {}).get('url')
                    if url:
                        state = info.state or data.get('_header', {}).get('state', 'COLLECTED')
                        self._db.save_history(url, status=state, article_id=info.article_id)
                except Exception as e:
                    print(f"âš ï¸ [Registry] Firestore save on register failed: {e}")
            
            return info
        return None
    
    def update_state(self, article_id: str, new_state: str, by: str = 'system', updates: Dict[str, Any] = None) -> bool:
        """
        ê¸°ì‚¬ ìƒíƒœ ë³€ê²½ ë° ë°ì´í„° ì—…ë°ì´íŠ¸ (ë ˆì§€ìŠ¤íŠ¸ë¦¬ + ì €ì¥ì†Œ ë™ì‹œ ì—…ë°ì´íŠ¸)
        
        Args:
            article_id: ê¸°ì‚¬ ID
            new_state: ìƒˆ ìƒíƒœ
            by: ë³€ê²½ ì£¼ì²´
            updates: ì¶”ê°€ë¡œ ì—…ë°ì´íŠ¸í•  ë°ì´í„° (ì˜ˆ: ë¶„ë¥˜ ì •ë³´, ë¶„ì„ ê²°ê³¼ ë“±)
                     í˜•ì‹: {'field': value} or {'section.field': value}

            
        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        info = self._articles.get(article_id)
        if not info:
            print(f"âš ï¸ [Registry] Article not found: {article_id}")
            return False
        
        old_state = info.state
        now = datetime.now(timezone.utc).isoformat()
        
        # 1. ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì—…ë°ì´íŠ¸
        # ì´ì „ ìƒíƒœ ì¸ë±ìŠ¤ì—ì„œ ì œê±°
        if old_state in self._by_state:
            self._by_state[old_state].discard(article_id)
        
        # ìƒˆ ìƒíƒœ ì„¤ì •
        info.state = new_state
        info.updated_at = now
        
        # ìƒˆ ìƒíƒœ ì¸ë±ìŠ¤ì— ì¶”ê°€
        if new_state not in self._by_state:
            self._by_state[new_state] = set()
        self._by_state[new_state].add(article_id)
        
        # 2. ë°ì´í„° ì €ì¥ (Update = Save Full Data)
        # ë‹¨ìˆœíˆ ìƒíƒœë§Œ ë°”ê¾¸ëŠ” ê²Œ ì•„ë‹ˆë¼, ì „ì²´ ë°ì´í„°ë¥¼ ê°±ì‹ í•˜ì—¬ ì •ë³¸ ìœ ì§€
        save_success = self._save_full_state(info, new_state, by, now, updates)
        
        if save_success:
            print(f"âœ… [Registry] State changed: {article_id} ({old_state} â†’ {new_state})")
            return True
        else:
            # ë¡¤ë°±
            info.state = old_state
            if old_state not in self._by_state:
                self._by_state[old_state] = set()
            self._by_state[old_state].add(article_id)
            self._by_state[new_state].discard(article_id)
            print(f"âŒ [Registry] State change failed, rolled back: {article_id}")
            return False
    
    def _save_full_state(self, info: ArticleInfo, new_state: str, by: str, timestamp: str, updates: Dict[str, Any] = None) -> bool:
        """
        ì „ì²´ ê¸°ì‚¬ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ê°±ì‹ í•˜ì—¬ ì €ì¥ì†Œ(DB, Local)ì— ì €ì¥ (SSOT ìœ ì§€)
        """
        import json
        
        full_data = None
        
        # 1. Load Full Data (Memory Priority -> Local File)
        if info.article_id in self._full_data:
             full_data = self._full_data[info.article_id]
        elif info.cache_path and os.path.exists(info.cache_path):
            try:
                with open(info.cache_path, 'r', encoding='utf-8') as f:
                    full_data = json.load(f)
            except Exception as e:
                print(f"âš ï¸ [Registry] Failed to load local cache: {e}")
        
        if not full_data:
            print(f"âŒ [Registry] Cannot Save: Source data not found for {info.article_id}")
            return False

        # 2. Update In-Memory Data
        # V2 Schema Update
        if '_header' not in full_data:
             full_data = {
                 '_header': {
                     'article_id': full_data.get('article_id', info.article_id),
                     'state': new_state,
                     'created_at': full_data.get('crawled_at', timestamp),
                     'updated_at': timestamp,
                 },
                 '_original': full_data,
             }
        
        # Standard Header Update
        full_data['_header']['state'] = new_state
        full_data['_header']['updated_at'] = timestamp
        
        # Apply Extra Updates (with dot notation support)
        if updates:
            for key, value in updates.items():
                if '.' in key:
                    section, field = key.split('.', 1)
                    if section not in full_data:
                        full_data[section] = {}
                    if isinstance(full_data[section], dict):
                        full_data[section][field] = value
                else:
                    full_data[key] = value
        
        # History
        if 'state_history' not in full_data['_header']:
            full_data['_header']['state_history'] = []
            
        full_data['_header']['state_history'].append({
            'state': new_state,
            'at': timestamp,
            'by': by
        })

        # [Important] Update Memory Cache
        self._full_data[info.article_id] = full_data
        
        # 3. Save to Local (Atomic Write Update)
        try:
            if info.cache_path:
                with open(info.cache_path, 'w', encoding='utf-8') as f:
                    json.dump(full_data, f, ensure_ascii=False, indent=2)
        except Exception as e:
            print(f"âš ï¸ [Registry] Local save failed: {e}")
            return False
            
        # 4. Save to Firestore (Full Overwrite)
        if self._db:
            try:
                # Use set(merge=True) to be safe, but practically it's overwriting with full data
                self._db.save_article(info.article_id, full_data)
            except Exception as e:
                print(f"âš ï¸ [Registry] Firestore save failed: {e}")
                return False
                
        return True
    
    # =========================================================================
    # Utility
    # =========================================================================
    
    def is_initialized(self) -> bool:
        """ì´ˆê¸°í™” ì—¬ë¶€"""
        return ArticleRegistry._initialized
    
    def reset(self):
        """ë ˆì§€ìŠ¤íŠ¸ë¦¬ ë¦¬ì…‹ (í…ŒìŠ¤íŠ¸ìš©)"""
        self._articles.clear()
        self._by_state.clear()
        self._by_url.clear()
        ArticleRegistry._initialized = False
        print("ğŸ”„ [Registry] Reset completed.")
    
    def refresh(self):
        """
        ìºì‹œ ìƒˆë¡œê³ ì¹¨ - ìƒˆ ìºì‹œ ìˆ˜ì§‘ í›„ ë˜ëŠ” íœ´ì§€í†µ ë¹„ìš´ í›„ í˜¸ì¶œ
        í˜„ì¬ ì‹œê°„ ê¸°ì¤€ìœ¼ë¡œ ìºì‹œ í´ë”ë¥¼ ë‹¤ì‹œ ìŠ¤ìº”
        """
        if not self._cache_root or not os.path.exists(self._cache_root):
            return
        
        cutoff_date = datetime.now() - timedelta(days=self._max_age_days)
        cutoff_str = cutoff_date.strftime('%Y-%m-%d')
        new_count = 0
        
        for folder in glob.glob(os.path.join(self._cache_root, '*')):
            folder_name = os.path.basename(folder)
            if not folder_name.startswith('20') or folder_name < cutoff_str:
                continue
            
            for fpath in glob.glob(os.path.join(folder, '*.json')):
                try:
                    article_id = os.path.basename(fpath).replace('.json', '')
                    if article_id in self._articles:
                        continue  # ì´ë¯¸ ë“±ë¡ë¨
                    
                    with open(fpath, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    
                    # register()ë¥¼ ì‚¬ìš©í•´ì„œ ë¡œì»¬ + Firestore ë‘˜ ë‹¤ ì €ì¥
                    info = self.register(data, cache_path=fpath)
                    if info:
                        new_count += 1
                except Exception:
                    continue
        
        if new_count > 0:
            print(f"ğŸ”„ [Registry] Refreshed: {new_count} new articles added")


# =========================================================================
# Module-level Convenience Functions
# =========================================================================

def get_registry() -> ArticleRegistry:
    """ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    return ArticleRegistry()


def init_registry(cache_root: str = None, db_client = None):
    """ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì´ˆê¸°í™” (ì„œë²„ ì‹œì‘ ì‹œ í˜¸ì¶œ)"""
    registry = get_registry()
    registry.initialize(cache_root, db_client)
    return registry
